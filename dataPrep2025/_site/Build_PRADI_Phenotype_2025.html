<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>PRADI Data Prep 2025</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding-0.33/datatables.js"></script>
<link href="site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Build_WRAP_Phenotype_2025.html">WRAP</a>
</li>
<li>
  <a href="Build_PRADI_Phenotype_2025.html">PRADI</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">PRADI Data Prep 2025</h1>

</div>


<p>Author: Mengna Zhang</p>
<p><em>Last updated on:</em> 2025-09-09</p>
<div id="set-path" class="section level1">
<h1>Set Path</h1>
<pre class="r"><code>## directory: can extend to the main CNT folder
directory &lt;- &quot;/Users/&quot;

## your own directory
my_directory &lt;- paste0(directory, &quot;mengnazhang/Desktop/&quot;)

## set PRADI path (the folder where PRADI raw files located)
pradi_directory &lt;- paste0(my_directory, &quot;ADSP_DataPrep_local/PRADI/Phenotype/2025/Raw/&quot;)

## output path
out_directory &lt;- paste0(my_directory, &quot;ADSP_DataPrep_local/PRADI/Phenotype/2025/Cleaned/&quot;)

## script path
script_directory &lt;- paste0(my_directory, &quot;ADSP_DataPrep_local/PRADI/Phenotype/2025/Scripts/&quot;)

## revised DD path
revisedDDpath &lt;- paste0(out_directory,&quot;colnamesPerSubdata.xlsx&quot;)</code></pre>
<p><br></p>
</div>
<div id="load-helper-scripts" class="section level1">
<h1>Load Helper Scripts</h1>
<pre class="r"><code>source(&quot;/Users/mengnazhang/Desktop/ADSP_DataPrep/dataPrep2025/helperScripts_PRADI.R&quot;)
# source(paste0(script_directory,&quot;helperScripts_WRAP.R&quot;))</code></pre>
<p><br></p>
</div>
<div id="load-packages" class="section level1">
<h1>Load Packages</h1>
<pre class="r"><code>require(dplyr)
require(readxl)
require(openxlsx)
require(stringr)
require(tidyr)
require(lubridate)
`%!in%` &lt;- Negate(`%in%`)</code></pre>
<p><br> <br></p>
</div>
<div id="sub-files-inspection" class="section level1">
<h1>Sub Files Inspection</h1>
<!-- ## Save all sub file names -->
<!-- **Extract all file names** -->
<!-- ```{r engine='bash', comment=''} -->
<!-- mypath="/Users/mengnazhang/Desktop/ADSP_DataPrep_local/PRADI/Phenotype/2025/Raw/" -->
<!-- ls ${mypath} | grep ".xlsx" > ${mypath}filelist.txt -->
<!-- wc -l ${mypath}filelist.txt ## 38 sub files in total -->
<!-- ``` -->
<div id="load-all-subfiles" class="section level2">
<h2>Load All Subfiles</h2>
<pre class="r"><code>file_list &lt;- paste0(out_directory,&quot;filelist.txt&quot;)

## read all lines (file names) from the file
file_names &lt;- readLines(file_list)

## loop over each file name
for (fname in file_names) {
  ## Extract the clean name by removing prefix and suffix
  clean_name &lt;- sub(&quot;^PRADI_&quot;, &quot;&quot;, fname)
  clean_name &lt;- sub(&quot;_05122025\\.xlsx$&quot;, &quot;&quot;, clean_name)
  
  ## read the Excel file and convert to data.frame
  data &lt;- as.data.frame(read_excel(paste0(pradi_directory, fname),sheet = &quot;Export Worksheet&quot;))
  
  ## assign to a variable with the clean name in the global environment
  assign(clean_name, data, envir = .GlobalEnv)
  rm(data)
}</code></pre>
<p><br> <br></p>
</div>
<div id="get-common-columns" class="section level2">
<h2>Get Common Columns</h2>
<pre class="r"><code>df_names &lt;- ls()[sapply(mget(ls(), .GlobalEnv), is.data.frame)]

## extract the column names for each data frame
column_lists &lt;- lapply(df_names, function(name) colnames(get(name)))

## find common columns across all data frames
common_cols &lt;- Reduce(intersect, column_lists)

# Print the result
print(common_cols)</code></pre>
<pre><code>##  [1] &quot;SYSXM&quot;         &quot;SYSIND&quot;        &quot;SYSGP&quot;         &quot;SYSGPSTUDY&quot;   
##  [5] &quot;SYSINDGP&quot;      &quot;CGI_ORDER&quot;     &quot;GPS_ORDER&quot;     &quot;STDCGI_ORDER&quot; 
##  [9] &quot;LSTUDY&quot;        &quot;DB_OWNER&quot;      &quot;STUDY&quot;         &quot;SUBSTUDY&quot;     
## [13] &quot;CENTER&quot;        &quot;GP&quot;            &quot;IND&quot;           &quot;REFCTR&quot;       
## [17] &quot;DATE_OF_BIRTH&quot;</code></pre>
<p><br> <br></p>
</div>
<div id="save-all-colnames" class="section level2">
<h2>Save all Colnames</h2>
<pre class="r"><code>## This code only needs to be run once.
## It will generate an Excel file where each sheet contains the column names for its corresponding dataset.
## Then I will use this excel and fill the infor for each variable to generate the revise DD: 
# Create a new workbook
wb &lt;- createWorkbook()

# For each data frame, add a sheet with its column names
# Loop through each data frame
for (df_name in df_names) {
  df &lt;- get(df_name)  # get the actual data frame
  col_names_df &lt;- data.frame(VarNames = colnames(df))  # create single-column df
  
  # Add sheet with df name (truncated to 31 characters max)
  sheet_name &lt;- substr(df_name, 1, 31)
  addWorksheet(wb, sheetName = sheet_name)
  
  # Write the column names into the sheet
  writeData(wb, sheet = sheet_name, col_names_df)
}

# Save the workbook
## define the name and location of this file to save
saveWorkbook(wb, file = colnames_file, overwrite = TRUE)</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="variable-check-per-file" class="section level1">
<h1>Variable Check Per File</h1>
<div id="aaad_geriat" class="section level2">
<h2>AAAD_GERIAT</h2>
<pre class="r"><code>df &lt;- AAAD_GERIAT

info(AAAD_GERIAT,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1051, cols:62, inds:939</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    1051 obs. of  62 variables:
##  $ SYSXM              : num  7534713 7540453 7540583 7540653 7540803 ...
##  $ SYSIND             : num  11108883 11006263 11048913 11048883 11059623 ...
##  $ SYSGP              : num  7920393 7888673 7896183 7896183 7897223 ...
##  $ SYSGPSTUDY         : num  1357713 1304013 1311503 1311503 1312543 ...
##  $ SYSINDGP           : num  7868403 7761063 7804773 7804743 7818553 ...
##  $ CGI_ORDER          : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER          : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER       : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY             : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER           : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY              : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY           : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER             : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                 : num  87634 87534 87657 87657 87699 ...
##  $ IND                : num  1 104 102 1000 101 108 1 1 1 1 ...
##  $ REFCTR             : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE          : POSIXct, format: &quot;2018-01-12&quot; &quot;2018-02-21&quot; ...
##  $ EXAMINER           : chr  &quot;axr1589&quot; &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; &quot;axr1589&quot; ...
##  $ DATE_OF_BIRTH      : POSIXct, format: &quot;1950-06-03&quot; &quot;1936-09-20&quot; ...
##  $ AGE_AT_EXAM        : num  67 81 72 94 88 68 67 71 68 69 ...
##  $ SATISFIED_LIFE     : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ DROPPED_ACTIVITIES : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ FEEL_EMPTY         : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ GOOD_SPIRIT        : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ AFRAID_BAD_THINGS  : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BORED              : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;Y&quot; ...
##  $ FEEL_HAPPY         : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ FEEL_HELPLESS      : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ STAY_HOME          : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ MEMORY_PROBLEM     : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ ALIVE              : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ FEEL_WORTHLESS     : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ FEEL_FULL_ENERGY   : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ FEEL_HOPELESS      : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ OTHER_BETTER_OFF   : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ TROUBLE_FALL_ASLEEP: logi  NA NA NA NA NA NA ...
##  $ TROUBLE_STAY_ASLEEP: logi  NA NA NA NA NA NA ...
##  $ SLEEPING_TOO_MUCH  : logi  NA NA NA NA NA NA ...
##  $ APPETITE_INCREASED : logi  NA NA NA NA NA NA ...
##  $ APPETITE_DECREASED : logi  NA NA NA NA NA NA ...
##  $ WEIGHT_LOSS        : logi  NA NA NA NA NA NA ...
##  $ AMOUNT_WEIGHT_LOSS : logi  NA NA NA NA NA NA ...
##  $ SATISFYING_LIFE    : logi  NA NA NA NA NA NA ...
##  $ COMMENTS           : logi  NA NA NA NA NA NA ...
##  $ RELIABLE           : logi  NA NA NA NA NA NA ...
##  $ LIFE_SCORE         : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ ACTIVITY_SCORE     : num  0 0 0 0 1 0 0 0 1 1 ...
##  $ EMPTY_SCORE        : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ BORED_SCORE        : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ SPIRIT_SCORE       : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ AFRAID_SCORE       : num  0 0 0 0 0 0 0 0 1 0 ...
##  $ HAPPY_SCORE        : num  0 0 0 0 0 0 1 0 0 0 ...
##  $ HELPLESS_SCORE     : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ STAY_HOME_SCORE    : num  0 0 0 0 1 1 0 0 1 0 ...
##  $ MEMORY_SCORE       : num  0 0 0 0 1 0 0 0 0 1 ...
##  $ ALIVE_SCORE        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ WORTHLESS_SCORE    : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ FULL_ENERGY_SCORE  : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ HOPELESS_SCORE     : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ BETTER_OFF_SCORE   : num  0 0 0 0 0 0 1 0 0 1 ...
##  $ TOTAL_STATUS       : chr  NA NA NA NA ...
##  $ TOTAL              : num  0 0 0 1 3 1 2 0 3 6 ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;AAAD_GERIAT&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 11 vars 

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 11 × 2
##    VarNames            `Data Type`
##    &lt;chr&gt;               &lt;chr&gt;      
##  1 REFCTR              VARCHAR2(6)
##  2 TROUBLE_FALL_ASLEEP &lt;NA&gt;       
##  3 TROUBLE_STAY_ASLEEP &lt;NA&gt;       
##  4 SLEEPING_TOO_MUCH   &lt;NA&gt;       
##  5 APPETITE_INCREASED  &lt;NA&gt;       
##  6 APPETITE_DECREASED  &lt;NA&gt;       
##  7 WEIGHT_LOSS         &lt;NA&gt;       
##  8 AMOUNT_WEIGHT_LOSS  &lt;NA&gt;       
##  9 SATISFYING_LIFE     &lt;NA&gt;       
## 10 COMMENTS            &lt;NA&gt;       
## 11 RELIABLE            &lt;NA&gt;</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;-c(&quot;REFCTR&quot;)

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;logical&quot;</code></pre>
<pre class="r"><code>## NOTE: For the other 10 variables, the DD does not provide data type information, so I’m leaving them unspecified for now.</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2018-01-12    1950-06-03
## 2 2018-02-21    1936-09-20
## 3 2018-02-19    1946-01-11
## 4 2018-02-19    1923-04-17
## 5 2018-02-18    1929-10-08
## 6 2018-02-19    1949-08-01</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;      &quot;logical&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)]
## 23 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2ac855cca5561d8ca785" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2ac855cca5561d8ca785">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["axr1589, v.rodriguez4, bxf258, avg55, ALEJANDRA BETACOURT, kxc672, RDW, sjt82, plb50, ascott2, prm72, mxp1257, erika negro, mxc2207, Erika Negro, MP, AS, PM, OG, M. prough, patricia, NIT, MICHAEL P, M PROUGH, UCC, CDel, NEREIDA FELICIANO, erica, erika, Maricarmen Contreras, xx, fxs121, MEDICAL RECORDS, jjs2031, axl4132, jmv184, cmanrique, gsv32, rmartinez1"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER, as I assume we can have multiple examiners</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 27 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-f3780a4dea4cefc3c77f" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-f3780a4dea4cefc3c77f">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104406, 104418, 104420, 104446, 104442, 104423, 104457, 104438, 104419, 104409, 104404, 104431, 104456, 104433, 104425, 104434, 104402, 104501, 104403, 104436, 104413, 104440, 104430, 104424, 104415, 104443, 104441, 104414, 104444, 104422, 104428, 104435, 104437, 104412, 104411, 104408, 104407, 104432, 104439, 104445, 104427, 104410, 104426, 104466, 104477, 104711"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>AAAD_GERIAT &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="aaad_medcon" class="section level2">
<h2>AAAD_MEDCON</h2>
<pre class="r"><code>df &lt;- AAAD_MEDCON

info(AAAD_MEDCON,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:397, cols:256, inds:367</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    397 obs. of  256 variables:
##  $ SYSXM                     : num  7134193 7839953 7838803 7838853 7838933 ...
##  $ SYSIND                    : num  11010563 11368403 11368463 11368453 11368443 ...
##  $ SYSGP                     : num  7889553 7950923 7950983 7950973 7950963 ...
##  $ SYSGPSTUDY                : num  1304893 1396033 1396093 1396083 1396073 ...
##  $ SYSINDGP                  : num  7765583 8137673 8137733 8137723 8137713 ...
##  $ CGI_ORDER                 : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                 : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER              : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                    : chr  &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER                  : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                     : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                  : chr  &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER                    : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                        : num  87580 88413 88419 88418 88417 ...
##  $ IND                       : num  1 1 1 1 1 100 1 1 1 1 ...
##  $ REFCTR                    : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                 : POSIXct, format: &quot;2016-09-07&quot; &quot;2020-03-06&quot; ...
##  $ EXAMINER                  : chr  &quot;ladams4&quot; &quot;sjt82&quot; &quot;mxp1257&quot; &quot;mxp1257&quot; ...
##  $ DATE_OF_BIRTH             : POSIXct, format: &quot;1925-08-21&quot; &quot;1928-02-14&quot; ...
##  $ AGE_AT_EXAM               : num  91 92 74 75 75 64 83 77 79 85 ...
##  $ REVIEW_DATE               : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                  : logi  NA NA NA NA NA NA ...
##  $ MEMORY_COMPLAINTS         : num  NA 1 0 0 0 1 0 0 0 0 ...
##  $ DATE_OF_ONSET             : POSIXct, format: NA NA ...
##  $ DOA_UNK                   : chr  NA &quot;U&quot; NA NA ...
##  $ DESCRIBE                  : chr  &quot;hello&quot; &quot;No family history of dementia.&quot; &quot;Brother with PD.&quot; &quot;Denies psychological/psychiatric conditions.  Brother, mother, aunt (father&#39;s sister) and grandparents with AD &quot;| __truncated__ ...
##  $ MEM_COMPLAINTS            : chr  NA &quot;misplaces objects  Informant: Daughter and self 92 YO widow female who lives with daughter and  visits senior c&quot;| __truncated__ &quot;None. Lives alone. Can cook, clean and take care of self. Fully capable of self care and fully oriented. Drives&quot;| __truncated__ &quot;none. denies memoery issues. Lives with daughter. can cook, clean and do chores but daughter helps. Says she co&quot;| __truncated__ ...
##  $ CURRENT_MED               : chr  NA NA &quot;Hypertension and Thyroid issues&quot; &quot;Hypertension + neuropathy + metformin&quot; ...
##  $ PMH                       : chr  NA &quot;HTN&quot; &quot;Hypertension and Thyroid issues&quot; NA ...
##  $ MOOD_CHANGES              : chr  NA &quot;denies&quot; &quot;denies.&quot; NA ...
##  $ MEDICATIONS               : chr  NA &quot;lisinopril, clopidogrel&quot; NA &quot;not collected&quot; ...
##  $ HYPERTENSION_DX           : num  NA 1 NA NA NA 1 NA 0 1 1 ...
##  $ HYPERTENSION_TREATED      : num  NA 1 NA NA NA 1 NA 0 NA NA ...
##  $ DIABETES_DX               : num  NA 0 NA NA NA 1 NA 0 0 1 ...
##  $ DIABETES_TREATED          : num  NA NA NA NA NA 1 NA 0 NA NA ...
##  $ MYOCARDIAL_DX             : num  NA 0 NA NA NA 0 NA 0 0 1 ...
##  $ MYOCARDIAL_TREATED        : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ HEART_FAILURE_DX          : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ HEART_FAILURE_TREATED     : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ HEART_DISEASE_DX          : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ HEART_DISEASE_TREATED     : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ COPD_DX                   : num  NA 0 NA NA NA 0 NA 0 0 1 ...
##  $ COPD_TREATED              : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ THYROID_DX                : num  NA 0 NA NA NA 0 NA 1 0 0 ...
##  $ THYROID_TREATED           : num  NA NA NA NA NA 0 NA 1 NA NA ...
##  $ LIVER_DX                  : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ LIVER_TREATED             : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ RENAL_DX                  : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ RENAL_TREATED             : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ PEPTIC_DX                 : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ PEPTIC_TREATED            : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ PERIPHERAL_DX             : num  NA 0 NA NA NA 0 NA 1 0 0 ...
##  $ PERIPHERAL_TREATED        : num  NA NA NA NA NA 0 NA 1 NA NA ...
##  $ STROKE_DX                 : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ STROKE_TREATED            : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ TIA_DX                    : num  NA 0 NA NA NA 0 NA 0 0 1 ...
##  $ TIA_TREATED               : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ HEAD_INJURY_DX            : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ HEAD_INJURY_TREATED       : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ SEIZURE_DX                : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ SEIZURE_TREATED           : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ CANCER_DX                 : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ CANCER_TREATED            : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ ARTHRITIS_DX              : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ ARTHRITIS_TREATED         : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ SYPHILIS_DX               : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ SYPHILIS_TREATED          : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ ALCOHOL_DX                : num  NA 0 NA NA NA 0 NA 0 0 1 ...
##  $ ALCOHOL_TREATED           : num  NA NA NA NA NA 0 NA 0 0 9 ...
##  $ ILLICIT_DRUG_DX           : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ ILLICIT_DRUG_TREATED      : num  NA NA NA NA NA 0 NA 0 0 9 ...
##  $ SMOKING_DX                : num  NA 0 NA NA NA 0 NA 0 0 1 ...
##  $ SMOKING_TREATED           : num  NA NA NA NA NA 0 NA 0 0 9 ...
##  $ PD_DX                     : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ PD_TREATED                : num  NA NA NA NA NA 0 NA 0 0 9 ...
##  $ HUNTINGTON_DX             : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ HUNTINGTON_TREATED        : num  NA NA NA NA NA 0 NA 0 0 9 ...
##  $ MULTIPLE_SCLEROSIS_DX     : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ MULTIPLE_SCLEROSIS_TREATED: num  NA NA NA NA NA 0 NA 0 NA 9 ...
##  $ B12_DX                    : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ B12_TREATED               : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ HYDROCEPHALUS_DX          : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ HYDROCEPHALUS_TREATED     : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ TREMOR_DX                 : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ TREMOR_TREATED            : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ DOWN_SYNDROME_DX          : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ DOWN_SYNDROME_TREATED     : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ MED_CONDITIONS_DX         : num  NA 0 NA NA NA 0 NA 0 0 0 ...
##  $ MED_CONDITIONS_TREATED    : num  NA NA NA NA NA 0 NA 0 NA NA ...
##  $ OTH_MED_COND_SP           : chr  NA NA NA NA ...
##  $ STROKE_BRAIN              : num  NA 0 NA NA NA 0 NA 0 9 1 ...
##  $ DOCTOR                    : num  NA NA NA NA NA 0 NA 0 9 1 ...
##  $ STROKE_PAST               : num  NA NA NA NA NA 0 NA 0 9 1 ...
##  $ STROKE_24HRS              : num  NA NA NA NA NA 0 NA 0 9 0 ...
##  $ SYMPTOMS                  : num  NA NA NA NA NA 0 NA 0 9 0 ...
##  $ LOST_SPEECH               : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ LOST_UNDERSTAND           : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ LOSS_CONSCIOUS            : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ WEAKNESS                  : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ NUMBNESS                  : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ LOSS_VISION               : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ HALF_VISION               : num  NA 0 NA NA NA 0 NA 0 9 9 ...
##  $ PERIOD                    : num  NA 9 NA NA NA 9 NA 0 9 0 ...
##  $ AGE                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DONT_KNOW                 : chr  NA NA NA NA ...
##  $ SEEK_HELP                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TREATMENT                 : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ MEDS                      : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ PSYCHOTHERAPY             : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ OTHER                     : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ SPECIFY                   : chr  NA NA NA NA ...
##  $ UNKNOWN                   : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ TAKING_MEDS               : num  NA NA NA NA NA NA NA 1 NA NA ...
##  $ MEDICATION1               : chr  NA NA NA NA ...
##  $ STRENGTH1                 : chr  NA NA NA NA ...
##  $ SEEN1                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN1_SPEC                : chr  NA NA NA NA ...
##  $ MEDICATION2               : chr  NA NA NA NA ...
##  $ STRENGTH2                 : chr  NA NA NA NA ...
##  $ SEEN2                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN2_SPEC                : chr  NA NA NA NA ...
##  $ MEDICATION3               : chr  NA NA NA NA ...
##  $ STRENGTH3                 : chr  NA NA NA NA ...
##  $ SEEN3                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN3_SPEC                : chr  NA NA NA NA ...
##  $ MEDICATION4               : chr  NA NA NA NA ...
##  $ STRENGTH4                 : chr  NA NA NA NA ...
##  $ SEEN4                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN4_SPEC                : chr  NA NA NA NA ...
##  $ MEDICATION5               : chr  NA NA NA NA ...
##  $ STRENGTH5                 : chr  NA NA NA NA ...
##  $ SEEN5                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN5_SPEC                : logi  NA NA NA NA NA NA ...
##  $ MEDICATION6               : chr  NA NA NA NA ...
##  $ STRENGTH6                 : chr  NA NA NA NA ...
##  $ SEEN6                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN6_SPEC                : logi  NA NA NA NA NA NA ...
##  $ MEDICATION7               : chr  NA NA NA NA ...
##  $ STRENGTH7                 : chr  NA NA NA NA ...
##  $ SEEN7                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN7_SPEC                : logi  NA NA NA NA NA NA ...
##  $ MEDICATION8               : chr  NA NA NA NA ...
##  $ STRENGTH8                 : chr  NA NA NA NA ...
##  $ SEEN8                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN8_SPEC                : logi  NA NA NA NA NA NA ...
##  $ MEDICATION9               : chr  NA NA NA NA ...
##  $ STRENGTH9                 : chr  NA NA NA NA ...
##  $ SEEN9                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN9_SPEC                : logi  NA NA NA NA NA NA ...
##  $ MEDICATION10              : chr  NA NA NA NA ...
##  $ STRENGTH10                : chr  NA NA NA NA ...
##  $ SEEN10                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN10_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION11              : chr  NA NA NA NA ...
##  $ STRENGTH11                : chr  NA NA NA NA ...
##  $ SEEN11                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN11_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION12              : chr  NA NA NA NA ...
##  $ STRENGTH12                : chr  NA NA NA NA ...
##  $ SEEN12                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN12_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION13              : chr  NA NA NA NA ...
##  $ STRENGTH13                : chr  NA NA NA NA ...
##  $ SEEN13                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN13_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION14              : chr  NA NA NA NA ...
##  $ STRENGTH14                : chr  NA NA NA NA ...
##  $ SEEN14                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN14_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION15              : chr  NA NA NA NA ...
##  $ STRENGTH15                : logi  NA NA NA NA NA NA ...
##  $ SEEN15                    : logi  NA NA NA NA NA NA ...
##  $ SEEN15_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION16              : chr  NA NA NA NA ...
##  $ STRENGTH16                : logi  NA NA NA NA NA NA ...
##  $ SEEN16                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN16_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION17              : chr  NA NA NA NA ...
##  $ STRENGTH17                : logi  NA NA NA NA NA NA ...
##  $ SEEN17                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SEEN17_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION18              : logi  NA NA NA NA NA NA ...
##  $ STRENGTH18                : logi  NA NA NA NA NA NA ...
##  $ SEEN18                    : logi  NA NA NA NA NA NA ...
##  $ SEEN18_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION19              : logi  NA NA NA NA NA NA ...
##  $ STRENGTH19                : logi  NA NA NA NA NA NA ...
##  $ SEEN19                    : logi  NA NA NA NA NA NA ...
##  $ SEEN19_SPEC               : logi  NA NA NA NA NA NA ...
##  $ MEDICATION20              : logi  NA NA NA NA NA NA ...
##  $ STRENGTH20                : logi  NA NA NA NA NA NA ...
##  $ SEEN20                    : logi  NA NA NA NA NA NA ...
##  $ SEEN20_SPEC               : logi  NA NA NA NA NA NA ...
##  $ NOTES                     : chr  NA NA NA NA ...
##  $ WARFARIN                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ASPIRIN                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTIPLATELETS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DIURETICS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTICONVULSANTS           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ INSULIN                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYPOGLYCEMICS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SULFONYLUREA              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ METFORMIN                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GLITAZONES                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DIGITALIS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NITRATES                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CALCIUM_CHANNEL           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BETA_2_AGAONIST           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BETA_BLOCKERS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ACE                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTI_ARRHYTHMICS          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTI_HYPERLIPIDEMICS      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ STATIN_DRUG               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ FIBRATE_DRUG              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ THYROID                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTICHOLINERGICS          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ LEVODOPA                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DOPAMINE                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTIDEPRESSANTS           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTIPSYCHOTICS            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANXIOLYTICS               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CHOLINESTERASE            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ RIVASTIGMINE              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TACRINE                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DONEPEZIL                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GALANTAMINE               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NMDA                      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEMANTINE                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ALPHA_BLOCKERS            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYPNOTICS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ H1_BLOCKERS               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ H2_BLOCKERS               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NSAID                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COX2                      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NARCOTICS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYDERGINE                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DEPRENYL                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ESTROGEN_SUPP             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PRESCRIPTION              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OTC                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ STEROIDS                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OTHER_MEDS                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPEC_MEDS                 : chr  NA NA NA NA ...
##  $ MULTIVITAMINS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_C                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_E                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMINE_B12              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COENZYME_Q                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DHA                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ LECITHIN                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GINKGO                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ FOLIC_ACID                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_B6                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_D                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OMEGA3                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEDCOND_COMENTS           : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-1" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;AAAD_MEDCON&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-1" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 33 vars

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 33 × 2
##    VarNames    `Data Type`  
##    &lt;chr&gt;       &lt;chr&gt;        
##  1 REFCTR      VARCHAR2(6)  
##  2 REVIEW_DATE date         
##  3 REVIEWER    VARCHAR      
##  4 SEEN5_SPEC  VARCHAR2(100)
##  5 SEEN6_SPEC  VARCHAR2(100)
##  6 SEEN7_SPEC  VARCHAR2(100)
##  7 SEEN8_SPEC  VARCHAR2(100)
##  8 SEEN9_SPEC  VARCHAR2(100)
##  9 SEEN10_SPEC VARCHAR2(100)
## 10 SEEN11_SPEC VARCHAR2(100)
## # ℹ 23 more rows</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)] ## &quot;SEEN15&quot; &quot;SEEN18&quot; &quot;SEEN19&quot; &quot;SEEN20&quot;

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## 28 vars

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-1" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; &quot;DATE_OF_ONSET&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## &quot;REVIEW_DATE, ignore it, since it has been converted in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH DATE_OF_ONSET
## 1 2016-09-07    1925-08-21          &lt;NA&gt;
## 2 2020-03-06    1928-02-14          &lt;NA&gt;
## 3 2020-03-06    1945-09-01          &lt;NA&gt;
## 4 2020-03-06    1944-03-22          &lt;NA&gt;
## 5 2020-03-06    1944-10-17          &lt;NA&gt;
## 6 2020-03-05    1955-06-26    2016-09-09</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-1" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)]
## 81 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## DOA_UNK, ignore, I have updated DD to &quot;char&quot;
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-9bdcaa8bb46375176569" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-9bdcaa8bb46375176569">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="handling-numeric-variables-1" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 31 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                           &quot;1 thru 99999;&quot;             
## [3] &quot;1 thru 9999;&quot;               &quot;0;\r\n1;&quot;                  
## [5] &quot;0;\r\n1;\r\n9;\r\n-1;&quot;      &quot;0;\r\n1;\r\n7;\r\n8;\r\n9;&quot;
## [7] &quot;0;\r\n1;\r\n9;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-b78b2b1615cb8a23ef98" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-b78b2b1615cb8a23ef98">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104406, 104405, 104422, 104428, 104435, 104437, 104411, 104418, 104442, 104445, 104427, 104460, 104415, 104410, 104466, 104438, 104419, 104409, 104446, 104464, 104408, 104431, 104407, 104432, 104439, 104420, 104423, 104424, 104530, 104501, 104412, 104426, 104403, 104429, 104433, 104440, 104443, 104444, 104425, 104413, 104441, 104430, 104421, 104404, 104402, 104436, 104401"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP and IND</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-1" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>AAAD_MEDCON &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="aaad_socio_demo" class="section level2">
<h2>AAAD_SOCIO_DEMO</h2>
<pre class="r"><code>df &lt;- AAAD_SOCIO_DEMO

info(AAAD_SOCIO_DEMO,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:402, cols:161, inds:391</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    402 obs. of  161 variables:
##  $ SYSXM        : num  7895153 7875263 7879973 7879993 7880213 ...
##  $ SYSIND       : num  11218613 11036843 11041143 11041043 11005233 ...
##  $ SYSGP        : num  7928123 7893863 7894373 7894373 7888553 ...
##  $ SYSGPSTUDY   : num  1366233 1309183 1309693 1309693 1303893 ...
##  $ SYSINDGP     : num  7981883 7792583 7797003 7796903 7760033 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  87998 87598 87502 87502 87501 ...
##  $ IND          : num  1 1 102 100 1 1 1 1 1 1 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE    : POSIXct, format: &quot;2021-02-01&quot; &quot;2020-07-14&quot; ...
##  $ EXAMINER     : chr  &quot;sjt82&quot; &quot;v.rodriguez4&quot; &quot;prm72&quot; &quot;prm72&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1943-09-22&quot; &quot;1946-10-04&quot; ...
##  $ AGE_AT_EXAM  : num  77 73 69 71 81 84 85 77 83 85 ...
##  $ REVIEW_DATE  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER     : logi  NA NA NA NA NA NA ...
##  $ SDF1         : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ SDF2         : num  1 NA NA NA NA NA NA NA NA NA ...
##  $ SDF2A        : chr  &quot;WH&quot; NA NA NA ...
##  $ SDF3         : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ SDF3A        : chr  &quot;SPANISH&quot; NA NA NA ...
##  $ SDF4         : chr  &quot;W&quot; NA NA NA ...
##  $ SDF4A        : chr  NA NA NA NA ...
##  $ SDF5         : chr  &quot;A&quot; NA NA NA ...
##  $ SDF5A        : chr  NA NA NA NA ...
##  $ SDF6         : chr  &quot;SF&quot; NA NA NA ...
##  $ SDF6A        : chr  NA NA NA NA ...
##  $ SDF7         : chr  NA NA NA NA ...
##  $ SDF8A        : chr  &quot;PT&quot; NA NA NA ...
##  $ SDF8B        : chr  NA NA NA NA ...
##  $ SDF8C        : chr  NA NA NA NA ...
##  $ SDF9         : chr  NA NA NA NA ...
##  $ SDF10        : chr  NA NA NA NA ...
##  $ SDF11        : chr  NA NA NA NA ...
##  $ SDF12        : logi  NA NA NA NA NA NA ...
##  $ SDF13        : logi  NA NA NA NA NA NA ...
##  $ SDF14        : logi  NA NA NA NA NA NA ...
##  $ SDF15        : logi  NA NA NA NA NA NA ...
##  $ SDF16        : logi  NA NA NA NA NA NA ...
##  $ SDF17        : logi  NA NA NA NA NA NA ...
##  $ SDF17A       : logi  NA NA NA NA NA NA ...
##  $ SDF18        : logi  NA NA NA NA NA NA ...
##  $ SDF19        : logi  NA NA NA NA NA NA ...
##  $ SDF20        : chr  &quot;TEACHER ASSISTANT&quot; &quot;UNKNOWN&quot; &quot;Computer service tech&quot; &quot;Engineer&quot; ...
##  $ SDF21        : chr  NA NA NA NA ...
##  $ SDF22        : logi  NA NA NA NA NA NA ...
##  $ SDF22A       : chr  NA NA NA NA ...
##  $ SDF23        : logi  NA NA NA NA NA NA ...
##  $ SDF24        : logi  NA NA NA NA NA NA ...
##  $ SDF25        : logi  NA NA NA NA NA NA ...
##  $ SDF26        : logi  NA NA NA NA NA NA ...
##  $ SDF27A       : logi  NA NA NA NA NA NA ...
##  $ SDF27B       : logi  NA NA NA NA NA NA ...
##  $ SDF27C       : logi  NA NA NA NA NA NA ...
##  $ SDF27D       : logi  NA NA NA NA NA NA ...
##  $ SDF27E       : logi  NA NA NA NA NA NA ...
##  $ SDF27F       : logi  NA NA NA NA NA NA ...
##  $ SDF27G       : logi  NA NA NA NA NA NA ...
##  $ SDF27H       : logi  NA NA NA NA NA NA ...
##  $ SDF28        : logi  NA NA NA NA NA NA ...
##  $ SDF29        : logi  NA NA NA NA NA NA ...
##  $ SDF30A       : logi  NA NA NA NA NA NA ...
##  $ SDF30B       : logi  NA NA NA NA NA NA ...
##  $ SDF30C       : logi  NA NA NA NA NA NA ...
##  $ SDF30D       : logi  NA NA NA NA NA NA ...
##  $ SDF30E       : logi  NA NA NA NA NA NA ...
##  $ SDF30F       : logi  NA NA NA NA NA NA ...
##  $ SDF30G       : logi  NA NA NA NA NA NA ...
##  $ SDF31        : logi  NA NA NA NA NA NA ...
##  $ SDF31A       : logi  NA NA NA NA NA NA ...
##  $ SDF32        : logi  NA NA NA NA NA NA ...
##  $ SDF33        : logi  NA NA NA NA NA NA ...
##  $ SDF33A       : logi  NA NA NA NA NA NA ...
##  $ SDF34        : logi  NA NA NA NA NA NA ...
##  $ SDF35        : logi  NA NA NA NA NA NA ...
##  $ SDF36        : logi  NA NA NA NA NA NA ...
##  $ SDF37        : logi  NA NA NA NA NA NA ...
##  $ SDF38        : logi  NA NA NA NA NA NA ...
##  $ SDF39        : logi  NA NA NA NA NA NA ...
##  $ SDF40        : logi  NA NA NA NA NA NA ...
##  $ SDF41        : logi  NA NA NA NA NA NA ...
##  $ SDF42        : logi  NA NA NA NA NA NA ...
##  $ SDF42A       : logi  NA NA NA NA NA NA ...
##  $ SDF42B       : logi  NA NA NA NA NA NA ...
##  $ SDF43A       : logi  NA NA NA NA NA NA ...
##  $ SDF43A1      : logi  NA NA NA NA NA NA ...
##  $ SDF43B       : logi  NA NA NA NA NA NA ...
##  $ SDF43B1      : logi  NA NA NA NA NA NA ...
##  $ SDF43C       : logi  NA NA NA NA NA NA ...
##  $ SDF43C1      : logi  NA NA NA NA NA NA ...
##  $ SDF44        : logi  NA NA NA NA NA NA ...
##  $ SDF44A       : logi  NA NA NA NA NA NA ...
##  $ SDF45A       : logi  NA NA NA NA NA NA ...
##  $ SDF45A1      : logi  NA NA NA NA NA NA ...
##  $ SDF45B       : logi  NA NA NA NA NA NA ...
##  $ SDF45B1      : logi  NA NA NA NA NA NA ...
##  $ SDF46        : logi  NA NA NA NA NA NA ...
##  $ SDF47        : logi  NA NA NA NA NA NA ...
##  $ SDF48        : logi  NA NA NA NA NA NA ...
##  $ SDF49A       : logi  NA NA NA NA NA NA ...
##  $ SDF49B       : logi  NA NA NA NA NA NA ...
##  $ SDF49C       : logi  NA NA NA NA NA NA ...
##  $ SDF49D       : logi  NA NA NA NA NA NA ...
##  $ SDF50A       : logi  NA NA NA NA NA NA ...
##  $ SDF50B       : logi  NA NA NA NA NA NA ...
##  $ SDF50C       : logi  NA NA NA NA NA NA ...
##  $ SDF50D       : logi  NA NA NA NA NA NA ...
##  $ SDF51        : logi  NA NA NA NA NA NA ...
##  $ SDF51A       : logi  NA NA NA NA NA NA ...
##  $ SDF52A       : logi  NA NA NA NA NA NA ...
##  $ SDF52B       : logi  NA NA NA NA NA NA ...
##  $ SDF53A       : logi  NA NA NA NA NA NA ...
##  $ SDF53A1      : logi  NA NA NA NA NA NA ...
##  $ SDF53B       : logi  NA NA NA NA NA NA ...
##  $ SDF53C       : logi  NA NA NA NA NA NA ...
##  $ SDF53C1      : logi  NA NA NA NA NA NA ...
##  $ SDF54        : logi  NA NA NA NA NA NA ...
##  $ SDF55        : logi  NA NA NA NA NA NA ...
##  $ SDF56        : logi  NA NA NA NA NA NA ...
##  $ SDF57A       : logi  NA NA NA NA NA NA ...
##  $ SDF57B       : logi  NA NA NA NA NA NA ...
##  $ SDF57C       : logi  NA NA NA NA NA NA ...
##  $ SDF57D       : logi  NA NA NA NA NA NA ...
##  $ SDF58A       : logi  NA NA NA NA NA NA ...
##  $ SDF58B       : logi  NA NA NA NA NA NA ...
##  $ SDF58C       : logi  NA NA NA NA NA NA ...
##  $ SDF58D       : logi  NA NA NA NA NA NA ...
##  $ SDF59        : logi  NA NA NA NA NA NA ...
##  $ SDF59A       : logi  NA NA NA NA NA NA ...
##  $ SDF60A       : logi  NA NA NA NA NA NA ...
##  $ SDF60B       : logi  NA NA NA NA NA NA ...
##  $ SDF60C       : logi  NA NA NA NA NA NA ...
##  $ SDF60D       : logi  NA NA NA NA NA NA ...
##  $ SDF60E       : logi  NA NA NA NA NA NA ...
##  $ SDF60F       : logi  NA NA NA NA NA NA ...
##  $ SDF60FS      : logi  NA NA NA NA NA NA ...
##  $ SDF60G       : logi  NA NA NA NA NA NA ...
##  $ SDF60GS      : logi  NA NA NA NA NA NA ...
##  $ SDF61A       : logi  NA NA NA NA NA NA ...
##  $ SDF61A1      : logi  NA NA NA NA NA NA ...
##  $ SDF61B       : logi  NA NA NA NA NA NA ...
##  $ SDF61C       : logi  NA NA NA NA NA NA ...
##  $ SDF61C1      : logi  NA NA NA NA NA NA ...
##  $ SDF62A       : logi  NA NA NA NA NA NA ...
##  $ SDF62B       : logi  NA NA NA NA NA NA ...
##  $ SDF62C       : logi  NA NA NA NA NA NA ...
##  $ SDF62D       : logi  NA NA NA NA NA NA ...
##  $ SDF63A       : logi  NA NA NA NA NA NA ...
##  $ SDF63B       : logi  NA NA NA NA NA NA ...
##  $ SDF63C       : logi  NA NA NA NA NA NA ...
##  $ SDF63D       : logi  NA NA NA NA NA NA ...
##  $ SDF64        : logi  NA NA NA NA NA NA ...
##  $ SDF65        : logi  NA NA NA NA NA NA ...
##  $ SDF65A       : logi  NA NA NA NA NA NA ...
##  $ SDF66        : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-2" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;AAAD_SOCIO_DEMO&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-2" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 121

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 121 × 2
##    VarNames    `Data Type`  
##    &lt;chr&gt;       &lt;chr&gt;        
##  1 REFCTR      VARCHAR2(6)  
##  2 REVIEW_DATE date         
##  3 REVIEWER    VARCHAR      
##  4 SDF12       VARCHAR2(200)
##  5 SDF13       NUMBER(3)    
##  6 SDF14       CHAR(2)      
##  7 SDF15       CHAR(2)      
##  8 SDF16       CHAR(2)      
##  9 SDF17       NUMBER(2)    
## 10 SDF17A      CHAR(2)      
## # ℹ 111 more rows</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)] ## 55 vars

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)]
## [1] &quot;REVIEW_DATE&quot;

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## 65 vars

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-2" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, can ignore, since it has been converted in last step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2021-02-01    1943-09-22
## 2 2020-07-14    1946-10-04
## 3 2020-09-16    1950-10-02
## 4 2020-09-16    1949-04-30
## 5 2019-05-22    1937-10-24
## 6 2020-09-17    1935-10-25</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-2" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 89 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-83ac3102a6259abd85b5" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-83ac3102a6259abd85b5">{"x":{"filter":"none","vertical":false,"data":[["SDF8A","SDF8B"],["SDF8A","SDF8B"],["FT  PT","FT  PD, R  O, U  R, T  R, R  PD"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>unique(df[[&quot;SDF8A&quot;]]) ## DD: 8. Are you working now? Circle all that apply</code></pre>
<pre><code>## [1] &quot;PT&quot;     NA       &quot;FT&quot;     &quot;V&quot;      &quot;FT  PT&quot;</code></pre>
<pre class="r"><code>unique(df[[&quot;SDF8B&quot;]]) ## DD: If participant says NO, ask Why not? If any of the following SKIP TO #20</code></pre>
<pre><code>##  [1] NA       &quot;O&quot;      &quot;FT&quot;     &quot;R&quot;      &quot;PD&quot;     &quot;FT  PD&quot; &quot;R  O&quot;   &quot;U  R&quot;  
##  [9] &quot;S&quot;      &quot;U&quot;      &quot;IS&quot;     &quot;T&quot;      &quot;T  R&quot;   &quot;R  PD&quot;</code></pre>
<pre class="r"><code>## NOTE: these two variables are good, as they being marked &quot;Multiple&quot; in the [Single, Multiple or Calculated Values] column of DD</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-2" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 69 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>##  [1] NA                            &quot;1 thru 99999;&quot;              
##  [3] &quot;1 thru 9999;&quot;                &quot;1;\r\n0;&quot;                   
##  [5] &quot;1 thru 145;&quot;                 &quot;1 thru 31;&quot;                 
##  [7] &quot;-2;&quot;                         &quot;0 thru 8;&quot;                  
##  [9] &quot;1;\r\n2;\r\n3;\r\n4;\r\n-2;&quot; &quot;0 thru 100;&quot;                
## [11] &quot;0 thru 5;&quot;                   &quot;0;\r\n1;\r\n-2;&quot;            
## [13] &quot;1;\r\n0;\r\n-2;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-6b992e15afe021ec5697" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-6b992e15afe021ec5697">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104406, 104422, 104435, 104437, 104411, 104418, 104445, 104427, 104410, 104420, 104438, 104415, 104419, 104409, 104421, 104428, 104405, 104446, 104431, 104408, 104407, 104432, 104439, 104423, 104424, 104442, 104412, 104426"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-2" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>AAAD_SOCIO_DEMO &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="aaad_trails" class="section level2">
<h2>AAAD_TRAILS</h2>
<pre class="r"><code>df &lt;- AAAD_TRAILS

info(AAAD_TRAILS,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:439, cols:34, inds:428</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    439 obs. of  34 variables:
##  $ SYSXM        : num  7670123 7650923 7651273 7659813 7660113 ...
##  $ SYSIND       : num  11221133 11218963 11219583 11036793 11221813 ...
##  $ SYSGP        : num  7929223 7928203 7928153 7893833 7929683 ...
##  $ SYSGPSTUDY   : num  1367333 1366313 1366263 1309153 1367793 ...
##  $ SYSINDGP     : num  7984403 7982233 7982853 7792533 7985083 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  88063 88095 88002 87595 88059 ...
##  $ IND          : num  1 1 100 9000 1 1 1 1 100 1 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE    : POSIXct, format: &quot;2019-03-07&quot; &quot;2019-03-08&quot; ...
##  $ EXAMINER     : chr  &quot;bxf258&quot; &quot;sjt82&quot; &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1928-01-11&quot; &quot;1941-05-02&quot; ...
##  $ AGE_AT_EXAM  : num  91 77 68 62 84 84 77 72 71 65 ...
##  $ REVIEW_DATE  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER     : logi  NA NA NA NA NA NA ...
##  $ TIME_A       : num  NA 70 56 93 71 71 NA 30 275 60 ...
##  $ TIME_AMISS   : num  -1 NA NA NA NA NA NA NA NA NA ...
##  $ ERR_A        : num  0 0 2 1 0 0 1 0 1 0 ...
##  $ ERR_AMISS    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COR_A        : num  24 24 22 23 24 24 23 24 24 24 ...
##  $ COR_AMISS    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TIME_B       : num  NA 225 124 109 240 240 NA 71 NA 90 ...
##  $ TIME_BMISS   : num  -1 NA NA NA NA NA NA NA -2 NA ...
##  $ ERR_B        : num  NA 4 0 0 0 0 NA 0 NA 0 ...
##  $ ERR_BMISS    : num  -1 NA NA NA NA NA NA NA -2 NA ...
##  $ COR_B        : num  NA 20 24 24 24 24 NA 24 NA 24 ...
##  $ COR_BMISS    : num  -1 NA NA NA NA NA NA NA -2 NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-3" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;AAAD_TRAILS&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-3" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 3

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    VARCHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)]
## [1] &quot;REVIEW_DATE&quot;

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## 2 vars

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-3" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, can ignore, since it has been converted in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2019-03-07    1928-01-11
## 2 2019-03-08    1941-05-02
## 3 2019-03-04    1950-03-25
## 4 2019-03-08    1956-10-19
## 5 2019-03-07    1934-11-07
## 6 2019-03-07    1934-12-03</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-3" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 8 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-75daebb6940e8eb3f2f0" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-75daebb6940e8eb3f2f0">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="handling-numeric-variables-3" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 23 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                  &quot;1 thru 99999;&quot;     &quot;1 thru 9999;&quot;     
## [4] &quot;0 thru 150;&quot;       &quot;-1;\r\n-2;\r\n-3;&quot; &quot;0 thru 40;&quot;       
## [7] &quot;0 thru 24;&quot;        &quot;0 thru 300;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-8ebaddd40b0de10b883e" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-8ebaddd40b0de10b883e">{"x":{"filter":"none","vertical":false,"data":[["GP","TIME_A","COR_A","TIME_B","COR_B"],["GP","TIME_A","COR_A","TIME_B","COR_B"],["104406, 104422, 104435, 104437, 104411, 104418, 104407, 104445, 104427, 104415, 104410, 104428, 104438, 104419, 104409, 104446, 104408, 104431, 104432, 104439, 104420, 104423, 104424, 104442, 104412, 104426, 104405, 104403, 104425, 104413, 104443, 104436, 104430, 104421, 104433, 104402, 104416","275, 180, 187, 190, 195, 205, 170, 300, 160, 188, 159, 169, 165","25","400, 302, 341, 328, 383, 326, 590, 316","25"],["1 - 99999","0 - 150","0 - 24","0 - 300","0 - 24"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP and IND
## need to contact Mike about other variables: TIME_A, TIME_B, COR_B</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-3" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>AAAD_TRAILS &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_b9_judge_rc" class="section level2">
<h2>ALZ_B9_JUDGE_RC</h2>
<pre class="r"><code>df &lt;- ALZ_B9_JUDGE_RC

info(ALZ_B9_JUDGE_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:483, cols:82, inds:481</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    483 obs. of  82 variables:
##  $ SYSXM                  : num  8276003 8276013 8258753 8259063 8277553 ...
##  $ SYSIND                 : num  11620433 11160523 11034403 11369813 11620763 ...
##  $ SYSGP                  : num  8005513 7923793 7888823 7952013 8005723 ...
##  $ SYSGPSTUDY             : num  1452223 1361903 1304163 1397123 1452433 ...
##  $ SYSINDGP               : num  8389503 7923633 7790023 8139083 8389833 ...
##  $ CGI_ORDER              : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER              : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER           : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                 : chr  &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER               : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                  : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY               : chr  &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER                 : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                     : num  104507 87883 87556 88301 104457 ...
##  $ IND                    : num  1 1 9001 1 1 ...
##  $ REFCTR                 : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE              : POSIXct, format: &quot;2023-08-09&quot; &quot;2024-02-14&quot; ...
##  $ EXAMINER               : chr  &quot;jjs2031&quot; &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH          : POSIXct, format: &quot;1944-06-21&quot; &quot;1939-03-20&quot; ...
##  $ AGE_AT_EXAM            : num  79 84 68 76 76 81 86 73 86 66 ...
##  $ REVIEW_DATE            : logi  NA NA NA NA NA NA ...
##  $ REVIEWER               : logi  NA NA NA NA NA NA ...
##  $ MEMORY_DECLINE         : num  0 1 0 0 1 0 1 0 0 1 ...
##  $ COP_RPT_MEMDECLINE     : num  8 1 0 0 8 8 0 0 0 1 ...
##  $ MEANINGFUL_IMP         : num  0 1 0 0 1 0 1 0 0 1 ...
##  $ IMP_MEMORY             : num  NA 1 NA NA 1 NA 1 NA NA 1 ...
##  $ IMP_ORIENTATION        : num  NA 0 NA NA 1 NA 0 NA NA 1 ...
##  $ IMP_EXEC_FUNC          : num  NA 0 NA NA 1 NA 0 NA NA 1 ...
##  $ IMP_LANGUAGE           : num  NA 0 NA NA 0 NA 0 NA NA 0 ...
##  $ IMP_VISUOSPATIAL       : num  NA 0 NA NA 0 NA 0 NA NA 0 ...
##  $ IMP_ATTENTION          : num  NA 0 NA NA 0 NA 0 NA NA 1 ...
##  $ IMP_FLUCTUATING_COG    : num  NA 0 NA NA 0 NA 0 NA NA 0 ...
##  $ IMP_FLUCTUATING_AGE    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ IMP_OTHER              : num  NA 0 NA NA 0 NA 0 NA NA 0 ...
##  $ IMP_OTH_SPECIFY        : chr  NA NA NA NA ...
##  $ IMP_PREDOMINANT_SYMP   : num  NA 1 NA NA 1 NA 1 NA NA 1 ...
##  $ IMP_PRED_SYMP_OTH      : chr  NA NA NA NA ...
##  $ IMP_MODE_ONSET         : num  NA 1 NA NA 1 NA 1 NA NA 1 ...
##  $ MODE_ONSET6A           : logi  NA NA NA NA NA NA ...
##  $ BEGIN_AGE              : num  NA 83 NA NA 76 NA 86 NA NA 63 ...
##  $ BEHAV_SYMPTOMS         : num  0 1 0 0 0 0 0 0 0 1 ...
##  $ BS_APATHY              : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_DEPRESSED           : num  NA 1 NA NA NA NA NA NA NA 1 ...
##  $ BS_VISUAL_HAL          : num  NA 1 NA NA NA NA NA NA NA 0 ...
##  $ HAL_WELL_INFORMED      : num  NA 1 NA NA NA NA NA NA NA NA ...
##  $ HAL_BEGIN_AGE          : num  NA 83 NA NA NA NA NA NA NA NA ...
##  $ AUDITORY_HAL           : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ ABN_BELIEFS            : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_DISINIBITION        : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_IRRITABILITY        : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_AGITATION           : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_PERSONAL_CHG        : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_REM                 : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ REM_BEGIN_AGE          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BS_ANXIETY             : num  NA 1 NA NA NA NA NA NA NA 0 ...
##  $ BS_OTHER               : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ BS_OTHER_SPEC          : chr  NA NA NA NA ...
##  $ BS_PREDOMINANT_SYMP    : num  NA 2 NA NA NA NA NA NA NA 2 ...
##  $ BS_PRED_SYMP_OTH       : chr  NA NA NA NA ...
##  $ BS_MODE_ONSET          : num  NA 1 NA NA NA NA NA NA NA 2 ...
##  $ BS_MODE_ONSET_OTH      : chr  NA NA NA NA ...
##  $ BS_BEGIN_AGE           : num  NA 74 NA NA NA NA NA NA NA 63 ...
##  $ MOTOR_SYPTOMS          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ MS_GAIT1               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_FALLS1              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_TREMOR1             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_SLOWNESS1           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_PRED_SYMPTOM        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_MODE_ONSET          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_MODE_ONSET_OTH      : chr  NA NA NA NA ...
##  $ MS_PARKINSONISM        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PARK_BEGIN_AGE         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_ALS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MS_ALS_BEGIN_AGE       : logi  NA NA NA NA NA NA ...
##  $ MS_BEGIN_AGE           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OVERALL_COURSE_DEC     : num  8 1 8 8 1 8 8 8 8 1 ...
##  $ PRED_DOMAIN            : num  8 2 8 8 1 8 8 8 8 1 ...
##  $ LBD_CANDIDATE          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ FLD_CANDIDATE          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ NOTES_B9JUDGE          : chr  NA NA NA NA ...
##  $ TOTALSCORE_B9_Q9       : num  0 3 0 0 0 0 0 0 0 1 ...
##  $ TOTALSCORE_B9_Q9_STATUS: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-4" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_B9_JUDGE_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-4" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 5 × 2
##   VarNames         `Data Type`  
##   &lt;chr&gt;            &lt;chr&gt;        
## 1 REFCTR           VARCHAR2(6)  
## 2 REVIEW_DATE      date         
## 3 REVIEWER         VARCHAR      
## 4 MODE_ONSET6A     VARCHAR2(100)
## 5 MS_ALS_BEGIN_AGE NUMBER(3)</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)] ## MS_ALS_BEGIN_AGE

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;       &quot;REVIEWER&quot;     &quot;MODE_ONSET6A&quot;

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-4" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-08-09    1944-06-21
## 2 2024-02-14    1939-03-20
## 3 2023-06-22    1954-08-20
## 4 2024-02-13    1947-05-13
## 5 2023-04-17    1946-12-19
## 6 2024-02-15    1942-09-30</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-4" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 17 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)

mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-99d97e080d45401b8406" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-99d97e080d45401b8406">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="handling-numeric-variables-4" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 62 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>##  [1] NA                                                                
##  [2] &quot;1 thru 99999;&quot;                                                   
##  [3] &quot;1 thru 9999;&quot;                                                    
##  [4] &quot;0;\r\n1;\r\n8;&quot;                                                  
##  [5] &quot;0;\r\n1;&quot;                                                        
##  [6] &quot;0;\r\n1;\r\n9;&quot;                                                  
##  [7] &quot;15 thru 110;&quot;                                                    
##  [8] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;\r\n8;\r\n99;&quot;             
##  [9] &quot;1;\r\n2;\r\n3;\r\n4;\r\n99;&quot;                                     
## [10] &quot;15 through 110;&quot;                                                 
## [11] &quot;15 through 110;\r\n888;&quot;                                         
## [12] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;\r\n8;\r\n9;\r\n10;\r\n99;&quot;
## [13] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n8;\r\n9;&quot;                          
## [14] &quot;1;\r\n2;\r\n3;\r\n8;\r\n9;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-cf031b34c3ae457b46dd" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-cf031b34c3ae457b46dd">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104507, 104457, 104540, 104476, 104528, 104556, 104455, 104511, 104549, 104552, 104452, 104525, 104497, 104531, 104518, 104472, 104469, 104521, 104499, 104514, 104496, 104487, 104515, 104490, 104453, 104526, 104548, 104454, 104513, 104554, 104456, 105805, 104471, 104459, 104516, 104463, 105806, 104477, 104466, 104529, 104500, 104460, 104464, 105803, 104486, 104498, 105817, 105825, 105827, 104572, 104564, 104468, 104535, 105809, 104582, 104542, 104461, 105807, 105815, 105808, 105822, 105814, 104485, 104495, 104578, 104575, 104447, 104474, 105826, 104550, 104574, 104573, 105824, 104545, 104570, 104527, 104583, 104519, 104510, 104590, 104591, 104581, 104473, 104480, 104544, 105813, 105821, 104482, 105816, 104568, 104563, 104484, 104571, 104557, 104494, 104565, 104569, 104508, 104475, 105819, 104536, 105812, 104541, 104479, 105811, 104505, 104509, 104579, 104555, 104470, 104561, 104520, 104566, 104448, 104502, 104567, 104580, 104533, 104451, 104478, 105810, 104534, 104450, 104547, 104584, 104458, 104449, 104560, 104483, 105820, 105823, 104605, 104636, 104662, 104650, 104652, 104666, 104632, 104659, 104640, 104658, 104651, 104660, 104501, 104612, 104614, 104623, 104656, 104655, 104621, 104617, 104683, 104685, 104681, 104517, 104604, 104619, 105829, 104668, 104643, 104657, 105834, 104602, 104644, 104680, 104645, 104665, 104688, 104599, 104616, 104537, 104669, 104648, 104633, 104663, 104672, 104696, 104638, 104631, 104522, 104667, 104592, 104698, 104701, 104593, 105833, 104682, 104686, 104634, 104630, 104611, 104646, 105828, 105830, 104606, 104622, 104647, 104608, 105832, 104637, 105831, 104639, 104661, 104629, 104558, 104654, 104624, 104594, 104538, 104620, 104642, 104684, 104504, 104607, 104673, 104677, 104503, 104641, 104626, 104699, 104613, 104714, 105838, 104708, 104713, 104704, 104710, 104717, 104724, 104725, 104746, 104734, 104781, 104775, 104758, 104742, 104735, 104674, 104743, 104723, 104712, 104709, 104754, 104737, 104738, 104744, 104703, 104769, 104751, 104771, 104763, 104627, 104702, 104628, 104700, 104721, 104722, 104711, 104706, 104719, 104720, 104729, 104730, 104778, 104695, 104765, 104783, 104727, 104715, 104718, 104761, 104762, 104770, 104728, 104726, 104768, 104764, 104777, 104625, 104675, 104747, 104690, 104748, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-4" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_B9_JUDGE_RC&lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_clinicalsum" class="section level2">
<h2>ALZ_CLINICALSUM</h2>
<pre class="r"><code>df &lt;- ALZ_CLINICALSUM

info(ALZ_CLINICALSUM,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1484, cols:39, inds:1480</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    1484 obs. of  39 variables:
##  $ SYSXM            : num  8063903 8066823 8067393 8065353 8058883 ...
##  $ SYSIND           : num  11493593 11493813 11493613 11493363 11493633 ...
##  $ SYSGP            : num  7946353 7946353 7946353 7946353 7946353 ...
##  $ SYSGPSTUDY       : num  1387463 1387463 1387463 1387463 1387463 ...
##  $ SYSINDGP         : num  8262663 8262883 8262683 8262433 8262703 ...
##  $ CGI_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER     : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY           : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER         : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY            : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY         : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER           : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP               : num  87545 87545 87545 87545 87545 ...
##  $ IND              : num  9026 1024 144 124 148 ...
##  $ REFCTR           : logi  NA NA NA NA NA NA ...
##  $ DATE_OF_BIRTH    : POSIXct, format: &quot;1973-01-14&quot; &quot;1941-04-03&quot; ...
##  $ LAST_CONTACT_DATE: logi  NA NA NA NA NA NA ...
##  $ LAST_CONTACT_AGE : logi  NA NA NA NA NA NA ...
##  $ AGE_OF_DEATH     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ AGE_OF_EXAM      : num  49 80 67 77 64 75 78 61 71 82 ...
##  $ IMPRESSION       : chr  &quot;Affected By Exam&quot; &quot;Affected By Exam&quot; &quot;Affected By Exam&quot; &quot;Affected By Exam&quot; ...
##  $ AD_CATEGORY      : chr  &quot;No Data&quot; &quot;No Data&quot; &quot;No Data&quot; &quot;Definite AD (Exam)&quot; ...
##  $ AGE_OF_ONSET     : num  43 79 65 57 61 73 71 60 65 75 ...
##  $ AOO_DOC_EST_UNK  : chr  &quot;E&quot; &quot;E&quot; &quot;E&quot; &quot;E&quot; ...
##  $ AGE_OF_DIAGNOSIS : num  NA 79 65 57 64 NA 73 NA 65 75 ...
##  $ AODX_UNKNOWN     : chr  &quot;U&quot; NA NA NA ...
##  $ AD_HX_CATEGORY   : chr  NA NA NA NA ...
##  $ UNCLEAR_CATEGORY : chr  NA NA NA NA ...
##  $ DEMENT_NAME      : chr  NA NA NA NA ...
##  $ CLINICAL_EXAMINER: chr  &quot;katrina/DR. VANCE&quot; &quot;JOSE&quot; &quot;JOSE&quot; &quot;Jose Sanchez&quot; ...
##  $ FOLLOW_UP        : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ AUTOPSY_DISCUSSED: chr  &quot;ND&quot; &quot;N&quot; &quot;ND&quot; &quot;Y&quot; ...
##  $ AUTOPSY_PLANNED  : chr  &quot;ND&quot; &quot;N&quot; &quot;ND&quot; &quot;N&quot; ...
##  $ VERIFY_DATE      : POSIXct, format: NA NA ...
##  $ VERIFY_USER      : chr  NA NA NA &quot;Jose Javier Sanchez&quot; ...
##  $ COMMENTS         : chr  NA NA NA NA ...
##  $ FORM_DATE        : POSIXct, format: &quot;2022-03-29&quot; &quot;2022-03-30&quot; ...
##  $ FILLED_OUT_BY    : chr  &quot;kxc672&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-5" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_CLINICALSUM&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-5" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] 

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames          `Data Type`
##   &lt;chr&gt;             &lt;chr&gt;      
## 1 REFCTR            VARCHAR2(6)
## 2 LAST_CONTACT_DATE DATE       
## 3 LAST_CONTACT_AGE  NUMBER(2)</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)] ## LAST_CONTACT_AGE

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## LAST_CONTACT_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## REFCTR

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-5" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;DATE_OF_BIRTH&quot; &quot;VERIFY_DATE&quot;   &quot;FORM_DATE&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;LAST_CONTACT_DATE&quot; can ignore LAST_CONTACT_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;LAST_CONTACT_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##   DATE_OF_BIRTH VERIFY_DATE  FORM_DATE
## 1    1973-01-14        &lt;NA&gt; 2022-03-29
## 2    1941-04-03        &lt;NA&gt; 2022-03-30
## 3    1955-02-08        &lt;NA&gt; 2022-03-28
## 4    1945-02-17  2022-05-18 2022-03-28
## 5    1958-03-11  2022-05-05 2022-03-29
## 6    1947-02-05  2022-05-05 2022-03-29</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-5" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 20 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## [1] &quot;IMPRESSION&quot;       &quot;AD_CATEGORY&quot;      &quot;AD_HX_CATEGORY&quot;   &quot;UNCLEAR_CATEGORY&quot;
## after checking the unique values of variables in the mismatchChrs_1, I believe that they all should be characters
## so I updated the DD for those variables (I changed their data type in DD and switch the values from &quot;Valid Responses&quot; and &quot; Valid Responses Codes&quot; columns)

mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-56c6c6ed911823f3b21f" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-56c6c6ed911823f3b21f">{"x":{"filter":"none","vertical":false,"data":[["IMPRESSION","AD_CATEGORY","AD_HX_CATEGORY","UNCLEAR_CATEGORY","FILLED_OUT_BY"],["IMPRESSION","AD_CATEGORY","AD_HX_CATEGORY","UNCLEAR_CATEGORY","FILLED_OUT_BY"],["Affected By Exam, Affected By History, Unclear, Unaffected By Exam, Normal By Screen, Unaffected By History, No Data","Definite AD (Exam), Probable AD (Exam), Possible AD (Exam)","Probable AD (History), Possible AD (History), Definite AD (History)","Unclear - MCI, Unclear - Other, Unclear - Demented, Unclear By Screen","kxc672, jjs2031, Celis, Katrina, avg55, v.rodriguez4, prm72, sjt82, mxc2207, axr1589, ALEJANDRA RODRIGUEZ, mxp1257, ERIKA NEGRO, bxf258, plb50, fxs121, jmv184, ALEJANDRA BETACOURT, ascott2, MICHAEL P, Dr Feliciano, pxg275, alejandra betancourt, axl4132, erika negro, Erika Negro, michael p, michael prough, Michael Prough, Dr. Feliciano, MICHAEL PROUGH, gmh86, j.delvilla, M. Prough, Celis, Katrina; Anto"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## the descrption for variable FILLED_OUT_BY mentioned this is Dropdown style for people to select, so I belive that multiple values are fine</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-5" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 15 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-e531d083ed0fbf57374f" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-e531d083ed0fbf57374f">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104405, 104418, 104420, 104422, 104428, 104435, 104437, 104438, 104446, 104419, 104424, 104415, 104410, 104423, 104409, 104426, 104411, 104408, 104407, 104432, 104439, 104442, 104445, 104427, 104431, 104406, 104412"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-5" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_CLINICALSUM&lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_csdd" class="section level2">
<h2>ALZ_CSDD</h2>
<pre class="r"><code>df &lt;- ALZ_CSDD

info(ALZ_CSDD,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:181, cols:42, inds:176</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    181 obs. of  42 variables:
##  $ SYSXM           : num  7555573 7557803 7551403 7550933 7551073 ...
##  $ SYSIND          : num  11006333 11039713 11048273 11063923 11048283 ...
##  $ SYSGP           : num  7888683 7896183 7894423 7894423 7894423 ...
##  $ SYSGPSTUDY      : num  1304023 1311503 1309743 1309743 1309743 ...
##  $ SYSINDGP        : num  7761133 7795453 7804133 7822853 7804143 ...
##  $ CGI_ORDER       : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER       : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER    : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY          : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER        : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY           : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY        : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER          : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP              : num  87535 87657 87650 87650 87650 ...
##  $ IND             : num  1001 1 105 110 106 ...
##  $ REFCTR          : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE       : POSIXct, format: &quot;2018-04-13&quot; &quot;2018-04-17&quot; ...
##  $ EXAMINER        : chr  &quot;axr1589&quot; &quot;axr1589&quot; &quot;axr1589&quot; &quot;axr1589&quot; ...
##  $ DATE_OF_BIRTH   : POSIXct, format: &quot;1932-02-20&quot; &quot;1947-04-23&quot; ...
##  $ AGE_AT_EXAM     : num  86 70 77 86 82 87 87 85 75 80 ...
##  $ ANXIETY         : num  2 0 0 0 0 2 -1 0 2 1 ...
##  $ SADNESS         : num  0 0 0 0 0 0 -1 2 0 1 ...
##  $ LACK_REACTION   : num  0 1 2 0 0 -1 -1 0 1 1 ...
##  $ IRRITABILITY    : num  1 0 0 2 0 0 -1 0 2 1 ...
##  $ AGITATION       : num  1 0 0 0 0 2 -1 0 1 0 ...
##  $ RETARDATION     : num  0 2 1 1 0 2 -1 0 0 1 ...
##  $ MULTI_COMPLAINTS: num  2 0 1 2 0 -1 -1 0 1 1 ...
##  $ LOSS_INTEREST   : num  1 0 2 0 0 -1 -1 0 2 0 ...
##  $ LOSS_APPETITE   : num  0 1 1 1 0 2 -1 1 1 1 ...
##  $ LOSS_WEIGHT     : num  0 0 2 2 1 2 -1 -1 1 0 ...
##  $ LACK_ENERGY     : num  2 0 2 1 1 2 -1 2 2 1 ...
##  $ DIURNAL_MOOD    : num  1 0 0 -1 0 2 -1 0 -1 0 ...
##  $ DIFF_ASLEEP     : num  0 0 0 0 0 2 -1 0 0 1 ...
##  $ MULTI_AWAKEN    : num  0 1 1 0 0 2 -1 0 0 0 ...
##  $ EARLY_AWAKEN    : num  0 0 1 0 1 0 -1 0 1 0 ...
##  $ SUICIDAL        : num  0 0 0 0 0 -1 -1 0 -1 0 ...
##  $ SELF_ESTEEM     : num  0 0 0 0 0 -1 -1 0 -1 0 ...
##  $ PESSIMISM       : num  0 0 0 0 0 -1 -1 0 -1 0 ...
##  $ MOOD_DELUSIONS  : num  0 0 0 0 0 -1 -1 0 -1 0 ...
##  $ NOTES_MEDS      : chr  NA NA NA NA ...
##  $ CSDD_SCORE      : num  10 5 13 9 3 18 0 5 14 9 ...
##  $ CSDD_COUNT      : num  19 19 19 18 19 12 0 18 14 19 ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-6" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_CSDD&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-6" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 1

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 1 × 2
##   VarNames `Data Type`
##   &lt;chr&gt;    &lt;chr&gt;      
## 1 REFCTR   VARCHAR2(6)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- c(&quot;REFCTR&quot;)

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-6" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2018-04-13    1932-02-20
## 2 2018-04-17    1947-04-23
## 3 2018-03-15    1940-06-24
## 4 2018-04-03    1931-07-01
## 5 2018-04-03    1935-05-25
## 6 2018-04-24    1930-06-19</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-6" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 8 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-73854ff44fad61073f0e" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-73854ff44fad61073f0e">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="handling-numeric-variables-6" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 32 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                      &quot;1 thru 99999;&quot;         &quot;1 thru 9999;&quot;         
## [4] &quot;-1;\r\n0;\r\n1;\r\n2;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-d08e04644922bb8d516b" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-d08e04644922bb8d516b">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104405"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-6" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_CSDD &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_exam" class="section level2">
<h2>ALZ_EXAM</h2>
<pre class="r"><code>df &lt;- ALZ_EXAM

info(ALZ_EXAM,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:526, cols:80, inds:522</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    526 obs. of  80 variables:
##  $ SYSXM               : num  7541263 7541363 7541493 7540523 7541543 ...
##  $ SYSIND              : num  11109753 11109763 11109783 11048913 11109793 ...
##  $ SYSGP               : num  7921103 7921113 7921133 7896183 7921143 ...
##  $ SYSGPSTUDY          : num  1359213 1359223 1359243 1311503 1359253 ...
##  $ SYSINDGP            : num  7869273 7869283 7869303 7804773 7869313 ...
##  $ CGI_ORDER           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER        : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY              : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER            : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY               : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY            : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER              : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                  : num  87787 87788 87790 87657 87791 ...
##  $ IND                 : num  1 1 1 102 1 1 1 1 1 1 ...
##  $ REFCTR              : logi  NA NA NA NA NA NA ...
##  $ FORM_DATE           : POSIXct, format: &quot;2018-03-06&quot; &quot;2018-03-06&quot; ...
##  $ FILLED_OUT_BY       : chr  &quot;v.rodriguez4&quot; &quot;bxf258&quot; &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; ...
##  $ DATE_OF_BIRTH       : POSIXct, format: &quot;1950-06-30&quot; &quot;1956-12-21&quot; ...
##  $ NEURO_METHOD        : chr  &quot;E&quot; &quot;E&quot; &quot;E&quot; &quot;E&quot; ...
##  $ NEURO_EXAM_DATE     : POSIXct, format: &quot;2018-03-06&quot; &quot;2018-03-06&quot; ...
##  $ NEURO_EXAMINER      : chr  &quot;vanessa r&quot; &quot;briseida felicia&quot; &quot;vanessa&quot; &quot;Vanessa&quot; ...
##  $ MOOD_AFFECT         : chr  &quot;N&quot; &quot;N&quot; &quot;A&quot; &quot;N&quot; ...
##  $ DEPRESSED           : chr  NA NA &quot;Y&quot; NA ...
##  $ MANIC               : chr  NA NA &quot;N&quot; NA ...
##  $ MOOD_OTHER          : chr  NA NA &quot;N&quot; NA ...
##  $ MOOD_OTHER_DSC      : chr  NA NA NA NA ...
##  $ SPEECH              : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ DYSARTHRIA          : chr  NA NA NA NA ...
##  $ DYSPHASIA           : chr  NA NA NA NA ...
##  $ SPEECH_OTHER        : chr  NA NA NA NA ...
##  $ SPEECH_OTHER_DSC    : chr  NA NA NA NA ...
##  $ FACIAL_EXPRESSION   : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ MASKED_FACE         : chr  NA NA NA NA ...
##  $ FACIAL_OTHER        : chr  NA NA NA NA ...
##  $ FACIAL_OTHER_DSC    : chr  NA NA NA NA ...
##  $ OCULAR_MOVEMENT     : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ IMPAIRED_UPGAZE     : chr  NA NA NA NA ...
##  $ OCULAR_OTHER        : chr  NA NA NA NA ...
##  $ OCULAR_OTHER_DSC    : chr  NA NA NA NA ...
##  $ BRADY               : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BRADY_GLOBAL        : chr  NA NA NA NA ...
##  $ SLOWED_RAMS         : chr  NA NA NA NA ...
##  $ BRADY_OTHER         : chr  NA NA NA NA ...
##  $ BRADY_OTHER_DSC     : chr  NA NA NA NA ...
##  $ TREMOR              : chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ TREMOR_RESTING      : chr  &quot;N&quot; NA NA NA ...
##  $ TREMOR_ACTION       : chr  &quot;Y&quot; NA NA NA ...
##  $ GAIT                : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ DECR_ARM_SWING      : chr  NA NA NA NA ...
##  $ SHUFFLING           : chr  NA NA NA NA ...
##  $ MULTI_STEP          : chr  NA NA NA NA ...
##  $ GAIT_OTHER          : chr  NA NA NA NA ...
##  $ GAIT_OTHER_DSC      : chr  NA NA NA NA ...
##  $ POST_STABILITY      : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ MOTOR_TONE          : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ RIGIDITY            : chr  NA NA NA NA ...
##  $ COGWHEELING         : chr  NA NA NA NA ...
##  $ SPASTICITY          : chr  NA NA NA NA ...
##  $ FLACCIDITY          : chr  NA NA NA NA ...
##  $ MOTOR_ASYM          : chr  &quot;ND&quot; &quot;ND&quot; &quot;ND&quot; &quot;ND&quot; ...
##  $ REFLEXES_ASYM       : chr  &quot;ND&quot; &quot;N&quot; &quot;ND&quot; &quot;ND&quot; ...
##  $ REFLEXES_HYPERACTIVE: chr  &quot;ND&quot; &quot;N&quot; &quot;ND&quot; &quot;ND&quot; ...
##  $ REFLEXES_DECREASED  : chr  &quot;ND&quot; &quot;N&quot; &quot;ND&quot; &quot;ND&quot; ...
##  $ BABINSKI            : chr  &quot;ND&quot; &quot;N&quot; &quot;ND&quot; &quot;ND&quot; ...
##  $ CLIN_METHOD         : chr  &quot;E&quot; &quot;E&quot; &quot;E&quot; &quot;E&quot; ...
##  $ CLIN_EXAM_DATE      : POSIXct, format: &quot;2018-03-06&quot; &quot;2018-03-06&quot; ...
##  $ CLIN_EXAMINER       : chr  &quot;vanessa r&quot; &quot;briseida&quot; NA &quot;Vanessa&quot; ...
##  $ PROG_APHASIA        : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ AMNESIA             : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ LUNG_DX             : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ PREV_ARREST         : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ SUBSTANCE_ABUSE     : chr  &quot;Y&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ SURGERY             : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ VAS_DEMENTIA        : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ PSY_DISORDER        : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ FLUCT_COGNITION     : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ DOPAMINE            : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ DOPA_CURRENT        : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ NEUROLEPTIC         : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;U&quot; ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-7" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_EXAM&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-7" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 1 × 2
##   VarNames `Data Type`
##   &lt;chr&gt;    &lt;chr&gt;      
## 1 REFCTR   VARCHAR2(6)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;-c(&quot;REFCTR&quot;)

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-7" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;FORM_DATE&quot;       &quot;DATE_OF_BIRTH&quot;   &quot;NEURO_EXAM_DATE&quot; &quot;CLIN_EXAM_DATE&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    FORM_DATE DATE_OF_BIRTH NEURO_EXAM_DATE CLIN_EXAM_DATE
## 1 2018-03-06    1950-06-30      2018-03-06     2018-03-06
## 2 2018-03-06    1956-12-21      2018-03-06     2018-03-06
## 3 2018-03-06    1946-10-29      2018-03-06     2018-03-06
## 4 2018-02-19    1946-01-11      2018-02-19     2018-02-19
## 5 2018-03-06    1949-10-06      2018-03-06     2018-03-06
## 6 2018-03-05    1938-11-06      2018-03-05     2018-03-05</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-7" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 66 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-35674f7996ebae152b62" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-35674f7996ebae152b62">{"x":{"filter":"none","vertical":false,"data":[["FILLED_OUT_BY","NEURO_METHOD"],["FILLED_OUT_BY","NEURO_METHOD"],["v.rodriguez4, bxf258, avg55, kxc672, axr1589, ALEJANDRA BETACOURT, ALEJANDRA, sjt82, prm72, NEREIDA FELICIANO, sek100, mxp1257, mpericak, mxc2207, Erika Negro, patricia manrique, pxg275, patricia m, jjs2031","M  E"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore NEURO_METHOD and FILLED_OUT_BY</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-7" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 10 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-876e9bf4fa47930249fe" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-876e9bf4fa47930249fe">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104425, 104402, 104403"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-7" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_EXAM &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_gai_sp" class="section level2">
<h2>ALZ_GAI_SP</h2>
<pre class="r"><code>df &lt;- ALZ_GAI_SP

info(ALZ_GAI_SP,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:19, cols:42, inds:19</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    19 obs. of  42 variables:
##  $ SYSXM               : num  8095923 8103313 8089823 8065953 8066073 ...
##  $ SYSIND              : num  11008753 11147113 11008763 11358523 11369753 ...
##  $ SYSGP               : num  7888993 7922413 7888993 7945143 7951963 ...
##  $ SYSGPSTUDY          : num  1304333 1360523 1304333 1386053 1397073 ...
##  $ SYSINDGP            : num  7763553 7910223 7763563 8127793 8139023 ...
##  $ CGI_ORDER           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER        : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY              : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER            : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY               : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY            : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER              : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                  : num  87577 87858 87577 88247 88316 ...
##  $ IND                 : num  9000 103 9001 1 1 ...
##  $ REFCTR              : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE           : POSIXct, format: &quot;2022-07-12&quot; &quot;2022-07-14&quot; ...
##  $ EXAMINER            : chr  &quot;mxc2207&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;mxc2207&quot; ...
##  $ DATE_OF_BIRTH       : POSIXct, format: &quot;1944-10-12&quot; &quot;1939-04-08&quot; ...
##  $ AGE_AT_EXAM         : num  77 83 61 75 85 81 71 80 52 62 ...
##  $ REVIEW_DATE         : logi  NA NA NA NA NA NA ...
##  $ REVIEWER            : logi  NA NA NA NA NA NA ...
##  $ WORRY_ALOT          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ DIFF_MAKE_DECISION  : num  1 0 0 0 0 0 0 1 0 1 ...
##  $ FEEL_JUMPY          : num  1 0 0 0 0 0 0 1 0 0 ...
##  $ HARD_TO_RELAX       : num  0 0 0 0 0 0 0 1 0 0 ...
##  $ CANNOT_ENJOY        : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ THINGS_BOTHER_ME    : num  1 0 0 0 0 0 0 0 0 1 ...
##  $ BUTTERFLIES         : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ WORRIER             : num  0 0 0 1 1 1 0 1 1 1 ...
##  $ RIVIAL_THINGS       : num  0 0 0 1 0 0 0 1 1 1 ...
##  $ OFTEN_NERVOUS       : num  1 1 0 0 1 0 0 0 1 0 ...
##  $ THOUGHTS_ANXIOUS    : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ UPSET_STOMACH       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ THINK_MYSELF_NERVOUS: num  0 0 0 1 0 0 0 1 0 0 ...
##  $ ANTICIPATE_WORST    : num  1 0 0 0 0 0 0 1 0 0 ...
##  $ FEEL_SHAKY          : num  1 0 0 0 0 0 0 1 0 0 ...
##  $ INTERFERE_WITH_LIFE : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ OVERWHELM           : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ FEEL_GREAT_KNOT     : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ MISS_OUT            : num  1 0 0 0 1 0 0 0 0 0 ...
##  $ FEEL_UPSET          : num  1 0 0 0 0 0 0 0 0 0 ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-8" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_GAI_SP&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-8" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    VARCHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;-c(&quot;REFCTR&quot;,&quot;REVIEWER&quot;)
convert2date &lt;- c(&quot;REVIEW_DATE&quot;)

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-8" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## &quot;REVIEW_DATE, ignore it, since it has been converted in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2022-07-12    1944-10-12
## 2 2022-07-14    1939-04-08
## 3 2022-07-12    1961-06-12
## 4 2022-04-01    1946-10-06
## 5 2022-03-31    1936-12-21
## 6 2022-03-30    1940-06-12</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-8" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)]
## [1] &quot;LSTUDY&quot;   &quot;DB_OWNER&quot; &quot;STUDY&quot;    &quot;SUBSTUDY&quot; &quot;CENTER&quot;   &quot;REFCTR&quot;   &quot;EXAMINER&quot; &quot;REVIEWER&quot;

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-a753a278b78baaac3a48" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a753a278b78baaac3a48">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["mxc2207, jjs2031, cmanrique"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER, as I assume we can have multiple examiners</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-8" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 31 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;\r\n0;\r\n&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<pre><code>## All numeric values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-46a97ab1fe10f872abee" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-46a97ab1fe10f872abee">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="save-cleaned-data-8" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_GAI_SP &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_load_cog" class="section level2">
<h2>ALZ_LOAD_COG</h2>
<pre class="r"><code>df &lt;- ALZ_LOAD_COG

info(ALZ_LOAD_COG,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1006, cols:41, inds:907</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    1006 obs. of  41 variables:
##  $ SYSXM         : num  7540463 7540813 7540903 7540593 7541233 ...
##  $ SYSIND        : num  11006263 11059623 11059693 11048913 11109753 ...
##  $ SYSGP         : num  7888673 7897223 7897223 7896183 7921103 ...
##  $ SYSGPSTUDY    : num  1304013 1312543 1312543 1311503 1359213 ...
##  $ SYSINDGP      : num  7761063 7818553 7818623 7804773 7869273 ...
##  $ CGI_ORDER     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER  : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY        : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER      : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY         : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY      : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER        : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP            : num  87534 87699 87699 87657 87787 ...
##  $ IND           : num  104 101 108 102 1 1 1 1 1 1 ...
##  $ REFCTR        : logi  NA NA NA NA NA NA ...
##  $ INTERVIEW_DATE: POSIXct, format: &quot;2018-02-21&quot; &quot;2018-02-18&quot; ...
##  $ INTERVIEWER   : chr  &quot;v.rodriguez4&quot; &quot;axr1589&quot; &quot;axr1589&quot; &quot;v.rodriguez4&quot; ...
##  $ DATE_OF_BIRTH : POSIXct, format: &quot;1936-09-20&quot; &quot;1929-10-08&quot; ...
##  $ INTERVIEW_AGE : num  81 88 68 72 67 61 68 68 79 65 ...
##  $ VERSION       : chr  &quot;2.0&quot; &quot;2.0&quot; &quot;2&quot; &quot;2.0&quot; ...
##  $ PHONE         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STORY         : num  6 3 4 6 18 19 9 1 9 12 ...
##  $ DIGFOR        : num  9 5 8 10 9 12 8 8 3 7 ...
##  $ DIGBAK        : num  6 5 7 4 7 6 4 0 2 5 ...
##  $ ANIMALS       : num  16 11 20 14 15 17 7 13 NA 13 ...
##  $ FRUITS        : logi  NA NA NA NA NA NA ...
##  $ VEG           : num  13 6 12 5 14 7 5 7 NA 6 ...
##  $ DIGORD        : num  7 2 4 5 8 8 7 0 NA 7 ...
##  $ DELAY         : num  8 0 6 3 12 17 7 0 NA 5 ...
##  $ HOWWELL       : num  NA NA 1 NA 1 1 1 9 1 1 ...
##  $ HEARIMP       : num  NA NA 2 NA 2 2 2 2 2 2 ...
##  $ STATUS        : num  1 1 1 1 1 1 1 1 4 1 ...
##  $ COMM          : chr  NA NA NA NA ...
##  $ ANIMALS_REP   : logi  NA NA NA NA NA NA ...
##  $ ANIMALS_INT   : logi  NA NA NA NA NA NA ...
##  $ VEG_REP       : logi  NA NA NA NA NA NA ...
##  $ VEG_INT       : logi  NA NA NA NA NA NA ...
##  $ DIGFOR_LEN    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DIGBAK_LEN    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DELAY_LEN     : num  NA NA NA NA NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-9" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_LOAD_COG&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-9" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] 

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 6 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 FRUITS      NUMBER     
## 3 ANIMALS_REP &lt;NA&gt;       
## 4 ANIMALS_INT &lt;NA&gt;       
## 5 VEG_REP     &lt;NA&gt;       
## 6 VEG_INT     &lt;NA&gt;</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;-c(&quot;REFCTR&quot;)
convert2num &lt;-c(&quot;FRUITS&quot;)

## for others, they are missing info in DD, I will leave them for now

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2num] &lt;- lapply(df[convert2chr], as.numeric)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;logical&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-9" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##   INTERVIEW_DATE DATE_OF_BIRTH
## 1     2018-02-21    1936-09-20
## 2     2018-02-18    1929-10-08
## 3     2018-02-19    1949-08-01
## 4     2018-02-19    1946-01-11
## 5     2018-03-06    1950-06-30
## 6     2018-03-06    1956-12-21</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;      &quot;logical&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-9" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 9 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-5fe2a3f145a6cbb38c14" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-5fe2a3f145a6cbb38c14">{"x":{"filter":"none","vertical":false,"data":[["INTERVIEWER"],["INTERVIEWER"],["v.rodriguez4, axr1589, michael p, bxf258, avg55, ALEJANDRA BETACOURT, kxc672, plb50, sjt82, prm72, MP, AS, M PROUGH, UCC, Cdel, OG, CDL, ascott2, ALEJANDRA, RMC, NEREIDA FELICIANO, erika, mxc2207, Erika Negro, pxg275, mxp1257, fxs121, A Grana, MICHAEL P, erica, jjs2031, axl4132, patricia m, jmv184, patricia manrique, cmanrique, Maricarmen Contreras"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore INTERVIEWER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-9" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 26 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>##  [1] NA                                                                     
##  [2] &quot;1 thru 99999;&quot;                                                        
##  [3] &quot;1 thru 9999;&quot;                                                         
##  [4] &quot;1;\r\n2;\r\n8;\r\n9;&quot;                                                 
##  [5] &quot;0 thru 25;\r\n96;\r\n97;\r\n98;\r\n99;&quot;                               
##  [6] &quot;0 thru 12;\r\n96;\r\n97;\r\n98;\r\n99;&quot;                               
##  [7] &quot;0 thru 75;\r\n96;\r\n97;\r\n98;\r\n99;&quot;                               
##  [8] &quot;0 thru 16;\r\n96;\r\n97;\r\n98;\r\n99;&quot;                               
##  [9] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n8;\r\n9;&quot;                               
## [10] &quot;1;\r\n2;&quot;                                                             
## [11] &quot;1;\r\n2;\r\n3;\r\n4;\r\n10;\r\n11;\r\n12;\r\n13;\r\n14;\r\n20;\r\n21;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-669bea34fec594f3db93" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-669bea34fec594f3db93">{"x":{"filter":"none","vertical":false,"data":[["GP","PHONE"],["GP","PHONE"],["104406, 104418, 104420, 104405, 104446, 104442, 104423, 104403, 104404, 104438, 104419, 104409, 104408, 104431, 104429, 104433, 104434, 104413, 104416, 104436, 104425, 104421, 104440, 104430, 104443, 104424, 104415, 104441, 104414, 104402, 104422, 104428, 104435, 104437, 104412, 104411, 104407, 104432, 104439, 104445, 104427, 104410, 104426","3"],["1 - 99999","1;2;8;9"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-9" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_LOAD_COG &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_ncrad" class="section level2">
<h2>ALZ_NCRAD</h2>
<pre class="r"><code>df &lt;- ALZ_NCRAD

info(ALZ_NCRAD,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:743, cols:53, inds:742</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    743 obs. of  53 variables:
##  $ SYSXM        : num  7895163 7879963 7879983 7880163 7880193 ...
##  $ SYSIND       : num  11218613 11041143 11041043 11039473 11005233 ...
##  $ SYSGP        : num  7928123 7894373 7894373 7896023 7888553 ...
##  $ SYSGPSTUDY   : num  1366233 1309693 1309693 1311343 1303893 ...
##  $ SYSINDGP     : num  7981883 7797003 7796903 7795213 7760033 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  87998 87502 87502 87506 87501 ...
##  $ IND          : num  1 102 100 1 1 1 1 1 1 1 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ QUALIFY      : chr  &quot;Unknown&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; ...
##  $ FORM_DATE    : POSIXct, format: &quot;2021-02-01&quot; &quot;2018-04-13&quot; ...
##  $ FILLED_OUT_BY: chr  &quot;sjt82&quot; &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; &quot;medical records&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1943-09-22&quot; &quot;1950-10-02&quot; ...
##  $ IN_NCRAD     : chr  NA NA NA NA ...
##  $ SAMPLED      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ EDUC         : num  14 12 16 9 12 1 5 16 3 15 ...
##  $ VISIT        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COMREQ       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NOTDEMCI     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ EVALMETH     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ EVALYR       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CLDEMLEW     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COMDXAD      : logi  NA NA NA NA NA NA ...
##  $ NONADDEM     : logi  NA NA NA NA NA NA ...
##  $ COMDXNAD     : logi  NA NA NA NA NA NA ...
##  $ AAOSYMP      : num  NA NA NA NA 1 1 NA NA NA NA ...
##  $ STROKETY     : logi  NA NA NA NA NA NA ...
##  $ STROKEAGE    : logi  NA NA NA NA NA NA ...
##  $ HYPERAGE     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HEARTAGE     : logi  NA NA NA NA NA NA ...
##  $ DIABETX      : logi  NA NA NA NA NA NA ...
##  $ DIABETAG     : logi  NA NA NA NA NA NA ...
##  $ PDCLINDX     : logi  NA NA NA NA NA NA ...
##  $ PDAGE        : logi  NA NA NA NA NA NA ...
##  $ DEPRTX       : logi  NA NA NA NA NA NA ...
##  $ DEPRAGE      : logi  NA NA NA NA NA NA ...
##  $ HEADAGE      : logi  NA NA NA NA NA NA ...
##  $ ABUSEAGE     : logi  NA NA NA NA NA NA ...
##  $ COM28_36     : logi  NA NA NA NA NA NA ...
##  $ COM_ANY      : chr  NA NA NA NA ...
##  $ CONTROL      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CONTYPE      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ RELDEM       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GENRSCH      : num  2 2 2 2 2 2 2 2 2 2 ...
##  $ UNCON_VAL    : logi  NA NA NA NA NA NA ...
##  $ UNCON_UNIT   : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-10" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_NCRAD&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-10" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 18 × 2
##    VarNames   `Data Type`  
##    &lt;chr&gt;      &lt;chr&gt;        
##  1 REFCTR     VARCHAR2(6)  
##  2 COMDXAD    VARCHAR2(255)
##  3 NONADDEM   NUMBER(2)    
##  4 COMDXNAD   VARCHAR2(255)
##  5 STROKETY   NUMBER(1)    
##  6 STROKEAGE  NUMBER(3)    
##  7 HEARTAGE   NUMBER(3)    
##  8 DIABETX    NUMBER(1)    
##  9 DIABETAG   NUMBER(3)    
## 10 PDCLINDX   NUMBER(1)    
## 11 PDAGE      NUMBER(3)    
## 12 DEPRTX     NUMBER(1)    
## 13 DEPRAGE    NUMBER(3)    
## 14 HEADAGE    NUMBER(3)    
## 15 ABUSEAGE   NUMBER(3)    
## 16 COM28_36   VARCHAR2(255)
## 17 UNCON_VAL  NUMBER(3)    
## 18 UNCON_UNIT VARCHAR2(7)</code></pre>
<pre class="r"><code>## converted to character
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`,ignore.case = T)] ## 13 vars
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)] ## 5 vars

## convert
df[convert2num] &lt;- lapply(df[convert2chr], as.numeric)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-10" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;FORM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    FORM_DATE DATE_OF_BIRTH
## 1 2021-02-01    1943-09-22
## 2 2018-04-13    1950-10-02
## 3 2020-04-23    1949-04-30
## 4 2016-11-17    1933-03-03
## 5 2019-05-22    1937-10-24
## 6 2020-09-17    1935-10-25</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-10" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 14 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-8e029ce71843eced3357" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-8e029ce71843eced3357">{"x":{"filter":"none","vertical":false,"data":[["FILLED_OUT_BY"],["FILLED_OUT_BY"],["sjt82, v.rodriguez4, medical records, mxc2207, Erika Negro, prm72, avg55, mxp1257, ERIKA NEGRO, jjs2031, axr1589, kxc672, Erika NEgro, medical record, axl4132, bxf258, erika negro, fxs121, plb50, ajennings, jmv184"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore FILLED_OUT_BY</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-10" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 37 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>##  [1] NA                                                                                                                 
##  [2] &quot;1 thru 99999;&quot;                                                                                                    
##  [3] &quot;1 thru 9999;&quot;                                                                                                     
##  [4] &quot;1;\r\n2;&quot;                                                                                                         
##  [5] &quot;0 thru 50;\r\n99;&quot;                                                                                                
##  [6] &quot;1 thru 50;\r\n98;&quot;                                                                                                
##  [7] &quot;1;\r\n2;\r\n3;\r\n9;&quot;                                                                                             
##  [8] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n9;&quot;                                                                           
##  [9] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;\r\n9;&quot;                                                                     
## [10] &quot;1930 thru 2020;\r\n9999;&quot;                                                                                         
## [11] &quot;1;\r\n2;\r\n9;&quot;                                                                                                   
## [12] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;\r\n8;\r\n9;\r\n10;\r\n11;\r\n12;\r\n13;\r\n14;\r\n15;\r\n16;\r\n17;\r\n99;&quot;
## [13] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;\r\n8;\r\n9;&quot;                                                               
## [14] &quot;1 thru 80;\r\n999;&quot;                                                                                               
## [15] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n9;&quot;                                                                                 
## [16] &quot;1;\r\n2;\r\n3;\r\n4;\r\n9;\r\n&quot;                                                                                   
## [17] &quot;1;\r\n2; \r\n3;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-7045adc12d6a2423e651" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-7045adc12d6a2423e651">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104406, 104422, 104428, 104435, 104437, 104446, 104411, 104408, 104418, 104407, 104445, 104427, 104438, 104415, 104419, 104409, 104421, 104431, 104432, 104439, 104420, 104423, 104424, 104442, 104412, 104426, 104405, 104433, 104403, 104429, 104444"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-10" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_NCRAD &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_neuro_cdr" class="section level2">
<h2>ALZ_NEURO_CDR</h2>
<pre class="r"><code>df &lt;- ALZ_NEURO_CDR

info(ALZ_NEURO_CDR,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1221, cols:30, inds:1102</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    1221 obs. of  30 variables:
##  $ SYSXM        : num  7540623 7540773 7546423 7546433 7546863 ...
##  $ SYSIND       : num  11048883 11059623 11044293 11011053 11046873 ...
##  $ SYSGP        : num  7896183 7897223 7894093 7889553 7894313 ...
##  $ SYSGPSTUDY   : num  1311503 1312543 1309413 1304893 1309633 ...
##  $ SYSINDGP     : num  7804743 7818553 7800153 7766073 7802733 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  87657 87699 87604 87580 87620 ...
##  $ IND          : num  1000 101 104 9010 101 106 110 1 102 1 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE    : POSIXct, format: &quot;2017-02-19&quot; &quot;2018-02-18&quot; ...
##  $ EXAMINER     : chr  &quot;axr1589&quot; &quot;axr1589&quot; &quot;avg55&quot; &quot;v.rodriguez4&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1923-04-17&quot; &quot;1929-10-08&quot; ...
##  $ AGE_AT_EXAM  : num  93 88 80 75 76 56 86 84 86 91 ...
##  $ METHOD       : chr  &quot;IP&quot; &quot;IP&quot; &quot;TE&quot; &quot;TE&quot; ...
##  $ RECONSTRUCTED: chr  &quot;U&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ CDR_TOTAL    : num  2 2 3 2 1 1 0.5 3 3 2 ...
##  $ MEMORY       : num  2 2 3 2 0.5 2 0.5 3 3 2 ...
##  $ ORIENTATION  : num  2 2 3 1 1 1 0.5 3 3 1 ...
##  $ PROBLEM_SOLVE: num  2 1 3 3 1 2 0 3 3 3 ...
##  $ COM_AFFAIR   : num  2 1 3 2 0.5 1 0 3 3 1 ...
##  $ HOME_HOBBIES : num  2 3 3 3 3 1 0.5 3 3 2 ...
##  $ PERSONAL_CARE: num  3 2 3 2 2 1 0 3 3 2 ...
##  $ CDR_COMM     : chr  NA NA &quot;Too impaired to complete patient portion.&quot; &quot;spoke with daughter about her mother, she is not able to keep a conversation. Barely functions with in the hous&quot;| __truncated__ ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-11" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_NEURO_CDR&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-11" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 1 × 2
##   VarNames `Data Type`
##   &lt;chr&gt;    &lt;chr&gt;      
## 1 REFCTR   VARCHAR2(6)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-11" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2017-02-19    1923-04-17
## 2 2018-02-18    1929-10-08
## 3 2018-03-16    1937-04-09
## 4 2018-03-20    1942-07-16
## 5 2018-03-06    1942-02-05
## 6 2018-04-03    1961-10-19</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-11" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 10 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2860ce5f0ee76d383b96" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2860ce5f0ee76d383b96">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["axr1589, avg55, v.rodriguez4, kxc672, sjt82, ascott2, prm72, bxf258, plb50, PEDRO MENA, OG, PM, AS, UCC, MP, M. prough, Patricia, erica, A Grana, Dr NIT, NEREIDA FELICIANO, M PROGUH, M PROUGH, PLB, mxc2207, Erika Negro, mxp1257, PATRICIA, pxg275, erika, Maricarmen Contreras, fxs121, erika negro, ERIKA NEGRO, mciliberti, ERIKA N, ERIKA, erika negron, ERIKA NEGRON, jjs2031, axl4132, mcuccaro, jmv184, joycelyn, gsv32, cmanrique"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore FILLED_OUT_BY</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-11" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 18 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                     &quot;1 thru 99999;&quot;        &quot;1 thru 9999;&quot;        
## [4] &quot;0.0 thru 3.4;\r\n-1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-8bed745e2e67f268ee18" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-8bed745e2e67f268ee18">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104418, 104420, 104405, 104422, 104406, 104442, 104445, 104427, 104410, 104426, 104423, 104438, 104419, 104409, 104431, 104408, 104424, 104439, 104415, 104428, 104435, 104437, 104446, 104412, 104411, 104407, 104432, 104443, 104425, 104404, 104403, 104429, 104433, 104413, 104434, 104436, 104430, 104402, 104441, 104444, 104421, 104440, 104401, 104416, 104414"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-11" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_NEURO_CDR &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_npiq_cbrs" class="section level2">
<h2>ALZ_NPIQ_CBRS</h2>
<pre class="r"><code>df &lt;- ALZ_NPIQ_CBRS

info(ALZ_NPIQ_CBRS,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:123, cols:116, inds:121</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    123 obs. of  116 variables:
##  $ SYSXM         : num  7545813 7557843 7550923 7551043 7558333 ...
##  $ SYSIND        : num  11039643 11039713 11063923 11048283 11039953 ...
##  $ SYSGP         : num  7896143 7896183 7894423 7894423 7896303 ...
##  $ SYSGPSTUDY    : num  1311463 1311503 1309743 1309743 1311623 ...
##  $ SYSINDGP      : num  7795383 7795453 7822853 7804143 7795693 ...
##  $ CGI_ORDER     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER  : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY        : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER      : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY         : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY      : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER        : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP            : num  87654 87657 87650 87650 87663 ...
##  $ IND           : num  1 1 110 106 1 ...
##  $ REFCTR        : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE     : POSIXct, format: &quot;2018-03-19&quot; &quot;2018-04-17&quot; ...
##  $ EXAMINER      : chr  &quot;avg55&quot; &quot;axr1589&quot; &quot;axr1589&quot; &quot;axr1589&quot; ...
##  $ DATE_OF_BIRTH : POSIXct, format: &quot;1933-06-05&quot; &quot;1947-04-23&quot; ...
##  $ AGE_AT_EXAM   : num  84 70 86 82 87 85 77 75 80 74 ...
##  $ NPIQINF       : chr  &quot;2&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ...
##  $ NPIQINF_PRO   : chr  NA NA NA NA ...
##  $ NPIQINF_OTH   : chr  NA NA NA NA ...
##  $ NPIQINFA      : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ NPIQINFB      : num  3 3 3 3 3 3 3 3 3 3 ...
##  $ NPIQTYPE      : num  2 1 1 1 1 2 1 1 1 1 ...
##  $ AGIT          : num  1 0 0 0 0 0 0 1 0 1 ...
##  $ AGITSEV       : num  1 NA NA NA NA NA NA 2 NA 1 ...
##  $ AGITATION_DIST: num  NA NA NA NA NA NA NA 5 NA 1 ...
##  $ DEPD          : num  1 0 0 0 0 1 0 0 1 0 ...
##  $ DEPDSEV       : num  1 NA NA NA NA 3 NA NA 2 NA ...
##  $ DEPRESS_DIST  : num  NA NA NA NA NA 5 NA NA 2 NA ...
##  $ ANX           : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ ANXSEV        : num  NA NA NA NA NA NA NA NA NA 2 ...
##  $ ANXIETY_DIST  : num  NA NA NA NA NA NA NA NA NA 4 ...
##  $ ELAT          : num  0 0 0 0 0 0 0 1 0 0 ...
##  $ ELATSEV       : num  NA NA NA NA NA NA NA 1 NA NA ...
##  $ ELATION_DIST  : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ APA           : num  0 0 0 0 1 0 0 0 1 0 ...
##  $ APASEV        : num  NA NA NA NA 3 NA NA NA 2 NA ...
##  $ APATHY_DIST   : num  NA NA NA NA 0 NA NA NA 2 NA ...
##  $ DISN          : num  0 0 0 0 0 0 0 1 0 1 ...
##  $ DISNSEV       : num  NA NA NA NA NA NA NA NA NA 2 ...
##  $ DISINHIB_DIST : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ IRR           : num  0 0 0 0 0 0 0 1 0 1 ...
##  $ IRRSEV        : num  NA NA NA NA NA NA NA 3 NA 2 ...
##  $ IRRIT_DIST    : num  NA NA NA NA NA NA NA 5 NA 5 ...
##  $ MOT           : num  1 0 0 0 0 0 0 0 0 1 ...
##  $ MOTSEV        : num  1 NA NA NA NA NA NA NA NA 3 ...
##  $ MOTOR_DIST    : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ NITE          : num  0 1 0 0 0 0 0 0 0 1 ...
##  $ NITESEV       : num  NA 2 NA NA NA NA NA NA NA 1 ...
##  $ NIGHTTIME_DIST: num  NA 2 NA NA NA NA NA NA NA 0 ...
##  $ APP           : num  1 1 1 0 1 0 0 0 0 1 ...
##  $ APPSEV        : num  2 2 1 NA 3 NA NA NA NA 3 ...
##  $ APPETITE_DIST : num  NA 0 0 NA 5 NA NA NA NA 2 ...
##  $ DEL           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ DELSEV        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DELUSION_DIST : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PARA          : num  0 0 0 0 0 0 NA NA NA 0 ...
##  $ PARAC         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PARAB         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PARAD         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HALL          : num  1 1 0 0 0 0 0 0 0 0 ...
##  $ HALLSEV       : num  1 1 NA NA NA NA NA NA NA NA ...
##  $ HALLUCIN_DIST : num  NA 0 NA NA NA NA NA NA NA NA ...
##  $ AUDHALL       : num  4 1 0 0 8 0 NA NA NA 0 ...
##  $ AUDHALLC      : num  NA NA NA NA 9 NA NA NA NA NA ...
##  $ AUDHALLB      : num  1 1 NA NA 1 NA NA NA NA NA ...
##  $ AUDHALLD      : num  0 0 NA NA 0 NA NA NA NA NA ...
##  $ VISHALL       : num  0 1 NA NA 8 9 NA NA NA NA ...
##  $ VISHALLB      : num  NA 1 NA NA 1 NA NA NA NA NA ...
##  $ VISHALLC      : num  NA NA NA NA 9 NA NA NA NA NA ...
##  $ VISHALLD      : num  NA 0 NA NA 0 NA NA NA NA NA ...
##  $ MISIDP        : num  2 0 9 9 9 9 NA NA NA 9 ...
##  $ MISIDPB       : num  1 NA NA NA NA NA NA NA NA NA ...
##  $ MISIDPC       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MISIDPD       : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ MISIDSEL      : num  0 0 9 9 9 9 NA NA NA 0 ...
##  $ MISIDSB       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MISIDSC       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MISIDSD       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MISIDT        : num  4 0 9 9 9 9 NA NA NA 0 ...
##  $ MISIDTB       : num  1 NA NA NA NA NA NA NA NA NA ...
##  $ MISIDTC       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MISIDTD       : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ INFID         : num  0 0 9 9 9 9 NA NA NA 9 ...
##  $ INFIDB        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ INFIDC        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ INFIDD        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ABND          : num  0 0 9 9 9 9 NA NA NA 0 ...
##  $ ABNDB         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ABNDC         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ABNDD         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ IMP           : num  0 0 9 9 9 9 NA NA NA 0 ...
##  $ IMPB          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ IMPC          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ IMPD          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TVR           : num  0 0 9 9 9 9 NA NA NA 0 ...
##  $ TVRB          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TVRC          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TVRD          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OPIH          : num  4 0 9 9 9 9 NA NA NA 0 ...
##  $ OPIHB         : num  1 NA NA NA NA NA NA NA NA NA ...
##  $ OPIHC         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OPIHD         : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ DPSA          : num  4 0 9 9 9 9 NA NA NA 0 ...
##  $ DPSAB         : num  9 NA NA NA NA NA NA NA NA NA ...
##  $ DPSAC         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DPSAD         : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ HNH           : num  2 0 9 9 9 9 NA NA NA 0 ...
##  $ HNHB          : num  1 NA NA NA NA NA NA NA NA NA ...
##  $ HNHC          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HNHD          : num  0 NA NA NA NA NA NA NA NA NA ...
##  $ INTQUAL       : num  0 0 0 0 0 0 NA NA NA 0 ...
##  $ NOTES         : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-12" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_NPIQ_CBRS&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-12" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 1 × 2
##   VarNames `Data Type`
##   &lt;chr&gt;    &lt;chr&gt;      
## 1 REFCTR   VARCHAR2(6)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-12" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2018-03-19    1933-06-05
## 2 2018-04-17    1947-04-23
## 3 2018-04-03    1931-07-01
## 4 2018-04-03    1935-05-25
## 5 2018-04-24    1930-06-19
## 6 2018-04-25    1933-03-11</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-12" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 11 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-8c3c2c4dabf437a14247" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-8c3c2c4dabf437a14247">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER","NPIQINF"],["EXAMINER","NPIQINF"],["avg55, axr1589, v.rodriguez4, kxc672, prm72, sjt82, mxc2207, mxp1257, bxf258, jjs2031, cmanrique","2  3  6, 2  7, 1  2, 2  6, 2  4"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore NPIQINF, since it can be multiple values as specified in the DD</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-12" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 103 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>##  [1] NA                                      
##  [2] &quot;1 thru 99999;&quot;                         
##  [3] &quot;1 thru 9999;&quot;                          
##  [4] &quot;0;\r\n1;&quot;                              
##  [5] &quot;1;\r\n2;\r\n3;&quot;                        
##  [6] &quot;1;\r\n2;&quot;                              
##  [7] &quot;1;\r\n0;&quot;                              
##  [8] &quot;0;\r\n1;\r\n2;\r\n3;\r\n4;\r\n5;&quot;      
##  [9] &quot;1;\r\n2;\r\n3;\r\n4;\r\n9;\r\n0;\r\n8;&quot;
## [10] &quot;1;\r\n2;\r\n3;\r\n4;\r\n9;&quot;            
## [11] &quot;0;\r\n1;\r\n9;&quot;                        
## [12] &quot;0;\r\n1;\r\n2;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-d956cc276db54026c664" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-d956cc276db54026c664">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104460"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-12" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_NPIQ_CBRS &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_rpfq" class="section level2">
<h2>ALZ_RPFQ</h2>
<pre class="r"><code>df &lt;- ALZ_RPFQ

info(ALZ_RPFQ,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:132, cols:67, inds:132</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    132 obs. of  67 variables:
##  $ SYSXM              : num  7895173 8010153 8011643 8012863 8001143 ...
##  $ SYSIND             : num  11218613 11109763 11447143 11458753 11248653 ...
##  $ SYSGP              : num  7928123 7921113 7968293 7974313 7931713 ...
##  $ SYSGPSTUDY         : num  1366233 1359223 1413403 1419423 1370023 ...
##  $ SYSINDGP           : num  7981883 7869283 8216213 8227823 8012383 ...
##  $ CGI_ORDER          : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER          : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER       : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY             : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER           : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY              : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY           : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER             : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                 : num  87998 87788 88462 88466 88118 ...
##  $ IND                : num  1 1 100 1 1 1 115 100 1 1 ...
##  $ REFCTR             : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE          : POSIXct, format: &quot;2021-02-01&quot; &quot;2021-11-15&quot; ...
##  $ EXAMINER           : chr  &quot;sjt82&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;mxc2207&quot; ...
##  $ DATE_OF_BIRTH      : POSIXct, format: &quot;1943-09-22&quot; &quot;1956-12-21&quot; ...
##  $ AGE_AT_EXAM        : num  77 64 70 72 77 63 76 72 83 71 ...
##  $ REVIEW_DATE        : logi  NA NA NA NA NA NA ...
##  $ REVIEWER           : logi  NA NA NA NA NA NA ...
##  $ SMOKE              : num  2 1 1 1 1 2 2 1 2 1 ...
##  $ SMOKE_AGE_START    : num  NA 15 15 16 12 NA NA 18 NA 20 ...
##  $ SMOKE_CURR         : num  NA 2 2 2 2 NA NA 2 NA 2 ...
##  $ SMOKE_AGE_STOP     : num  NA 64 40 68 73 NA NA 40 NA 50 ...
##  $ PREGNANCIES        : num  NA NA 6 2 NA NA 1 NA NA NA ...
##  $ LIVE_KIDS          : num  NA NA 4 2 NA NA 1 NA NA NA ...
##  $ HRT                : num  NA NA 2 2 NA NA 2 NA 9 NA ...
##  $ HRT_AGE_START      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HRT_AGE_STOP       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HRT_YEARS          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYSTERECTOMY       : num  NA NA 2 1 NA NA 2 NA 9 NA ...
##  $ HYSTERECTOMY_AGE   : num  NA NA NA 48 NA NA NA NA NA NA ...
##  $ OVARIES_RMV        : num  NA NA 2 2 NA NA 2 NA 9 NA ...
##  $ OVARIES_RMV_AGE    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OVARIES_RMV_BOTH   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HRT_OVR_RMV        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PHYSICAL_ACTIVITIES: num  NA 1 0 0 0 1 0 0 0 0 ...
##  $ NOPA_REASON        : num  NA NA 2 0 1 NA 0 1 1 1 ...
##  $ VA_PAST2W          : num  NA 0 0 0 0 0 0 0 NA 1 ...
##  $ VA_PAST2W_TIMES    : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ VA_PAST2W_MINS     : num  NA NA NA NA NA NA NA NA NA 60 ...
##  $ MA_PAST2W          : num  NA 0 0 0 0 0 0 0 NA 0 ...
##  $ MA_PAST2W_TIMES    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MA_PAST2W_MINS     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ LA_PAST2W          : num  NA 1 0 0 0 1 0 0 NA 1 ...
##  $ LA_PAST2W_TIMES    : num  NA 2 NA NA NA 14 NA NA NA 1 ...
##  $ LA_PAST2W_MINS     : num  NA 15 NA NA NA 30 NA NA NA 60 ...
##  $ VA_AR13            : num  NA 1 0 1 1 1 0 0 NA 1 ...
##  $ VA_AR13_LEVEL      : chr  NA &quot;V&quot; NA &quot;A&quot; ...
##  $ MA_AR13            : num  NA 1 1 1 1 1 0 0 NA 1 ...
##  $ MA_AR13_LEVEL      : chr  NA &quot;V&quot; &quot;V&quot; &quot;A&quot; ...
##  $ LA_AR13            : num  NA 1 1 1 1 1 0 0 NA 1 ...
##  $ LA_AR13_LEVEL      : chr  NA &quot;V&quot; &quot;V&quot; &quot;A&quot; ...
##  $ VA_AR24            : num  NA 0 0 1 1 0 0 0 NA 1 ...
##  $ VA_AR24_LEVEL      : chr  NA NA NA &quot;V&quot; ...
##  $ MA_AR24            : num  NA 1 1 1 1 0 0 0 NA 1 ...
##  $ MA_AR24_LEVEL      : chr  NA &quot;F&quot; &quot;V&quot; &quot;V&quot; ...
##  $ LA_AR24            : num  NA 1 1 1 1 1 0 0 NA 1 ...
##  $ LA_AR24_LEVEL      : chr  NA &quot;F&quot; &quot;V&quot; &quot;V&quot; ...
##  $ VA_AR50            : num  NA 0 0 0 0 0 0 0 NA 1 ...
##  $ VA_AR50_LEVEL      : chr  NA NA NA NA ...
##  $ MA_AR50            : num  NA 0 0 0 1 0 0 0 NA 1 ...
##  $ MA_AR50_LEVEL      : chr  NA NA NA NA ...
##  $ LA_AR50            : num  NA 1 1 1 1 1 0 0 NA 1 ...
##  $ LA_AR50_LEVEL      : chr  NA &quot;V&quot; &quot;F&quot; &quot;V&quot; ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-13" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_RPFQ&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-13" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    VARCHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)]
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`,ignore.case = T)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-13" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2021-02-01    1943-09-22
## 2 2021-11-15    1956-12-21
## 3 2021-08-18    1951-03-04
## 4 2021-12-06    1949-06-04
## 5 2021-09-09    1944-01-03
## 6 2021-11-15    1958-03-03</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-13" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 17 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-75692e3f9b9840ff2a2d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-75692e3f9b9840ff2a2d">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["sjt82, jjs2031, mxc2207, axl4132, mxp1257, jmv184, Maricarmen Contreras, cmanrique"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-13" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 47 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                                 &quot;1 thru 99999;&quot;                   
## [3] &quot;1 thru 9999;&quot;                     &quot;1;\r\n2;\r\n9;&quot;                  
## [5] &quot;0;\r\n1;\r\n9;&quot;                   &quot;0;\r\n1;\r\n2;\r\n3;\r\n4;\r\n5;&quot;
## [7] &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-55c1cd53a8c530bb2e49" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-55c1cd53a8c530bb2e49">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104411, 104408, 104445, 104427, 104406, 104415, 104431, 104407, 104432, 104439, 104442, 104530, 104403, 104404"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-13" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_RPFQ &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_screening" class="section level2">
<h2>ALZ_SCREENING</h2>
<pre class="r"><code>df &lt;- ALZ_SCREENING

info(ALZ_SCREENING,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:279, cols:49, inds:272</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    279 obs. of  49 variables:
##  $ SYSXM            : num  7178373 7178243 7178253 7178263 7178273 ...
##  $ SYSIND           : num  1.1e+07 1.1e+07 1.1e+07 1.1e+07 1.1e+07 ...
##  $ SYSGP            : num  7894403 7894393 7896003 7896013 7896093 ...
##  $ SYSGPSTUDY       : num  1309723 1309713 1311323 1311333 1311413 ...
##  $ SYSINDGP         : num  7793363 7793333 7795173 7795203 7795323 ...
##  $ CGI_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER     : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY           : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER         : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY            : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY         : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER           : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP               : num  87648 87503 87504 87505 87512 ...
##  $ IND              : num  101 1 1 9000 1 ...
##  $ REFCTR           : logi  NA NA NA NA NA NA ...
##  $ FORM_DATE        : POSIXct, format: &quot;2017-07-18&quot; &quot;2017-07-14&quot; ...
##  $ FILLED_OUT_BY    : chr  &quot;axr1589&quot; &quot;axr1589&quot; &quot;axr1589&quot; &quot;axr1589&quot; ...
##  $ DATE_OF_BIRTH    : POSIXct, format: &quot;1948-02-01&quot; &quot;1939-01-13&quot; ...
##  $ LUMBAR_YES_NO    : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ LUMBAR_DATE      : POSIXct, format: NA NA ...
##  $ LUMBAR_NO_DATE   : chr  NA NA NA NA ...
##  $ LUMBAR_PUNCTURE  : chr  NA NA NA NA ...
##  $ BRAIN_MRI_YES_NO : chr  &quot;N&quot; &quot;Y&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BRAIN_MRI_DATE   : POSIXct, format: NA NA ...
##  $ BRAIN_MRI_NO_DATE: chr  NA NA NA NA ...
##  $ BRAIN_MRI        : chr  NA &quot;NL&quot; NA NA ...
##  $ BRAIN_CT_YES_NO  : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BRAIN_CT_DATE    : POSIXct, format: NA NA ...
##  $ BRAIN_CT_NO_DATE : chr  NA NA NA NA ...
##  $ BRAIN_CT         : chr  NA NA NA NA ...
##  $ EEG_YES_NO       : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ EEG_DATE         : POSIXct, format: NA NA ...
##  $ EEG_NO_DATE      : chr  NA NA NA NA ...
##  $ EEG              : chr  NA NA NA NA ...
##  $ PET_SP_YES_NO    : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ PET_SP_DATE      : POSIXct, format: NA NA ...
##  $ PET_SP_NO_DATE   : chr  NA NA NA NA ...
##  $ PET_SP           : chr  NA NA NA NA ...
##  $ BRAIN_BIO_YES_NO : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BRAIN_BIO_DATE   : logi  NA NA NA NA NA NA ...
##  $ BRAIN_BIO_NO_DATE: logi  NA NA NA NA NA NA ...
##  $ BRAIN_BIO        : logi  NA NA NA NA NA NA ...
##  $ LUMB_NOTES       : logi  NA NA NA NA NA NA ...
##  $ BRNMRI_NOTES     : logi  NA NA NA NA NA NA ...
##  $ BRNCT_NOTES      : logi  NA NA NA NA NA NA ...
##  $ EEG_NOTES        : logi  NA NA NA NA NA NA ...
##  $ PETSP_NOTES      : logi  NA NA NA NA NA NA ...
##  $ BRNBIO_NOTES     : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-14" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_SCREENING&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-14" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 10 × 2
##    VarNames          `Data Type`   
##    &lt;chr&gt;             &lt;chr&gt;         
##  1 REFCTR            VARCHAR2(6)   
##  2 BRAIN_BIO_DATE    DATE          
##  3 BRAIN_BIO_NO_DATE CHAR(2)       
##  4 BRAIN_BIO         CHAR(2)       
##  5 LUMB_NOTES        VARCHAR2(4000)
##  6 BRNMRI_NOTES      VARCHAR2(4000)
##  7 BRNCT_NOTES       VARCHAR2(4000)
##  8 EEG_NOTES         VARCHAR2(4000)
##  9 PETSP_NOTES       VARCHAR2(4000)
## 10 BRNBIO_NOTES      VARCHAR2(4000)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`)]
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;DATE&quot;, dfDD$`Data Type`)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-14" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;FORM_DATE&quot;      &quot;DATE_OF_BIRTH&quot;  &quot;LUMBAR_DATE&quot;    &quot;BRAIN_MRI_DATE&quot; &quot;BRAIN_CT_DATE&quot;  &quot;EEG_DATE&quot;       &quot;PET_SP_DATE&quot;  

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## &quot;BRAIN_BIO_DATE&quot;, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;BRAIN_BIO_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    FORM_DATE DATE_OF_BIRTH LUMBAR_DATE BRAIN_MRI_DATE BRAIN_CT_DATE EEG_DATE
## 1 2017-07-18    1948-02-01        &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;     &lt;NA&gt;
## 2 2017-07-14    1939-01-13        &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;     &lt;NA&gt;
## 3 2017-07-14    1944-10-03        &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;     &lt;NA&gt;
## 4 2017-07-14    1960-10-23        &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;     &lt;NA&gt;
## 5 2017-07-14    1940-11-18        &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;     &lt;NA&gt;
## 6 2017-07-14    1946-10-04        &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;     &lt;NA&gt;
##   PET_SP_DATE
## 1        &lt;NA&gt;
## 2        &lt;NA&gt;
## 3        &lt;NA&gt;
## 4        &lt;NA&gt;
## 5        &lt;NA&gt;
## 6        &lt;NA&gt;</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-14" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 31 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-a877d4aedf98d7034d78" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a877d4aedf98d7034d78">{"x":{"filter":"none","vertical":false,"data":[["FILLED_OUT_BY"],["FILLED_OUT_BY"],["axr1589, v.rodriguez4, avg55, ALEJANDRA BETACOURT, bxf258, sjt82, prm72, kxc672, ascott2, patricia manrique, patricia, mxc2207, fxs121, jjs2031, axl4132, jmv184, gsv32, cmanrique"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore FILLED_OUT_BY</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-14" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 10 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-53e0d5826b6625bd7b20" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-53e0d5826b6625bd7b20">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104415, 104410, 104456, 104557, 104403, 104404, 104705"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-14" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_SCREENING &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_screening_rc" class="section level2">
<h2>ALZ_SCREENING_RC</h2>
<pre class="r"><code>df &lt;- ALZ_SCREENING_RC

info(ALZ_SCREENING_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:556, cols:61, inds:552</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    556 obs. of  61 variables:
##  $ SYSXM             : num  8258773 8258813 8260093 8277633 8278003 ...
##  $ SYSIND            : num  11037673 11369813 11362953 11638763 11621333 ...
##  $ SYSGP             : num  7894423 7952013 7946353 8007323 8006293 ...
##  $ SYSGPSTUDY        : num  1309743 1397123 1387463 1454033 1453003 ...
##  $ SYSINDGP          : num  7793413 8139083 8132223 8407833 8390403 ...
##  $ CGI_ORDER         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER      : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY            : chr  &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER          : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY             : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY          : chr  &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER            : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                : num  87650 88301 87545 104540 104528 ...
##  $ IND               : num  9000 1 106 1 1 ...
##  $ REFCTR            : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE         : POSIXct, format: &quot;2023-10-24&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER          : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH     : POSIXct, format: &quot;1954-10-29&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM       : num  68 76 66 86 86 67 60 81 77 62 ...
##  $ REVIEW_DATE       : logi  NA NA NA NA NA NA ...
##  $ REVIEWER          : logi  NA NA NA NA NA NA ...
##  $ LUMB_YN           : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ LUMB_DT           : POSIXct, format: NA NA ...
##  $ LUMB_PUNC         : chr  NA NA NA NA ...
##  $ LUMB_NOTES        : chr  NA NA NA NA ...
##  $ BRNMRI_YN         : chr  &quot;Y&quot; &quot;N&quot; &quot;Y&quot; &quot;N&quot; ...
##  $ BRNMRI_DT         : POSIXct, format: &quot;2017-10-01&quot; NA ...
##  $ BRAIN_MRI         : chr  &quot;NL&quot; NA &quot;AC&quot; NA ...
##  $ BRNMRI_NOTES      : chr  NA NA &quot;NO DATE AVAILABLE&quot; NA ...
##  $ BRNCT_YN          : chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BRNCT_DT          : POSIXct, format: &quot;2017-10-01&quot; NA ...
##  $ BRAIN_CT          : chr  &quot;NL&quot; NA NA NA ...
##  $ BRNCT_NOTES       : chr  NA NA NA NA ...
##  $ EEG_YN            : chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ EEG_DT            : POSIXct, format: &quot;2017-10-01&quot; NA ...
##  $ EEG               : chr  &quot;NL&quot; NA NA NA ...
##  $ EEG_NOTES         : chr  NA NA NA NA ...
##  $ PETSP_YN          : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ PETSP_DT          : POSIXct, format: NA NA ...
##  $ PET_SPECT         : chr  NA NA NA NA ...
##  $ PETSP_NOTES       : chr  NA NA NA NA ...
##  $ BRNBIO_YN         : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ BRNBIO_DT         : logi  NA NA NA NA NA NA ...
##  $ BRAIN_BIO         : logi  NA NA NA NA NA NA ...
##  $ BRNBIO_NOTES      : logi  NA NA NA NA NA NA ...
##  $ PRIOR_SCORE_MMSE1 : logi  NA NA NA NA NA NA ...
##  $ DATE_MMSE1        : logi  NA NA NA NA NA NA ...
##  $ PRIOR_SCORE_MOCA1 : logi  NA NA NA NA NA NA ...
##  $ DATE_MOCA1        : logi  NA NA NA NA NA NA ...
##  $ PRIOR_SC_BROOKE1  : logi  NA NA NA NA NA NA ...
##  $ DATE_BROOKE1      : logi  NA NA NA NA NA NA ...
##  $ PRIOR_SC_CHIF1    : logi  NA NA NA NA NA NA ...
##  $ DATE_CHIF1        : logi  NA NA NA NA NA NA ...
##  $ PRIOR_SC_WORDLIST1: logi  NA NA NA NA NA NA ...
##  $ DATE_WORDLIST1    : logi  NA NA NA NA NA NA ...
##  $ OTHER_TEST1       : logi  NA NA NA NA NA NA ...
##  $ DATE_OTHER_TEST1  : logi  NA NA NA NA NA NA ...
##  $ PRIOR_CLASSIF1    : logi  NA NA NA NA NA NA ...
##  $ PRIOR_ASSESS_NOTE1: logi  NA NA NA NA NA NA ...
##  $ NOTE_ALZ_SCREEN   : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-15" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_SCREENING_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-15" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 20 × 2
##    VarNames           `Data Type`   
##    &lt;chr&gt;              &lt;chr&gt;         
##  1 REFCTR             VARCHAR2(6)   
##  2 REVIEW_DATE        date          
##  3 REVIEWER           VARCHAR       
##  4 BRNBIO_DT          DATE          
##  5 BRAIN_BIO          CHAR(2)       
##  6 BRNBIO_NOTES       VARCHAR2(4000)
##  7 PRIOR_SCORE_MMSE1  NUMBER(3)     
##  8 DATE_MMSE1         DATE          
##  9 PRIOR_SCORE_MOCA1  NUMBER(3)     
## 10 DATE_MOCA1         DATE          
## 11 PRIOR_SC_BROOKE1   NUMBER(3)     
## 12 DATE_BROOKE1       DATE          
## 13 PRIOR_SC_CHIF1     NUMBER(3)     
## 14 DATE_CHIF1         DATE          
## 15 PRIOR_SC_WORDLIST1 NUMBER(3)     
## 16 DATE_WORDLIST1     DATE          
## 17 OTHER_TEST1        NUMBER(3)     
## 18 DATE_OTHER_TEST1   DATE          
## 19 PRIOR_CLASSIF1     VARCHAR2(50)  
## 20 PRIOR_ASSESS_NOTE1 VARCHAR2(150)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,,ignore.case = T)] ## 6 vars
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`,ignore.case = T)] ## 8 vars
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`,ignore.case = T)] ## 6 vars

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2num] &lt;- lapply(df[convert2chr], as.numeric)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-15" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; &quot;LUMB_DT&quot;       &quot;BRNMRI_DT&quot;     &quot;BRNCT_DT&quot;      &quot;EEG_DT&quot;        &quot;PETSP_DT&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols)</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;      &quot;BRNBIO_DT&quot;        &quot;DATE_MMSE1&quot;       &quot;DATE_MOCA1&quot;      
## [5] &quot;DATE_BROOKE1&quot;     &quot;DATE_CHIF1&quot;       &quot;DATE_WORDLIST1&quot;   &quot;DATE_OTHER_TEST1&quot;</code></pre>
<pre class="r"><code># [1] &quot;REVIEW_DATE&quot;      &quot;BRNBIO_DT&quot;        &quot;DATE_MMSE1&quot;       &quot;DATE_MOCA1&quot;       &quot;DATE_BROOKE1&quot;     &quot;DATE_CHIF1&quot;      
# [7] &quot;DATE_WORDLIST1&quot;   &quot;DATE_OTHER_TEST1&quot;
## these variables have been corrected in previous step

head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH LUMB_DT  BRNMRI_DT   BRNCT_DT     EEG_DT PETSP_DT
## 1 2023-10-24    1954-10-29    &lt;NA&gt; 2017-10-01 2017-10-01 2017-10-01     &lt;NA&gt;
## 2 2024-02-13    1947-05-13    &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;
## 3 2024-02-20    1957-08-05    &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;
## 4 2023-09-13    1937-08-13    &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;
## 5 2023-05-09    1936-05-22    &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;
## 6 2023-08-16    1956-01-09    &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-15" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 29 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-12fdad3c36667868d537" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-12fdad3c36667868d537">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, cmanrique, sjt82, kxc672, mxp1257, mxl2473, v.rodriguez4, cxc2077, smm493, Katalina McInerney, axl4418, Izri Martinez, prm72, Anisley Martinez, eir34, ABIGAIL LOPEZ, Katalina Fernandez M, bxf258, lxi119"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-15" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 17 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-ba9ab1ecda070d52c7ea" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-ba9ab1ecda070d52c7ea">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104540, 104528, 104519, 104455, 104511, 104548, 104549, 104459, 104452, 104531, 104497, 104521, 104487, 104496, 104525, 104472, 104515, 104508, 104490, 104453, 104513, 104499, 104500, 104536, 104518, 104454, 104514, 104554, 104481, 105805, 104475, 104526, 104539, 104527, 104466, 104556, 104532, 104552, 104463, 104512, 104469, 105806, 104457, 104464, 104529, 104516, 104476, 104530, 104502, 105801, 104458, 104470, 104553, 105817, 104569, 104482, 105821, 105818, 104589, 105827, 104565, 105820, 104557, 104564, 104535, 105809, 104560, 104574, 104542, 104461, 105815, 105807, 105808, 105803, 105814, 104507, 104578, 104586, 104467, 104582, 104447, 104585, 104550, 104573, 105824, 104468, 104547, 104545, 104570, 104583, 105811, 104485, 104450, 104559, 104546, 104555, 104590, 104591, 104568, 104506, 104551, 104544, 104571, 104473, 104483, 105813, 104494, 104563, 104484, 105822, 104572, 104495, 105826, 104524, 104489, 104462, 104479, 104523, 104488, 104509, 104505, 104579, 104448, 104534, 104566, 104465, 105812, 104562, 104580, 104581, 104584, 104541, 104533, 105810, 104451, 104498, 104510, 104449, 104575, 104474, 104561, 104520, 105800, 105816, 104480, 105825, 105823, 104478, 104486, 104594, 104654, 104662, 104661, 104652, 104666, 104632, 104626, 104656, 104659, 104660, 104658, 104614, 104588, 104623, 104664, 104629, 104657, 104634, 104599, 104616, 104610, 104621, 104617, 104684, 104679, 104697, 104619, 104612, 104501, 105829, 104638, 104655, 104640, 104643, 104602, 104639, 104645, 104685, 104681, 104503, 104522, 104665, 105830, 104456, 104597, 104669, 104618, 104624, 105832, 104595, 104538, 104504, 104537, 104648, 104672, 105833, 105834, 104650, 104558, 104517, 104667, 104604, 104701, 104688, 104593, 104689, 105828, 104663, 104686, 104630, 104611, 104644, 104646, 104615, 104605, 104606, 104622, 104683, 104647, 104608, 104696, 104677, 104699, 104631, 105831, 104680, 104642, 104598, 104600, 104596, 104637, 104543, 104620, 104668, 104651, 104609, 104607, 104673, 104682, 104674, 104592, 104401, 104641, 104649, 104712, 104714, 104711, 104613, 105838, 104708, 104704, 104713, 104710, 104724, 104725, 104720, 104723, 104735, 104675, 104676, 104781, 104785, 104775, 104718, 104719, 104717, 104736, 104743, 104742, 104761, 104740, 104744, 104769, 104765, 104754, 104752, 104758, 104766, 104762, 104770, 104771, 104627, 104747, 104628, 104727, 104721, 104728, 104726, 104700, 104734, 104715, 104706, 104746, 104722, 104730, 104690, 104774, 104778, 104695, 104748, 104738, 104737, 104751, 104703, 104731, 104729, 104768, 104764, 104777, 104763, 104776, 104625, 104603, 104702"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-15" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_SCREENING_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="alz_stick_d_rc" class="section level2">
<h2>ALZ_STICK_D_RC</h2>
<pre class="r"><code>df &lt;- ALZ_STICK_D_RC

info(ALZ_STICK_D_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:430, cols:46, inds:428</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    430 obs. of  46 variables:
##  $ SYSXM                        : num  8275873 8258963 8259113 8277733 8277873 ...
##  $ SYSIND                       : num  11160523 11369813 11037673 11435853 11638763 ...
##  $ SYSGP                        : num  7923793 7952013 7894423 7962813 8007323 ...
##  $ SYSGPSTUDY                   : num  1361903 1397123 1309743 1407923 1454033 ...
##  $ SYSINDGP                     : num  7923633 8139083 7793413 8205123 8407833 ...
##  $ CGI_ORDER                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER                 : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                       : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER                     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                     : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER                       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                           : num  87883 88301 87650 88452 104540 ...
##  $ IND                          : num  1 1 9000 1 1 106 9000 1 1 1 ...
##  $ REFCTR                       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                    : POSIXct, format: &quot;2024-02-14&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER                     : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH                : POSIXct, format: &quot;1939-03-20&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM                  : num  84 76 68 81 86 66 56 79 79 77 ...
##  $ REVIEW_DATE                  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                     : logi  NA NA NA NA NA NA ...
##  $ DRSD_I                       : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ DRSD_II                      : num  1 1 1 1 1 0 1 1 1 1 ...
##  $ DRSD_III                     : num  0 1 0 1 1 0 1 1 0 1 ...
##  $ DRSD_IV                      : num  1 1 1 0 1 1 0 1 0 1 ...
##  $ DRSD_V                       : num  1 1 1 0 1 0 0 1 0 1 ...
##  $ DRSD_VI                      : num  0 0 0 0 0 0 0 1 0 1 ...
##  $ DRSD_VII                     : num  0 1 0 0 0 1 0 0 0 1 ...
##  $ DRSD_VIII                    : num  0 1 0 0 0 1 0 0 0 1 ...
##  $ DRSD_IX                      : num  0 0 0 0 0 1 0 0 0 1 ...
##  $ DRSD_X                       : num  1 0 1 1 0 0 0 1 1 1 ...
##  $ DRSD_XI                      : num  1 0 1 0 0 0 0 1 1 1 ...
##  $ DRSD_XII                     : num  1 0 0 0 0 0 0 1 1 1 ...
##  $ COMMENTS_DRSD                : chr  &quot;did not remember chevron figure&quot; NA NA &quot;unable to remember figures: triangle with stem and chevron&quot; ...
##  $ STATUS_DRSD                  : logi  NA NA NA NA NA NA ...
##  $ TOTAL_SCORE_ITEM1_DRSD       : num  2 3 2 3 3 1 3 3 2 3 ...
##  $ TOTAL_SCORE_ITEM1_DRSD_STATUS: logi  NA NA NA NA NA NA ...
##  $ TOTAL_SCORE_ITEM2_DRSD       : num  2 2 2 0 2 1 0 3 0 3 ...
##  $ TOTAL_SCORE_ITEM2_DRSD_STATUS: logi  NA NA NA NA NA NA ...
##  $ TOTAL_SCORE_ITEM3_DRSD       : num  0 2 0 0 0 3 0 0 0 3 ...
##  $ TOTAL_SCORE_ITEM3_DRSD_STATUS: logi  NA NA NA NA NA NA ...
##  $ TOTAL_SCORE_ITEM4_DRSD       : num  3 0 2 1 0 0 0 3 3 3 ...
##  $ TOTAL_SCORE_ITEM4_DRSD_STATUS: logi  NA NA NA NA NA NA ...
##  $ SUM_TOTAL_SCORE_DRSD         : num  7 7 6 4 5 5 3 9 5 12 ...
##  $ SUM_TOTAL_SCORE_DRSD_STATUS  : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-16" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;ALZ_STICK_D_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-16" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 8 × 2
##   VarNames                      `Data Type`
##   &lt;chr&gt;                         &lt;chr&gt;      
## 1 REFCTR                        VARCHAR2(6)
## 2 REVIEW_DATE                   date       
## 3 REVIEWER                      VARCHAR    
## 4 STATUS_DRSD                   NUMBER(3)  
## 5 TOTAL_SCORE_ITEM1_DRSD_STATUS CHAR       
## 6 TOTAL_SCORE_ITEM2_DRSD_STATUS CHAR       
## 7 TOTAL_SCORE_ITEM3_DRSD_STATUS CHAR       
## 8 TOTAL_SCORE_ITEM4_DRSD_STATUS CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)] ## STATUS_DRSD

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date))

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-16" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-14    1939-03-20
## 2 2024-02-13    1947-05-13
## 3 2023-10-24    1954-10-29
## 4 2024-02-15    1942-09-30
## 5 2023-09-13    1937-08-13
## 6 2024-02-20    1957-08-05</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-16" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 14 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-824cec7afb6a461d6fcb" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-824cec7afb6a461d6fcb">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, cmanrique, prm72, smm493, Katalina McInerney, Anisley Martinez, Izri Martinez, mxl2473, ABIGAIL LOPEZ, mxp1257, cxc2077, Katalina Fernandez M, v.rodriguez4, lxi119, eir34, Elias Rojas, jxr1528, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-16" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 29 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                             &quot;1 thru 99999;&quot;               
## [3] &quot;1 thru 9999;&quot;                 &quot;1;\r\n0;\r\n&quot;                
## [5] &quot;995;\r\n996;\r\n997;\r\n998;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-8416f1ad9ec613aaff9c" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-8416f1ad9ec613aaff9c">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104540, 104556, 104511, 104549, 104552, 104500, 104525, 104497, 104518, 104536, 104521, 105806, 104514, 104515, 104490, 104526, 104548, 104554, 104508, 104513, 104539, 104527, 104512, 104516, 104501, 105809, 104498, 105817, 104569, 104557, 105815, 105808, 105822, 105814, 104519, 105826, 104566, 104581, 104574, 104573, 105824, 104570, 105819, 104582, 105807, 104583, 105813, 104506, 104507, 104510, 104546, 105810, 104563, 105821, 105816, 104494, 104562, 104571, 104565, 105827, 104572, 104495, 104586, 104585, 104541, 104488, 104505, 104509, 104580, 104579, 104561, 104520, 104578, 104502, 104533, 104524, 104534, 104584, 104567, 104575, 104560, 105818, 104542, 105823, 105825, 104636, 104662, 104664, 104650, 104652, 104666, 104632, 104656, 104640, 104658, 104588, 104614, 104634, 104611, 104610, 104623, 104621, 104617, 104683, 105833, 104604, 104619, 104612, 105829, 104609, 104668, 104655, 104643, 104657, 104602, 104645, 104680, 104688, 104665, 104597, 105832, 105830, 104595, 104685, 104681, 104669, 104599, 104616, 104624, 104537, 104648, 104684, 104649, 104638, 104504, 104503, 104522, 104667, 104558, 104517, 104592, 104672, 104699, 104698, 104701, 104593, 105831, 104689, 104682, 104686, 104644, 104646, 104605, 104606, 104622, 104647, 104594, 104608, 105828, 105834, 104637, 104631, 104639, 104661, 104642, 104598, 104600, 104618, 104538, 104620, 104596, 104696, 104607, 104677, 104635, 104641, 104709, 104714, 104711, 104613, 105838, 104708, 104705, 104704, 104713, 104712, 104710, 104717, 104722, 104724, 104725, 104723, 104720, 104746, 104734, 104781, 104775, 104718, 104737, 104742, 104735, 104674, 104743, 104738, 104736, 104744, 104769, 104703, 104765, 104751, 104766, 104762, 104771, 104702, 104727, 104721, 104728, 104700, 104754, 104715, 104706, 104752, 104730, 104747, 104774, 104778, 104695, 104783, 104719, 104726, 104761, 104770, 104731, 104729, 104768, 104764, 104776, 104777, 104763, 104675, 104690, 104676, 104748, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-16" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>ALZ_STICK_D_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="b4_cdr_rc" class="section level2">
<h2>B4_CDR_RC</h2>
<pre class="r"><code>df &lt;- B4_CDR_RC

info(B4_CDR_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:599, cols:38, inds:592</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    599 obs. of  38 variables:
##  $ SYSXM              : num  8275843 8276023 8276613 8258933 8259053 ...
##  $ SYSIND             : num  11160523 11620763 11369703 11369813 11037673 ...
##  $ SYSGP              : num  7923793 8005723 7951913 7952013 7894423 ...
##  $ SYSGPSTUDY         : num  1361903 1452433 1397023 1397123 1309743 ...
##  $ SYSINDGP           : num  7923633 8389833 8138973 8139083 7793413 ...
##  $ CGI_ORDER          : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER          : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER       : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY             : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER           : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY              : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY           : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER             : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                 : num  87883 104457 88299 88301 87650 ...
##  $ IND                : num  1 1 1 1 9000 1 1 1 1 106 ...
##  $ REFCTR             : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE          : POSIXct, format: &quot;2024-02-14&quot; &quot;2023-04-17&quot; ...
##  $ EXAMINER           : chr  &quot;gsv32&quot; &quot;sjt82&quot; &quot;gsv32&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH      : POSIXct, format: &quot;1939-03-20&quot; &quot;1946-12-19&quot; ...
##  $ AGE_AT_EXAM        : num  84 76 79 76 68 73 81 86 86 66 ...
##  $ REVIEW_DATE        : logi  NA NA NA NA NA NA ...
##  $ REVIEWER           : logi  NA NA NA NA NA NA ...
##  $ METHOD_CDR         : chr  &quot;IP&quot; &quot;IP&quot; &quot;IP&quot; &quot;IP&quot; ...
##  $ MEMO_NOTE          : chr  NA NA NA NA ...
##  $ MEMO_SC            : num  0.5 1 0.5 0 0 0 0 0.5 0 1 ...
##  $ ORIENT_NOTE        : chr  NA NA NA NA ...
##  $ ORIENT_SC          : num  0 0.5 0 0 0 0 0 0 0 1 ...
##  $ P_SOLVE_NOTE       : chr  NA NA NA NA ...
##  $ P_SOLVE_SC         : num  0 1 0 0 0 0 0 0 0 1 ...
##  $ COM_AFFAIR_NOTE    : chr  NA NA NA NA ...
##  $ COM_AFFAIR_SC      : num  0 1 0 0 0 0 0 0 0 0.5 ...
##  $ HOME_HOB_NOTES     : chr  NA NA NA NA ...
##  $ HOME_HOB_SC        : num  0 1 0 0 0 0 0 0 0 0.5 ...
##  $ P_CARE_NOTE        : chr  NA NA NA NA ...
##  $ P_CARE_SC          : num  0 1 0 0 0 0 0 0 0 0.5 ...
##  $ CDR_TOTAL_CDR      : num  5 1 5 0 0 0 0 5 0 5 ...
##  $ SUM_BOXSCORE       : num  0.5 5.5 0.5 0 0 0 0 0.5 0 4.5 ...
##  $ SUM_BOXSCORE_STATUS: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-17" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;B4_CDR_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-17" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    VARCHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;   &quot;REVIEWER&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-17" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-14    1939-03-20
## 2 2023-04-17    1946-12-19
## 3 2024-02-13    1944-09-22
## 4 2024-02-13    1947-05-13
## 5 2023-10-24    1954-10-29
## 6 2023-05-15    1950-04-02</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-17" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 16 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-22d51533077b3e55398d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-22d51533077b3e55398d">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, sjt82, jjs2031, mxp1257, cmanrique, prm72, v.rodriguez4, kxc672, bxf258, mxl2473, axl4418, smm493, Katalina McInerney, Anisley Martinez, Izri Martinez, ABIGAIL LOPEZ, cxc2077, Katalina Fernandez M, lxi119, eir34, fxs121, Elias Rojas, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-17" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 19 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                             &quot;1 thru 99999;&quot;               
## [3] &quot;1 thru 9999;&quot;                 &quot;0;\r\n0.5;\r\n1;\r\n2;\r\n3;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-ccde5e56e3d948bcf593" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-ccde5e56e3d948bcf593">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104457, 104476, 104540, 104528, 104456, 104556, 104511, 104549, 104452, 104552, 104500, 104525, 104497, 104531, 104518, 105801, 104472, 104469, 104521, 105806, 104499, 104536, 104514, 104496, 104487, 104515, 104490, 104453, 104526, 104548, 104459, 104454, 104513, 104554, 104460, 105805, 104508, 104475, 104455, 104481, 104539, 104471, 104532, 104463, 104512, 104516, 104527, 104466, 104477, 104529, 104464, 104507, 105802, 105804, 104530, 104502, 104489, 104458, 105803, 105809, 104551, 105817, 104569, 104589, 104565, 105825, 105820, 104564, 104542, 105813, 104535, 104557, 105807, 105815, 105808, 105822, 104430, 105814, 104553, 104485, 104578, 104465, 104474, 104591, 104582, 104574, 105826, 104545, 104550, 104573, 105824, 104434, 104494, 104547, 104506, 104570, 104461, 104583, 104450, 104559, 104519, 104510, 104590, 104546, 104509, 104447, 104473, 104563, 105821, 104482, 104484, 104571, 104568, 105827, 104495, 104586, 104572, 105819, 104462, 104479, 105811, 104560, 104523, 104488, 104505, 104579, 104555, 104448, 104470, 104561, 104520, 105812, 104562, 104580, 104566, 104581, 104533, 104541, 104467, 104478, 104451, 105810, 104468, 104498, 104524, 104534, 104567, 104584, 104449, 104575, 104483, 104585, 105800, 104436, 105816, 104480, 105818, 104544, 105823, 104486, 104636, 104662, 104664, 104652, 104650, 104666, 104632, 104659, 104640, 104614, 104658, 104588, 104651, 104638, 104660, 104634, 104612, 104623, 104656, 104621, 104617, 104672, 105833, 105829, 104604, 104619, 104501, 105830, 104609, 104668, 104655, 105828, 104643, 104657, 104602, 104645, 104680, 104685, 104503, 104688, 104665, 104597, 104595, 104681, 104669, 104616, 105832, 104624, 104537, 104648, 104633, 104599, 104684, 104696, 104649, 104631, 104635, 104522, 104667, 104558, 104414, 104517, 104592, 104699, 104701, 104593, 105831, 104689, 104663, 104682, 104686, 104630, 104611, 104644, 104646, 104654, 104615, 104605, 104606, 104622, 104647, 104608, 104679, 105834, 104637, 104639, 104661, 104629, 104642, 104598, 104600, 104618, 104543, 104538, 104620, 104607, 104504, 104594, 104673, 104677, 104641, 104626, 104683, 104709, 104711, 104714, 104613, 105838, 104708, 104713, 104705, 104704, 104710, 104717, 104724, 104725, 104723, 104746, 104734, 104781, 104727, 104775, 104736, 104742, 104735, 104674, 104743, 104731, 104737, 104738, 104744, 104703, 104769, 104752, 104751, 104712, 104762, 104758, 104771, 104763, 104627, 104702, 104690, 104721, 104695, 104700, 104728, 104722, 104754, 104715, 104706, 104720, 104729, 104730, 104770, 104747, 104778, 104765, 104783, 104718, 104719, 104726, 104768, 104764, 104777, 104675, 104676, 104748, 104761, 104698, 104625, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-17" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>B4_CDR_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="b5_npiq_rc" class="section level2">
<h2>B5_NPIQ_RC</h2>
<pre class="r"><code>df &lt;- B5_NPIQ_RC

info(B5_NPIQ_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:305, cols:38, inds:304</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    305 obs. of  38 variables:
##  $ SYSXM        : num  8275943 8258983 8277543 8260623 8261293 ...
##  $ SYSIND       : num  11160523 11369813 11620763 11163453 11638403 ...
##  $ SYSGP        : num  7923793 7952013 8005723 7924953 8006953 ...
##  $ SYSGPSTUDY   : num  1361903 1397123 1452433 1363063 1453663 ...
##  $ SYSINDGP     : num  7923633 8139083 8389833 7926663 8407473 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  87883 88301 104457 87923 104556 ...
##  $ IND          : num  1 1 1 9000 1 1 1 1 1 101 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE    : POSIXct, format: &quot;2024-02-14&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER     : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;sjt82&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1939-03-20&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM  : num  84 76 76 56 79 71 74 64 86 70 ...
##  $ REVIEW_DATE  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER     : logi  NA NA NA NA NA NA ...
##  $ NPIQINF      : num  1 2 3 3 2 2 3 1 3 3 ...
##  $ NPIQINF_OTH  : chr  NA NA &quot;center caretaker&quot; &quot;cousin&quot; ...
##  $ NPIQTYPE     : num  1 NA NA 1 NA NA 1 NA NA 1 ...
##  $ DELSEV       : num  0 0 2 0 0 0 0 0 0 0 ...
##  $ HALLSEV      : num  1 0 2 0 0 0 0 0 0 0 ...
##  $ AGITSEV      : num  0 0 0 0 0 2 0 0 1 0 ...
##  $ DEPDSEV      : num  1 0 0 1 1 2 0 0 0 0 ...
##  $ ANXSEV       : num  1 0 0 0 2 2 0 0 1 0 ...
##  $ ELATSEV      : num  0 0 0 0 0 2 0 0 1 0 ...
##  $ APASEV       : num  0 0 0 0 0 3 0 0 0 0 ...
##  $ DISNSEV      : num  0 0 0 0 0 2 0 0 0 0 ...
##  $ IRRSEV       : num  0 0 0 1 0 2 0 0 0 0 ...
##  $ MOTSEV       : num  0 0 0 0 0 2 0 0 0 0 ...
##  $ NITESEV      : num  1 0 0 0 0 1 0 0 0 0 ...
##  $ APPSEV       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ NOTES_NPIQ   : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-18" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;B5_NPIQ_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-18" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`)]
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-18" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-14    1939-03-20
## 2 2024-02-13    1947-05-13
## 3 2023-04-17    1946-12-19
## 4 2023-10-25    1967-06-15
## 5 2023-09-12    1944-04-17
## 6 2023-09-12    1952-04-25</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-18" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 10 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-47694071aaf81ed18303" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-47694071aaf81ed18303">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, sjt82, mxp1257, cmanrique, v.rodriguez4, bxf258, mxl2473, Katalina McInerney, prm72, ABIGAIL LOPEZ, Anisley Martinez, Katalina Fernandez M, axl4418, lxi119, eir34, smm493"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-18" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 25 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                                      
## [2] &quot;1 thru 99999;&quot;                         
## [3] &quot;1 thru 9999;&quot;                          
## [4] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;&quot;
## [5] &quot;1;\r\n2;&quot;                              
## [6] &quot;1;\r\n2;\r\n3;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2aaea7b1441830f2918d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2aaea7b1441830f2918d">{"x":{"filter":"none","vertical":false,"data":[["GP","DELSEV","HALLSEV","AGITSEV","DEPDSEV","ANXSEV","ELATSEV","APASEV","DISNSEV","IRRSEV","MOTSEV","NITESEV","APPSEV"],["GP","DELSEV","HALLSEV","AGITSEV","DEPDSEV","ANXSEV","ELATSEV","APASEV","DISNSEV","IRRSEV","MOTSEV","NITESEV","APPSEV"],["104457, 104556, 104552, 104452, 104518, 104472, 105801, 104496, 105806, 104490, 104554, 104460, 104475, 104532, 104463, 104466, 104459, 104529, 104481, 104464, 105803, 105817, 105827, 104572, 104542, 104461, 105807, 105815, 104519, 105808, 104578, 105809, 105813, 104575, 104474, 104574, 104573, 105824, 104545, 104570, 104582, 104583, 105826, 104581, 104480, 104544, 104562, 105814, 105816, 104571, 104569, 104565, 104579, 104566, 104567, 104563, 104580, 104478, 104458, 105811, 105800, 104462, 105818, 104483, 104451, 104546, 105823, 105825, 104486, 104636, 104662, 104666, 104632, 104659, 104640, 104614, 104660, 104611, 104623, 104621, 104617, 104683, 104681, 104604, 104619, 104612, 105833, 105829, 104609, 104668, 104643, 104644, 104602, 104680, 104665, 104616, 105830, 104537, 104648, 104633, 104649, 104638, 104631, 104652, 104667, 104698, 104593, 105831, 104689, 104646, 104615, 104606, 104622, 104647, 104608, 105828, 105832, 104637, 104594, 104639, 104558, 104642, 104600, 104654, 105834, 104620, 104607, 104596, 104673, 104677, 104635, 104641, 104709, 104711, 104613, 105838, 104714, 104722, 104769, 104742, 104735, 104674, 104744, 104751, 104765, 104771, 104763, 104770, 104700, 104729, 104778, 104695, 104762, 104726, 104768, 104764, 104747, 104690, 104676","0","0, 9","0, 9","0, 9","0","0, 9","0, 9","0, 9","0, 9","0, 9","0, 9","0, 9"],["1 - 99999","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3","1;2;3"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-18" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>B5_NPIQ_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="b6_gds_rc" class="section level2">
<h2>B6_GDS_RC</h2>
<pre class="r"><code>df &lt;- B6_GDS_RC

info(B6_GDS_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:543, cols:39, inds:539</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    543 obs. of  39 variables:
##  $ SYSXM         : num  8276623 8258953 8259103 8277723 8277863 ...
##  $ SYSIND        : num  11369703 11369813 11037673 11435853 11638763 ...
##  $ SYSGP         : num  7951913 7952013 7894423 7962813 8007323 ...
##  $ SYSGPSTUDY    : num  1397023 1397123 1309743 1407923 1454033 ...
##  $ SYSINDGP      : num  8138973 8139083 7793413 8205123 8407833 ...
##  $ CGI_ORDER     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER  : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY        : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER      : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY         : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY      : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER        : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP            : num  88299 88301 87650 88452 104540 ...
##  $ IND           : num  1 1 9000 1 1 1 1 106 9000 1 ...
##  $ REFCTR        : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE     : POSIXct, format: &quot;2024-02-13&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER      : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH : POSIXct, format: &quot;1944-09-22&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM   : num  79 76 68 81 86 73 86 66 56 73 ...
##  $ REVIEW_DATE   : logi  NA NA NA NA NA NA ...
##  $ REVIEWER      : logi  NA NA NA NA NA NA ...
##  $ LIFE          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ ACTIVITY      : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ EMPTY         : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ BORED         : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ SPIRIT        : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ AFRAID        : num  0 0 1 0 0 0 0 0 0 1 ...
##  $ HAPPY         : num  0 0 0 0 1 0 0 1 0 0 ...
##  $ HELPLESS      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ STAY_HOME     : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ MEMORY        : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ ALIVE         : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ WORTHLESS     : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ ENERGY        : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ HOPELESS      : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ BETTER_OFF    : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ INCOMPLETE_GDS: num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COMMENTS_GDS  : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-19" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;B6_GDS_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-19" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)]
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;DATE&quot;, dfDD$`Data Type`,ignore.case = T)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-19" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols)</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code># [1] &quot;REVIEW_DATE&quot;, ignore it, this variables have been corrected in previous step

head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-13    1944-09-22
## 2 2024-02-13    1947-05-13
## 3 2023-10-24    1954-10-29
## 4 2024-02-15    1942-09-30
## 5 2023-09-13    1937-08-13
## 6 2023-05-15    1950-04-02</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-19" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 9 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-695db9f98121f10fb64f" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-695db9f98121f10fb64f">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, mxp1257, cmanrique, prm72, sjt82, kxc672, mxl2473, v.rodriguez4, smm493, Katalina McInerney, Anisley Martinez, axl4418, ABIGAIL LOPEZ, KATALINA MCINERNEY, llc97, cxc2077, Katalina Fernandez M, bxf258, lxi119, eir34, Elias Rojas, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-19" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 27 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-29b1da04d8676852b8ca" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-29b1da04d8676852b8ca">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104540, 104476, 104528, 104456, 104556, 104455, 104511, 104549, 104552, 104452, 104500, 104525, 104497, 104531, 104518, 104459, 104472, 105801, 104469, 104521, 105806, 104499, 104536, 104514, 104487, 104515, 104496, 104490, 104526, 104453, 104548, 104454, 104554, 105805, 104508, 104475, 104513, 104539, 104471, 104532, 104512, 104516, 104507, 104529, 104481, 104464, 104530, 105809, 105817, 104569, 104589, 105827, 104565, 104494, 104564, 104535, 104542, 104557, 105815, 104421, 105808, 105803, 105822, 104519, 104485, 104553, 105807, 104578, 104470, 104591, 105826, 104447, 104474, 104550, 104574, 104573, 104545, 104570, 104582, 104583, 104450, 105813, 104506, 104510, 104590, 104568, 104546, 104473, 105810, 105824, 104465, 104544, 104563, 105821, 104482, 105816, 104484, 104571, 104495, 104586, 104585, 104572, 105819, 104541, 104479, 105811, 104560, 104523, 104509, 104488, 104505, 104579, 104555, 105814, 104561, 104520, 104566, 104448, 104502, 104567, 104562, 104580, 104581, 104533, 104467, 104451, 104478, 104468, 104498, 104524, 104534, 104547, 104584, 104458, 104449, 104575, 105800, 104462, 105818, 104483, 104551, 105820, 105823, 105825, 104662, 104664, 104650, 104652, 104666, 104632, 104659, 104656, 104614, 104658, 104588, 104651, 104638, 104660, 104634, 104611, 104610, 104623, 104621, 104617, 104683, 104696, 104697, 104701, 105829, 104604, 104619, 104612, 104609, 104404, 104668, 104655, 104643, 104657, 105834, 104602, 104645, 104680, 104503, 104688, 104665, 105830, 104597, 105832, 104595, 104685, 104681, 104669, 104599, 104616, 104624, 104537, 104648, 104672, 105833, 104635, 104684, 104649, 104631, 104517, 104667, 104558, 104592, 104699, 104698, 104593, 105831, 104689, 104682, 104686, 104640, 104626, 104630, 104644, 104646, 104615, 104605, 104606, 104622, 104647, 104594, 104608, 105828, 104679, 104637, 104639, 104661, 104642, 104598, 104600, 104654, 104618, 104538, 104620, 104607, 104596, 104504, 104673, 104677, 104522, 104641, 104709, 104714, 104613, 105838, 104705, 104708, 104713, 104712, 104704, 104710, 104722, 104725, 104723, 104746, 104781, 104769, 104775, 104742, 104735, 104674, 104743, 104737, 104736, 104738, 104744, 104703, 104765, 104752, 104751, 104766, 104762, 104758, 104771, 104763, 104627, 104702, 104727, 104721, 104628, 104700, 104728, 104754, 104715, 104706, 104729, 104730, 104747, 104774, 104778, 104695, 104783, 104718, 104719, 104717, 104770, 104726, 104731, 104768, 104764, 104776, 104777, 104675, 104690, 104676, 104748, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-19" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>B6_GDS_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="b7_fas_rc" class="section level2">
<h2>B7_FAS_RC</h2>
<pre class="r"><code>df &lt;- B7_FAS_RC

info(B7_FAS_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:435, cols:33, inds:431</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    435 obs. of  33 variables:
##  $ SYSXM        : num  8275913 8275953 8258973 8259133 8277373 ...
##  $ SYSIND       : num  11620433 11160523 11369813 11037673 11620763 ...
##  $ SYSGP        : num  8005513 7923793 7952013 7894423 8005723 ...
##  $ SYSGPSTUDY   : num  1452223 1361903 1397123 1309743 1452433 ...
##  $ SYSINDGP     : num  8389503 7923633 8139083 7793413 8389833 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  104507 87883 88301 87650 104457 ...
##  $ IND          : num  1 1 1 9000 1 1 1 1 106 9000 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE    : POSIXct, format: &quot;2023-08-09&quot; &quot;2024-02-14&quot; ...
##  $ EXAMINER     : chr  &quot;jjs2031&quot; &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1944-06-21&quot; &quot;1939-03-20&quot; ...
##  $ AGE_AT_EXAM  : num  79 84 76 68 76 81 73 86 66 56 ...
##  $ REVIEW_DATE  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER     : logi  NA NA NA NA NA NA ...
##  $ FAQ1         : num  0 8 0 8 0 0 0 0 0 0 ...
##  $ FAQ2         : num  0 0 0 8 1 0 0 0 0 0 ...
##  $ FAQ3         : num  0 0 0 8 1 0 0 0 0 0 ...
##  $ FAQ4         : num  0 0 0 8 1 0 0 0 0 0 ...
##  $ FAQ5         : num  0 0 0 8 1 0 0 0 1 0 ...
##  $ FAQ6         : num  0 0 0 8 1 0 0 0 1 0 ...
##  $ FAQ7         : num  0 0 0 8 1 0 0 0 0 0 ...
##  $ FAQ8         : num  0 0 0 8 1 0 0 0 0 0 ...
##  $ FAQ9         : num  0 0 0 8 1 0 0 0 0 0 ...
##  $ FAQ10        : num  0 2 0 8 1 0 0 0 1 0 ...
##  $ NOTES_B7FAS  : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-20" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;B7_FAS_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-20" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)]
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`,ignore.case = T)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-20" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-08-09    1944-06-21
## 2 2024-02-14    1939-03-20
## 3 2024-02-13    1947-05-13
## 4 2023-10-24    1954-10-29
## 5 2023-04-17    1946-12-19
## 6 2024-02-15    1942-09-30</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-20" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 9 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2fd3bd35c66d8fc93e1a" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2fd3bd35c66d8fc93e1a">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["jjs2031, gsv32, sjt82, mxp1257, cmanrique, prm72, kxc672, bxf258, mxl2473, v.rodriguez4, Katalina McInerney, ABIGAIL LOPEZ, cxc2077, Anisley Martinez, axl4418, lxi119, eir34, smm493, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-20" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 21 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                           &quot;1 thru 99999;&quot;             
## [3] &quot;1 thru 9999;&quot;               &quot;0;\r\n1;\r\n2;\r\n3;\r\n8;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-1850fa637b0961c79c58" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1850fa637b0961c79c58">{"x":{"filter":"none","vertical":false,"data":[["GP","FAQ4","FAQ6","FAQ8","FAQ10"],["GP","FAQ4","FAQ6","FAQ8","FAQ10"],["104507, 104457, 104476, 104528, 104556, 104455, 104511, 104549, 104552, 104500, 104525, 104497, 104531, 104518, 104472, 105801, 104469, 104521, 104496, 105806, 104499, 104514, 104487, 104526, 104548, 104554, 105805, 104475, 104456, 104471, 104532, 104516, 104539, 104466, 104477, 104459, 104529, 104481, 104464, 105803, 104508, 104453, 104545, 104589, 104572, 104564, 105809, 104542, 104461, 104557, 105807, 105808, 104519, 104578, 104470, 104515, 104591, 104575, 104447, 104474, 105826, 104547, 104574, 104573, 105824, 104570, 104582, 104583, 104450, 104513, 104510, 104590, 104568, 104473, 104480, 104544, 105813, 104482, 104562, 104563, 104484, 104571, 104569, 104494, 104565, 104586, 104585, 105819, 104536, 104490, 104479, 105811, 104509, 104579, 104448, 105814, 104561, 104566, 104502, 104567, 104580, 104581, 104533, 104467, 104478, 104468, 104498, 104534, 104584, 104458, 104449, 104451, 105800, 104462, 104560, 104483, 104551, 105823, 104486, 104636, 104650, 104652, 104666, 104632, 104640, 104658, 104588, 104651, 104656, 104634, 104611, 104610, 104623, 104621, 104617, 104683, 104684, 104604, 104619, 104612, 105829, 105833, 104609, 104655, 104643, 104657, 105834, 104645, 104680, 104665, 104688, 104685, 104681, 104669, 104599, 104616, 105830, 104624, 104537, 104648, 104633, 104649, 104638, 104504, 104503, 104522, 104667, 104558, 104517, 104672, 104593, 105831, 104682, 104686, 104626, 104644, 104646, 104606, 104622, 104647, 104608, 105832, 104637, 104594, 105828, 104639, 104642, 104598, 104600, 104654, 104618, 104538, 104620, 104607, 104677, 104641, 104613, 104714, 105838, 104708, 104710, 104722, 104746, 104781, 104775, 104758, 104735, 104674, 104743, 104723, 104712, 104754, 104736, 104744, 104769, 104703, 104751, 104765, 104771, 104763, 104702, 104774, 104700, 104721, 104727, 104715, 104706, 104752, 104730, 104778, 104695, 104718, 104719, 104761, 104766, 104770, 104726, 104768, 104777, 104625, 104675, 104690, 104676, 104748, 104783, 104603","9","9","9","9"],["1 - 99999","0;1;2;3;8","0;1;2;3;8","0;1;2;3;8","0;1;2;3;8"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-20" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>B7_FAS_RC&lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="bcf_recog_rc" class="section level2">
<h2>BCF_RECOG_RC</h2>
<pre class="r"><code>df &lt;- BCF_RECOG_RC

info(BCF_RECOG_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:266, cols:24, inds:266</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    266 obs. of  24 variables:
##  $ SYSXM                 : num  8275963 8260183 8260813 8262253 8262463 ...
##  $ SYSIND                : num  11620763 11620563 11621203 11638453 11638463 ...
##  $ SYSGP                 : num  8005723 8005633 8006163 8007003 8007013 ...
##  $ SYSGPSTUDY            : num  1452433 1452343 1452873 1453713 1453723 ...
##  $ SYSINDGP              : num  8389833 8389633 8390273 8407523 8407533 ...
##  $ CGI_ORDER             : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER             : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER          : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                : chr  &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER              : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                 : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY              : chr  &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                    : num  104457 104477 104455 104549 104548 ...
##  $ IND                   : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ REFCTR                : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE             : POSIXct, format: &quot;2023-04-17&quot; &quot;2023-05-15&quot; ...
##  $ EXAMINER              : chr  &quot;sjt82&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH         : POSIXct, format: &quot;1946-12-19&quot; &quot;1949-12-01&quot; ...
##  $ AGE_AT_EXAM           : num  76 73 81 74 80 74 73 70 81 91 ...
##  $ REVIEW_DATE           : logi  NA NA NA NA NA NA ...
##  $ REVIEWER              : logi  NA NA NA NA NA NA ...
##  $ CBF_RECOGNIZE_STIMULUS: num  0 0 1 1 1 1 0 1 1 1 ...
##  $ COMMENTS_BCFRECOGN    : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-21" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;BCF_RECOG_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-21" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;   &quot;REVIEWER&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-21" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-04-17    1946-12-19
## 2 2023-05-15    1949-12-01
## 3 2023-02-24    1941-10-04
## 4 2023-09-11    1949-05-19
## 5 2023-09-11    1942-10-17
## 6 2023-02-23    1948-11-25</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-21" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 9 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-f5a6f87aa3e3f8fd968d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-f5a6f87aa3e3f8fd968d">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["sjt82, jjs2031, gsv32, cmanrique, prm72, mxp1257, kxc672, v.rodriguez4, axl4418, mxl2473, ABIGAIL LOPEZ, cxc2077, IZRI MARTINEZ, Anisley Martinez, eir34, smm493, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-21" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 12 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-e3cccbdaf5b398562d7c" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-e3cccbdaf5b398562d7c">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104457, 104477, 104455, 104549, 104548, 104452, 104459, 104500, 104499, 104525, 104531, 104536, 104472, 104530, 104469, 104521, 104496, 104487, 104515, 104490, 104526, 104453, 105804, 104518, 104454, 104514, 104513, 105805, 104508, 104475, 104481, 104539, 104527, 104532, 104516, 104456, 104471, 104466, 104507, 104529, 104464, 105801, 104501, 105809, 104564, 104563, 104468, 104557, 104498, 105808, 105803, 105826, 105807, 104578, 104470, 104474, 104582, 104584, 104447, 104506, 104476, 104497, 104510, 104489, 104573, 104528, 104494, 104570, 104583, 104450, 104473, 104586, 104482, 104572, 104495, 105822, 104462, 104479, 105811, 104560, 104509, 104488, 104505, 104579, 105814, 104448, 104534, 104566, 104511, 104562, 104581, 104519, 104533, 104467, 104451, 105813, 104524, 104485, 104567, 104574, 104449, 104575, 104502, 104483, 105800, 104484, 104478, 105823, 104465, 105833, 104503, 104517, 104680, 104688, 104665, 104681, 104624, 104629, 104558, 104672, 104522, 104504, 104684, 104638, 104698, 104682, 104686, 104630, 104647, 104608, 105832, 104538, 104619, 104596, 104683, 105838, 104746, 104736, 104754, 104674, 104744, 104703, 104702, 104690, 104700, 104706, 104774, 104695, 104783, 104768, 104675, 104676"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-21" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>BCF_RECOG_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="bcfcd_rc" class="section level2">
<h2>BCFCD_RC</h2>
<pre class="r"><code>df &lt;- BCFCD_RC

info(BCFCD_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:269, cols:38, inds:269</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    269 obs. of  38 variables:
##  $ SYSXM                        : num  8275933 8260173 8260803 8262243 8262453 ...
##  $ SYSIND                       : num  11620763 11620563 11621203 11638453 11638463 ...
##  $ SYSGP                        : num  8005723 8005633 8006163 8007003 8007013 ...
##  $ SYSGPSTUDY                   : num  1452433 1452343 1452873 1453713 1453723 ...
##  $ SYSINDGP                     : num  8389833 8389633 8390273 8407523 8407533 ...
##  $ CGI_ORDER                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER                 : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                       : chr  &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER                     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                     : chr  &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                           : num  104457 104477 104455 104549 104548 ...
##  $ IND                          : num  1 1 1 1 1 1 1 105 1 1 ...
##  $ REFCTR                       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                    : POSIXct, format: &quot;2023-04-17&quot; &quot;2023-05-15&quot; ...
##  $ EXAMINER                     : chr  &quot;sjt82&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH                : POSIXct, format: &quot;1946-12-19&quot; &quot;1949-12-01&quot; ...
##  $ AGE_AT_EXAM                  : num  76 73 81 74 80 74 73 63 70 81 ...
##  $ REVIEW_DATE                  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                     : logi  NA NA NA NA NA NA ...
##  $ FOURSIDED_DELAY              : num  0 2 1 2 1 2 0 2 2 2 ...
##  $ STRAIGHT_LINES_DELAY         : num  0 2 1 2 2 1 0 2 2 2 ...
##  $ MIDDLETHIRD_DELAY            : num  0 0 0 1 0 1 0 2 1 0 ...
##  $ ROUND_DELAY                  : num  0 0 1 2 2 1 0 2 2 0 ...
##  $ VERTICAL_LINES_DELAY         : num  0 0 1 1 1 1 0 2 1 0 ...
##  $ BELOW3_DELAY                 : num  0 2 1 1 1 1 0 2 1 1 ...
##  $ VERTEX_DELAY                 : num  0 0 0 1 0 0 0 2 1 0 ...
##  $ GAB87_DELAY                  : num  0 1 1 1 0 1 0 1 1 1 ...
##  $ BONUS_DELAY                  : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TIME_HOUR_DELAY              : chr  &quot;01:00 PM&quot; &quot;10:23 AM&quot; &quot;01:19 PM&quot; &quot;12:21 PM&quot; ...
##  $ COMMENT_BCFDELAY             : chr  &quot;Drew a landscape&quot; NA NA NA ...
##  $ FILE_NAME1                   : chr  NA NA NA NA ...
##  $ TOTAL_SCORE_BENSON_DELAY     : num  0 7 6 11 7 8 0 15 11 6 ...
##  $ TOTAL_SCORE_BENSON_DEL_STATUS: logi  NA NA NA NA NA NA ...
##  $ PLUS_BONUS_DELAY             : num  0 7 6 11 7 8 0 15 11 6 ...
##  $ PLUS_BONUS_DELAY_STATUS      : chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-22" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;BCFCD_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-22" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 4 × 2
##   VarNames                      `Data Type`
##   &lt;chr&gt;                         &lt;chr&gt;      
## 1 REFCTR                        VARCHAR2(6)
## 2 REVIEW_DATE                   date       
## 3 REVIEWER                      CHAR       
## 4 TOTAL_SCORE_BENSON_DEL_STATUS CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## &quot;REFCTR&quot; &quot;REVIEWER&quot; &quot;TOTAL_SCORE_BENSON_DEL_STATUS&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-22" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-04-17    1946-12-19
## 2 2023-05-15    1949-12-01
## 3 2023-02-24    1941-10-04
## 4 2023-09-11    1949-05-19
## 5 2023-09-11    1942-10-17
## 6 2023-02-23    1948-11-25</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-22" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 13 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-e7db3e87314e55cb71f8" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-e7db3e87314e55cb71f8">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["sjt82, jjs2031, gsv32, cmanrique, prm72, mxp1257, kxc672, v.rodriguez4, axl4418, mxl2473, Anisley Martinez, ABIGAIL LOPEZ, cxc2077, eir34, smm493"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-22" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 22 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA               &quot;1 thru 99999;&quot;  &quot;1 thru 9999;&quot;   &quot;0;\r\n1;\r\n2;&quot;
## [5] &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2307202f99833120a8cd" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2307202f99833120a8cd">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104457, 104477, 104455, 104549, 104548, 104452, 104459, 104500, 104499, 104525, 104531, 104536, 104472, 104530, 104469, 104521, 104496, 104487, 104515, 104490, 104526, 104453, 105804, 104518, 104454, 104514, 104513, 105805, 104508, 104475, 104481, 104539, 104527, 104532, 104516, 104456, 104471, 104466, 104529, 104464, 105801, 104501, 104564, 104563, 104468, 104557, 104498, 105808, 104465, 105809, 105803, 105822, 104519, 105826, 105807, 104578, 104470, 104474, 104582, 104584, 104447, 104506, 104574, 104476, 104497, 104510, 104489, 104573, 104528, 104570, 104583, 104450, 104507, 104473, 104586, 104482, 104495, 104494, 104462, 104479, 105811, 104560, 104509, 104488, 104505, 104579, 105814, 104448, 104534, 104566, 104511, 104562, 104581, 104533, 104467, 104451, 105813, 104524, 104485, 104567, 104449, 104575, 104502, 105800, 104484, 104480, 104478, 104483, 105823, 105833, 104503, 104517, 104680, 104688, 104665, 104681, 104624, 104629, 104558, 104672, 104522, 104504, 104684, 104638, 104698, 104682, 104686, 104630, 104647, 104608, 105832, 105834, 104538, 104619, 104596, 104683, 105838, 104746, 104754, 104674, 104703, 104736, 104744, 104702, 104690, 104695, 104700, 104706, 104774, 104768, 104675, 104676"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-22" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>BCFCD_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="bcfci_rc" class="section level2">
<h2>BCFCI_RC</h2>
<pre class="r"><code>df &lt;- BCFCI_RC

info(BCFCI_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:270, cols:38, inds:270</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    270 obs. of  38 variables:
##  $ SYSXM                        : num  8260073 8260643 8260693 8261453 8278753 ...
##  $ SYSIND                       : num  11620563 11621213 11621203 11621283 11617943 ...
##  $ SYSGP                        : num  8005633 8006173 8006163 8006243 8005103 ...
##  $ SYSGPSTUDY                   : num  1452343 1452883 1452873 1452953 1451813 ...
##  $ SYSINDGP                     : num  8389633 8390283 8390273 8390353 8387013 ...
##  $ CGI_ORDER                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER                 : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                       : chr  &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER                     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                     : chr  &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                           : num  104477 104456 104455 104471 104519 ...
##  $ IND                          : num  1 1 1 1 1 1 1 105 1 1 ...
##  $ REFCTR                       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                    : POSIXct, format: &quot;2023-05-15&quot; &quot;2023-02-24&quot; ...
##  $ EXAMINER                     : chr  &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH                : POSIXct, format: &quot;1949-12-01&quot; &quot;1949-06-10&quot; ...
##  $ AGE_AT_EXAM                  : num  73 73 81 67 67 74 80 63 73 81 ...
##  $ REVIEW_DATE                  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                     : logi  NA NA NA NA NA NA ...
##  $ FOURSIDED                    : num  2 2 1 1 2 2 2 2 0 2 ...
##  $ STRAIGHT_LINES               : num  2 2 2 2 2 2 2 2 0 1 ...
##  $ MIDDLETHIRD                  : num  2 2 2 1 2 2 2 2 0 2 ...
##  $ ROUND                        : num  2 2 2 2 2 2 2 2 0 2 ...
##  $ VERTICAL_LINES               : num  2 2 2 1 2 2 2 2 0 2 ...
##  $ BELOW3                       : num  2 2 1 1 1 2 2 2 0 2 ...
##  $ VERTEX                       : num  2 2 1 1 2 2 2 2 0 2 ...
##  $ GAP87                        : num  2 2 1 1 2 2 2 2 0 2 ...
##  $ BONUS                        : num  1 1 0 0 0 1 1 1 0 0 ...
##  $ TIME_HOUR_COPY               : chr  &quot;10:13 AM&quot; &quot;10:44 AM&quot; &quot;01:08 PM&quot; &quot;11:15 AM&quot; ...
##  $ COMMENT_BCFCOPY              : chr  NA NA NA NA ...
##  $ FILE_NAME1                   : chr  NA NA NA NA ...
##  $ BCF_COPY_SCORE               : num  16 16 12 10 15 16 16 16 0 15 ...
##  $ BCF_COPY_SCORE_STATUS        : logi  NA NA NA NA NA NA ...
##  $ TOTAL_SCORE_PLUS_BONUS       : num  17 17 12 10 15 17 17 17 0 15 ...
##  $ TOTAL_SCORE_PLUS_BONUS_STATUS: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-23" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;BCFCI_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-23" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 4 × 2
##   VarNames              `Data Type`
##   &lt;chr&gt;                 &lt;chr&gt;      
## 1 REFCTR                VARCHAR2(6)
## 2 REVIEW_DATE           date       
## 3 REVIEWER              CHAR       
## 4 BCF_COPY_SCORE_STATUS CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;  &quot;REVIEWER&quot;  &quot;BCF_COPY_SCORE_STATUS&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-23" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, as it has been converted in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-05-15    1949-12-01
## 2 2023-02-24    1949-06-10
## 3 2023-02-24    1941-10-04
## 4 2023-05-08    1956-04-15
## 5 2023-08-16    1956-01-09
## 6 2023-09-11    1949-05-19</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-23" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 13 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-a77c2b4cd4432cf877d7" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a77c2b4cd4432cf877d7">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["jjs2031, gsv32, sjt82, prm72, cmanrique, mxp1257, kxc672, v.rodriguez4, mxl2473, axl4418, ABIGAIL LOPEZ, cxc2077, eir34, Anisley Martinez, smm493, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-23" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 22 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA               &quot;1 thru 99999;&quot;  &quot;1 thru 9999;&quot;   &quot;0;\r\n1;\r\n2;&quot;
## [5] &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2f2be1bc07c8330a09d1" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2f2be1bc07c8330a09d1">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104456, 104455, 104471, 104519, 104549, 104548, 104459, 104499, 104531, 104530, 104454, 104472, 104469, 104521, 104496, 104487, 104500, 104525, 105804, 104490, 104515, 104508, 104453, 104513, 104536, 104518, 104514, 104481, 105805, 104475, 104526, 104539, 104527, 104532, 104452, 104516, 104457, 104529, 104464, 104466, 105801, 104501, 104524, 104449, 104569, 105800, 104564, 104563, 104468, 104557, 104498, 104473, 105808, 105809, 105803, 104578, 104474, 104582, 104574, 104447, 104506, 104476, 104497, 104510, 104489, 104573, 104528, 104570, 105807, 104583, 104450, 104507, 104478, 104560, 104482, 104494, 104495, 105826, 104462, 104479, 105811, 104509, 104465, 104488, 104505, 105822, 104485, 104579, 104448, 105814, 104534, 104566, 104567, 104511, 104502, 104562, 104581, 104584, 104533, 105813, 104467, 104451, 104470, 104575, 104484, 104480, 105823, 104483, 104684, 105833, 104503, 105834, 104517, 104680, 104688, 104665, 104681, 104624, 104629, 104558, 104672, 104522, 104504, 104638, 104698, 104682, 104686, 104630, 104647, 104608, 105832, 104538, 104619, 104596, 104683, 105838, 104675, 104676, 104783, 104754, 104674, 104736, 104744, 104703, 104702, 104695, 104700, 104706, 104746, 104690, 104768"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-23" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>BCFCI_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="bilingual_scale_rc" class="section level2">
<h2>BILINGUAL_SCALE_RC</h2>
<pre class="r"><code>df &lt;- BILINGUAL_SCALE_RC

info(BILINGUAL_SCALE_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:240, cols:90, inds:240</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    240 obs. of  90 variables:
##  $ SYSXM               : num  8275903 8275993 8258743 8259043 8277793 ...
##  $ SYSIND              : num  11160523 11620433 11034403 11369813 11435853 ...
##  $ SYSGP               : num  7923793 8005513 7888823 7952013 7962813 ...
##  $ SYSGPSTUDY          : num  1361903 1452223 1304163 1397123 1407923 ...
##  $ SYSINDGP            : num  7923633 8389503 7790023 8139083 8205123 ...
##  $ CGI_ORDER           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER        : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY              : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER            : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY               : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY            : chr  &quot;ADCRLPRADI&quot; &quot;ADCONTROL&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER              : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                  : num  87883 104507 87556 88301 88452 ...
##  $ IND                 : num  1 1 9001 1 1 ...
##  $ REFCTR              : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE           : POSIXct, format: &quot;2024-02-14&quot; &quot;2023-08-09&quot; ...
##  $ EXAMINER            : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH       : POSIXct, format: &quot;1939-03-20&quot; &quot;1944-06-21&quot; ...
##  $ AGE_AT_EXAM         : num  84 79 68 76 81 73 86 66 81 79 ...
##  $ REVIEW_DATE         : logi  NA NA NA NA NA NA ...
##  $ REVIEWER            : logi  NA NA NA NA NA NA ...
##  $ BILING_YEAR_EDU     : num  6 12 14 14 9 20 12 12 14 7 ...
##  $ BILING_LANG         : chr  &quot;Spanish&quot; &quot;SPANISH&quot; &quot;SPANISH&quot; &quot;SPANISH&quot; ...
##  $ BILING_OTHER_LANG   : num  0 1 1 0 1 0 0 1 0 0 ...
##  $ BILINGUAL_LANG_YES1 : chr  NA &quot;ENGLISH&quot; &quot;SPANISH&quot; NA ...
##  $ BILINGUAL_LANG_YES2 : chr  NA &quot;SPANISH&quot; &quot;ENGLISH&quot; NA ...
##  $ BILINGUAL_LANG_YES3 : chr  NA NA NA NA ...
##  $ BILINGUAL_LANG_YES4 : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_REGION1   : chr  NA NA NA NA ...
##  $ BILINGUAL_REGION2   : chr  NA NA NA NA ...
##  $ BILINGUAL_REGION3   : chr  NA NA NA NA ...
##  $ BILINGUAL_REGION4   : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_LENGTH1   : chr  NA NA NA NA ...
##  $ BILINGUAL_LENGTH2   : chr  NA NA NA NA ...
##  $ BILINGUAL_LENGTH3   : chr  NA NA NA NA ...
##  $ BILINGUAL_LENGTH4   : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_LANG1     : chr  NA &quot;ENGLISH&quot; &quot;SPANISH&quot; NA ...
##  $ BILINGUAL_LANG2     : chr  NA &quot;SPANISH&quot; &quot;ENGLISH&quot; NA ...
##  $ BILINGUAL_LANG3     : chr  NA NA NA NA ...
##  $ BILINGUAL_LANG4     : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_FREQUENCY1: num  NA 7 7 NA 7 NA NA NA NA NA ...
##  $ BILINGUAL_FREQUENCY2: num  NA 7 4 NA 7 NA NA NA NA NA ...
##  $ BILINGUAL_FREQUENCY3: num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_FREQUENCY4: logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_LEARN1    : chr  NA &quot;ENGLISH&quot; &quot;SPANISH&quot; NA ...
##  $ BILINGUAL_LEARN2    : chr  NA &quot;SPANISH&quot; &quot;ENGLISH&quot; NA ...
##  $ BILINGUAL_LEARN3    : chr  NA NA NA NA ...
##  $ BILINGUAL_LEARN4    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_HOME1     : num  NA NA 1 NA NA NA NA 1 NA NA ...
##  $ BILINGUAL_HOME2     : num  NA 1 NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_HOME3     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_HOME4     : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_SCHOOL1   : num  NA NA 1 NA 8 NA NA NA NA NA ...
##  $ BILINGUAL_SCHOOL2   : num  NA 1 NA NA NA NA NA 1 NA NA ...
##  $ BILINGUAL_SCHOOL3   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_SCHOOL4   : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_MIGRAT1   : num  NA 1 NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_MIGRAT2   : num  NA NA 1 NA 27 NA NA 1 NA NA ...
##  $ BILINGUAL_MIGRAT3   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_MIGRAT4   : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_NONFORMAL1: num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_NONFORMAL2: num  NA NA NA NA NA NA NA 1 NA NA ...
##  $ BILINGUAL_NONFORMAL3: logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_NONFORMAL4: logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_OTHER1    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_OTHER2    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_OTHER3    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_OTHER4    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_RATE1     : chr  NA &quot;ENGLISH&quot; &quot;SPANISH&quot; NA ...
##  $ BILINGUAL_RATE2     : chr  NA &quot;SPANISH&quot; &quot;ENGLISH&quot; NA ...
##  $ BILINGUAL_RATE3     : chr  NA NA NA NA ...
##  $ BILINGUAL_RATE4     : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_READ1     : num  NA 7 7 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_READ2     : num  NA 7 4 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_READ3     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_READ4     : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_WRITE1    : num  NA 7 7 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_WRITE2    : num  NA 7 4 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_WRITE3    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_SPEAK1    : num  NA 7 7 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_WRITE4    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_SPEAK2    : num  NA 7 4 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_SPEAK3    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_SPEAK4    : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_LISTEN1   : num  NA 7 7 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_LISTEN2   : num  NA 7 4 NA 7 NA NA 7 NA NA ...
##  $ BILINGUAL_LISTEN3   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BILINGUAL_LISTEN4   : logi  NA NA NA NA NA NA ...
##  $ BILINGUAL_TIME      : num  NA NA NA NA 20 NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-24" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;BILINGUAL_SCALE_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-24" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 23 vars

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 23 × 2
##    VarNames             `Data Type` 
##    &lt;chr&gt;                &lt;chr&gt;       
##  1 REFCTR               VARCHAR2(6) 
##  2 REVIEW_DATE          date        
##  3 REVIEWER             CHAR        
##  4 BILINGUAL_LANG_YES4  VARCHAR2(25)
##  5 BILINGUAL_REGION4    VARCHAR2(10)
##  6 BILINGUAL_LENGTH4    VARCHAR2(25)
##  7 BILINGUAL_LANG4      VARCHAR2(25)
##  8 BILINGUAL_FREQUENCY4 NUMBER(2)   
##  9 BILINGUAL_LEARN4     VARCHAR2(25)
## 10 BILINGUAL_HOME4      NUMBER(2)   
## # ℹ 13 more rows</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)]

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date))

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-24" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-14    1939-03-20
## 2 2023-08-09    1944-06-21
## 3 2023-06-22    1954-08-20
## 4 2024-02-13    1947-05-13
## 5 2024-02-15    1942-09-30
## 6 2023-05-15    1950-04-02</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-24" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 33 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-b6f71b7327c3371a16f5" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-b6f71b7327c3371a16f5">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, cmanrique, bxf258, v.rodriguez4, axl4418, sjt82, ABIGAIL LOPEZ, mxp1257, mxl2473, Anisley Martinez, cxc2077, eir34, lxi119"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-24" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 15 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                                      
## [2] &quot;1 thru 99999;&quot;                         
## [3] &quot;1 thru 9999;&quot;                          
## [4] &quot;0;\r\n1;&quot;                              
## [5] &quot;1;\r\n2;\r\n3;\r\n4;\r\n5;\r\n6;\r\n7;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-c43e11a9c1219da54a1f" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-c43e11a9c1219da54a1f">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104507, 104476, 104528, 104455, 104511, 104452, 104525, 104497, 104531, 104518, 104536, 104472, 104469, 104521, 104499, 104514, 104496, 104487, 104515, 104490, 104453, 104526, 104454, 104513, 104508, 104456, 104527, 105805, 104512, 104516, 104539, 105806, 104466, 104477, 104500, 105803, 104564, 104542, 104557, 105808, 104484, 104553, 105807, 104495, 104578, 105809, 105813, 104590, 104575, 104447, 104474, 105826, 104574, 104573, 104570, 104519, 104510, 104591, 104473, 105811, 104562, 105814, 104529, 104563, 104475, 104541, 104479, 104509, 104579, 104555, 104470, 104561, 104520, 104566, 104502, 104580, 104581, 104533, 104524, 104534, 104449, 104483, 104451, 105823, 104636, 104650, 104632, 104611, 104501, 104681, 104517, 104619, 105833, 104468, 104680, 104609, 104665, 104688, 104666, 105830, 104633, 104649, 104638, 104652, 104522, 104558, 104682, 104634, 104623, 104503, 104637, 104631, 105831, 104600, 104618, 104504, 105838, 104722, 104746, 104775, 104758, 104735, 104674, 104743, 104754, 104703, 104744, 104769, 104771, 104702, 104700, 104781, 104695, 104718, 104761, 104770, 104726, 104768, 104675"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-24" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>BILINGUAL_SCALE_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="cat_fluency_rc" class="section level2">
<h2>CAT_FLUENCY_RC</h2>
<pre class="r"><code>df &lt;- CAT_FLUENCY_RC

info(CAT_FLUENCY_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:555, cols:29, inds:550</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    555 obs. of  29 variables:
##  $ SYSXM        : num  8276513 8258853 8258903 8260133 8277653 ...
##  $ SYSIND       : num  11369703 11369813 11037673 11620563 11435853 ...
##  $ SYSGP        : num  7951913 7952013 7894423 8005633 7962813 ...
##  $ SYSGPSTUDY   : num  1397023 1397123 1309743 1452343 1407923 ...
##  $ SYSINDGP     : num  8138973 8139083 7793413 8389633 8205123 ...
##  $ CGI_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER     : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY     : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER       : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP           : num  88299 88301 87650 104477 88452 ...
##  $ IND          : num  1 1 9000 1 1 ...
##  $ REFCTR       : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE    : POSIXct, format: &quot;2024-02-13&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER     : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH: POSIXct, format: &quot;1944-09-22&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM  : num  79 76 68 73 81 86 81 73 60 79 ...
##  $ REVIEW_DATE  : logi  NA NA NA NA NA NA ...
##  $ REVIEWER     : logi  NA NA NA NA NA NA ...
##  $ ANIM_ENTRY   : chr  &quot;perro, gato, pajaritos, jirafa, cerditos, conejo, paloma, vaca, bueyes, hipopotamos, peces, aguila, avestruz, guinea&quot; &quot;ELEFANTE VACA CHIVE PERRO BUFALO CERDO TORO HORMISA&quot; &quot;perro, conejo, gato, gallina, elefante, caballo, paloma, gato, mono, leon, jirafa, lagartijo, raton, culebra&quot; &quot;DOG CAT BIRD LION CAMEL HORSE ZEBRA CHIT... MONKEY MULE DONKEY OSTRICH PARROT EAGLE Moj... RAT COCKROACH FISH SHARK SARDINE&quot; ...
##  $ ANIM_SCORE   : num  14 8 13 20 19 12 20 17 25 11 ...
##  $ ANIM_STATUS  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VEG_ENTRY    : chr  &quot;tomate, lechuga, ganganbo, repollo, peti poas, calabaza&quot; &quot;BAFATA NAME YAUTIA PAPA MALAGA ZANCHORIA APIO HABICHUELA TERNIA MAIZ&quot; &quot;platano, yautia, name, chayote, pepinillo, remolacha, esparrago, repollo, lechuga, tomate, papa, habichuelas&quot; &quot;MALANGA PUMPKIN PLANTAIN YUCA CORN PEAR (X)  PEACH (X) GRAPE (X) STRAWBERRY (X) Sapote (X) Mamey (X) WATERMELON&quot;| __truncated__ ...
##  $ VEG_SCORE    : num  6 9 14 9 13 11 15 8 16 7 ...
##  $ VEG_STATUS   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NOTE_CATEGORY: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-25" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CAT_FLUENCY_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-25" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;   &quot;REVIEWER&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-25" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-13    1944-09-22
## 2 2024-02-13    1947-05-13
## 3 2023-10-24    1954-10-29
## 4 2023-05-15    1949-12-01
## 5 2024-02-15    1942-09-30
## 6 2023-05-09    1936-05-22</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-25" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 11 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-a0ea44eccac4877c5c6d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a0ea44eccac4877c5c6d">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, ols36, sjt82, prm72, cmanrique, mxp1257, kxc672, axl4418, v.rodriguez4, mxl2473, smm493, Katalina McInerney, Izri Martinez, ABIGAIL LOPEZ, bxf258, Katalina Fernandez M, cxc2077, Anisley Martinez, lxi119, eir34, axr1589, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-25" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 15 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                             &quot;1 thru 99999;&quot;               
## [3] &quot;1 thru 9999;&quot;                 &quot;995;\r\n996;\r\n997;\r\n998;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-3b1dcc0f247b04cdcedc" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-3b1dcc0f247b04cdcedc">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104528, 104455, 104456, 104556, 104471, 104511, 104519, 104549, 104548, 104452, 104459, 104499, 104497, 104531, 104472, 104530, 105806, 104469, 104521, 104496, 104500, 104525, 104487, 104490, 104515, 104526, 104453, 104513, 105804, 104536, 104518, 104454, 104514, 104554, 104481, 105805, 104508, 104475, 104539, 104527, 104532, 104552, 104512, 104516, 104507, 104457, 104529, 104464, 104476, 104466, 105801, 104501, 104489, 104586, 105817, 105821, 104565, 104564, 104563, 105809, 104535, 105826, 104542, 104541, 104557, 104403, 105815, 104473, 105808, 105803, 105814, 104540, 105807, 104578, 104474, 104582, 104574, 104584, 104447, 104571, 104506, 104573, 105824, 104494, 104468, 104570, 104583, 104450, 105813, 104568, 104546, 104585, 104478, 104482, 105818, 105816, 104560, 104484, 104569, 105827, 104572, 104495, 105819, 104462, 104479, 105811, 104523, 104509, 104465, 104488, 104505, 105822, 104485, 104579, 104534, 104561, 104520, 104566, 104567, 104448, 104502, 104562, 104580, 104581, 104533, 105810, 104467, 104451, 104555, 104498, 104524, 104510, 104449, 104470, 104575, 105800, 104480, 104483, 105823, 105825, 104636, 104594, 104662, 104664, 104616, 104652, 104666, 104632, 104626, 104656, 104640, 104614, 104588, 104599, 104651, 104657, 104658, 104634, 104610, 104623, 104621, 104617, 104684, 104679, 104696, 104697, 105833, 104604, 104619, 104612, 105829, 104655, 104668, 104643, 104654, 104602, 104645, 104680, 104685, 104688, 104600, 104665, 104597, 104595, 104681, 104669, 105830, 104618, 105832, 104537, 104648, 104672, 105834, 104638, 104635, 104522, 104517, 104558, 104677, 104667, 104699, 104698, 104593, 105831, 104689, 104682, 104686, 104611, 104644, 104646, 104605, 104606, 104622, 104647, 104608, 105828, 104631, 104639, 104661, 104642, 104598, 104637, 104504, 104538, 104503, 104620, 104609, 104607, 104596, 104650, 104624, 104641, 104683, 104592, 104649, 104709, 104714, 104711, 104613, 105838, 104708, 104705, 104704, 104713, 104712, 104710, 104724, 104725, 104723, 104720, 104747, 104676, 104775, 104719, 104718, 104717, 104754, 104738, 104743, 104742, 104735, 104761, 104674, 104736, 104740, 104744, 104769, 104703, 104765, 104752, 104758, 104762, 104766, 104770, 104771, 104627, 104702, 104781, 104727, 104721, 104728, 104726, 104695, 104700, 104734, 104715, 104706, 104746, 104722, 104730, 104690, 104774, 104778, 104783, 104748, 104737, 104731, 104729, 104751, 104768, 104764, 104776, 104777, 104675, 104763, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-25" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CAT_FLUENCY_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="cerad_del_rc" class="section level2">
<h2>CERAD_DEL_RC</h2>
<pre class="r"><code>df &lt;- CERAD_DEL_RC

info(CERAD_DEL_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:177, cols:44, inds:177</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    177 obs. of  44 variables:
##  $ SYSXM                    : num  8275853 8260563 8278733 8264043 8264683 ...
##  $ SYSIND                   : num  11160523 11163453 11618053 11620393 11617573 ...
##  $ SYSGP                    : num  7923793 7924953 8005213 8005493 8004733 ...
##  $ SYSGPSTUDY               : num  1361903 1363063 1451923 1452203 1451443 ...
##  $ SYSINDGP                 : num  7923633 7926663 8387123 8389463 8386643 ...
##  $ CGI_ORDER                : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER             : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                   : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER                 : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                    : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                 : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                   : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                       : num  87883 87923 104511 104500 104525 ...
##  $ IND                      : num  1 9000 1 1 1 105 110 1 1 1 ...
##  $ REFCTR                   : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                : POSIXct, format: &quot;2024-02-14&quot; &quot;2023-10-25&quot; ...
##  $ EXAMINER                 : chr  &quot;gsv32&quot; &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH            : POSIXct, format: &quot;1939-03-20&quot; &quot;1967-06-15&quot; ...
##  $ AGE_AT_EXAM              : num  84 56 77 70 91 63 65 64 76 81 ...
##  $ REVIEW_DATE              : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                 : logi  NA NA NA NA NA NA ...
##  $ WLM_CRTA                 : num  1 0 1 1 1 0 0 1 1 1 ...
##  $ WLM_CRTB                 : num  0 0 0 0 0 1 1 1 1 0 ...
##  $ WLM_CRTC                 : num  0 1 0 0 0 0 0 1 1 1 ...
##  $ WLM_CRTD                 : num  0 0 0 1 0 0 0 1 0 0 ...
##  $ WLM_CRTE                 : num  0 0 1 1 1 1 1 1 0 1 ...
##  $ WLM_CRTF                 : num  0 0 0 0 0 1 0 1 0 1 ...
##  $ WLM_CRTG                 : num  0 1 0 1 0 1 0 0 1 1 ...
##  $ WLM_CRTH                 : num  0 0 1 0 0 1 0 1 1 0 ...
##  $ WLM_CRTI                 : num  0 0 0 1 0 0 0 1 0 1 ...
##  $ WLM_CRTJ                 : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ WLM_INT1                 : num  1 1 NA NA NA NA NA NA NA NA ...
##  $ WLM_INT2                 : num  NA 1 NA NA NA NA NA NA NA NA ...
##  $ WLM_INT3                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_INT4                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_INT5                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NOTES_CERADRECALL        : chr  NA NA NA NA ...
##  $ WLM_CRT                  : num  1 2 3 5 2 5 2 8 5 6 ...
##  $ WLM_CRT_STATUS           : chr  NA NA NA NA ...
##  $ WLM_INT                  : num  1 2 NA NA NA NA NA NA NA NA ...
##  $ WLM_INT_STATUS           : chr  &quot;partial&quot; &quot;partial&quot; NA NA ...
##  $ SCALES_CERADRECALL       : chr  &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;7&quot; ...
##  $ SCALES_CERADRECALL_STATUS: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-26" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CERAD_DEL_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-26" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;   &quot;REVIEWER&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-26" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-14    1939-03-20
## 2 2023-10-25    1967-06-15
## 3 2023-08-11    1946-06-19
## 4 2023-08-14    1952-08-29
## 5 2023-08-18    1931-09-20
## 6 2023-06-19    1960-06-04</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-26" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 13 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## [1] SCALES_CERADRECALL
## SCALES_CERADRECALL shows numeric in DD, but read in as character
## the reason it pops up is because they use &quot;na&quot; to represent the NAs
## I will correct it and convert it to numeric

df$SCALES_CERADRECALL[df$SCALES_CERADRECALL == &quot;na&quot;] &lt;- NA
unique(df$SCALES_CERADRECALL)</code></pre>
<pre><code>## [1] &quot;3&quot;  &quot;4&quot;  &quot;5&quot;  &quot;7&quot;  &quot;11&quot; &quot;8&quot;  NA   &quot;10&quot; &quot;13&quot;</code></pre>
<pre class="r"><code>df$SCALES_CERADRECALL &lt;- as.numeric(df$SCALES_CERADRECALL)

mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-c73dab34e007b46b6035" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-c73dab34e007b46b6035">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, cmanrique, jmccauley, Anisley Martinez, mxl2473, ABIGAIL LOPEZ, cxc2077, v.rodriguez4, mxp1257, eir34, smm493, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-26" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 29 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;\r\n0;&quot;     
## [5] &quot;1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-eb656505823a1e6f614a" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-eb656505823a1e6f614a">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104511, 104500, 104525, 104518, 104499, 104536, 104514, 104490, 104526, 104513, 104539, 104527, 104501, 104498, 104569, 104494, 104557, 105822, 104519, 105807, 104578, 105826, 104574, 104570, 104582, 104583, 104507, 105813, 104506, 104510, 105809, 104563, 104562, 104495, 104586, 104585, 105811, 104560, 104488, 104505, 104579, 105814, 104566, 104502, 104567, 104581, 104524, 104584, 104575, 105823, 104638, 104619, 105834, 104688, 104665, 104503, 104517, 104672, 104698, 104686, 104504, 104522, 104709, 104711, 104714, 105838, 104708, 104713, 104712, 104705, 104704, 104710, 104722, 104717, 104724, 104725, 104723, 104746, 104734, 104781, 104775, 104742, 104735, 104743, 104737, 104738, 104736, 104744, 104765, 104752, 104751, 104766, 104762, 104758, 104771, 104727, 104721, 104728, 104754, 104706, 104730, 104719, 104747, 104774, 104778, 104695, 104783, 104718, 104715, 104720, 104761, 104770, 104731, 104729, 104768, 104769, 104764, 104776, 104777, 104763, 104675, 104748"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-26" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CERAD_DEL_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="cerad_imm_rc" class="section level2">
<h2>CERAD_IMM_RC</h2>
<pre class="r"><code>df &lt;- CERAD_IMM_RC

info(CERAD_IMM_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:188, cols:88, inds:188</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    188 obs. of  88 variables:
##  $ SYSXM                    : num  8260413 8278683 8264003 8264323 8264633 ...
##  $ SYSIND                   : num  11163453 11618053 11620393 11618173 11617573 ...
##  $ SYSGP                    : num  7924953 8005213 8005493 8005333 8004733 ...
##  $ SYSGPSTUDY               : num  1363063 1451923 1452203 1452043 1451443 ...
##  $ SYSINDGP                 : num  7926663 8387123 8389463 8387243 8386643 ...
##  $ CGI_ORDER                : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER             : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                   : chr  &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER                 : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                    : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                 : chr  &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                   : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                       : num  87923 104511 104500 104499 104525 ...
##  $ IND                      : num  9000 1 1 1 1 105 110 1 1 1 ...
##  $ REFCTR                   : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                : POSIXct, format: &quot;2023-10-25&quot; &quot;2023-08-11&quot; ...
##  $ EXAMINER                 : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH            : POSIXct, format: &quot;1967-06-15&quot; &quot;1946-06-19&quot; ...
##  $ AGE_AT_EXAM              : num  56 77 70 81 91 63 65 69 76 83 ...
##  $ REVIEW_DATE              : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                 : logi  NA NA NA NA NA NA ...
##  $ CERAD_PRESENTATION       : num  1 2 2 1 2 1 1 2 1 2 ...
##  $ WLM_1A                   : num  0 1 1 1 1 NA NA 1 1 1 ...
##  $ WLM_1B                   : num  0 0 0 NA NA NA NA 1 NA 0 ...
##  $ WLM_1C                   : num  0 1 0 1 NA NA 1 1 1 1 ...
##  $ WLM_1D                   : num  0 0 0 NA NA NA NA NA NA 0 ...
##  $ WLM_1E                   : num  0 0 0 NA NA 1 NA NA NA 0 ...
##  $ WLM_1F                   : num  0 0 1 NA NA NA NA 1 NA 0 ...
##  $ WLM_1G                   : num  0 0 0 NA NA NA NA 1 NA 0 ...
##  $ WLM_1H                   : num  0 0 0 NA NA NA 1 NA NA 0 ...
##  $ WLM_1I                   : num  0 0 0 1 NA 1 NA NA NA 0 ...
##  $ WLM_1J                   : num  0 0 1 1 1 1 1 1 1 1 ...
##  $ WLM_1INT1                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_1INT2                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_1INT3                : logi  NA NA NA NA NA NA ...
##  $ WLM_1INT4                : logi  NA NA NA NA NA NA ...
##  $ WLM_1INT5                : logi  NA NA NA NA NA NA ...
##  $ WLM_1INT6                : logi  NA NA NA NA NA NA ...
##  $ WLM_2H                   : num  1 1 1 0 0 1 1 0 1 0 ...
##  $ WLM_2F                   : num  0 0 1 1 0 1 1 1 0 0 ...
##  $ WLM_2A                   : num  0 1 1 1 1 0 1 1 1 1 ...
##  $ WLM_2C                   : num  1 0 0 1 1 1 0 0 1 1 ...
##  $ WLM_2J                   : num  1 0 0 1 1 1 0 0 1 0 ...
##  $ WLM_2B                   : num  1 0 0 1 0 1 0 1 1 1 ...
##  $ WLM_2E                   : num  0 0 0 1 0 1 0 0 0 0 ...
##  $ WLM_2D                   : num  1 1 0 0 0 0 1 0 0 0 ...
##  $ WLM_2G                   : num  0 0 1 1 0 0 1 1 0 1 ...
##  $ WLM_2I                   : num  1 0 1 1 0 1 1 0 1 1 ...
##  $ WLM_2INT1                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_2INT2                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_2INT3                : logi  NA NA NA NA NA NA ...
##  $ WLM_2INT4                : logi  NA NA NA NA NA NA ...
##  $ WLM_2INT5                : logi  NA NA NA NA NA NA ...
##  $ WLM_2INT6                : logi  NA NA NA NA NA NA ...
##  $ WLM_3E                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ WLM_3I                   : num  0 0 1 1 0 0 0 0 0 0 ...
##  $ WLM_3B                   : num  1 1 0 1 0 0 1 1 1 0 ...
##  $ WLM_3F                   : num  1 1 1 1 0 1 1 1 0 0 ...
##  $ WLM_3G                   : num  1 0 1 1 0 1 0 1 1 0 ...
##  $ WLM_3C                   : num  0 0 0 1 1 1 1 1 1 1 ...
##  $ WLM_3A                   : num  0 1 1 1 1 1 1 1 1 0 ...
##  $ WLM_3J                   : num  1 0 0 0 0 0 1 0 1 1 ...
##  $ WLM_3H                   : num  1 0 1 0 1 1 0 1 1 1 ...
##  $ WLM_3D                   : num  0 1 1 1 1 1 1 0 1 1 ...
##  $ WLM_3INT1                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_3INT2                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_3INT3                : logi  NA NA NA NA NA NA ...
##  $ WLM_3INT4                : logi  NA NA NA NA NA NA ...
##  $ WLM_3INT5                : logi  NA NA NA NA NA NA ...
##  $ WLM_3INT6                : logi  NA NA NA NA NA NA ...
##  $ COMMENTS_CERAD           : chr  NA NA NA NA ...
##  $ WLM_1                    : num  0 2 3 4 2 3 3 6 3 3 ...
##  $ WLM_1_STATUS             : chr  NA NA NA &quot;partial&quot; ...
##  $ WLM_1INT                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_1INT_STATUS          : chr  NA NA NA NA ...
##  $ WLM_2                    : num  6 3 5 8 3 7 6 4 6 5 ...
##  $ WLM_2_STATUS             : chr  NA NA NA NA ...
##  $ WLM_2INT                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_2INT_STATUS          : chr  NA NA NA NA ...
##  $ WLM_3                    : num  6 5 7 8 5 7 7 7 8 4 ...
##  $ WLM_3_STATUS             : chr  NA NA NA NA ...
##  $ WLM_3INT                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WLM_3INT_STATUS          : chr  NA NA NA NA ...
##  $ RAWSCORE_CERAD           : num  12 10 15 20 10 17 16 17 17 12 ...
##  $ RAWSCORE_CERAD_STATUS    : chr  NA NA NA &quot;partial&quot; ...
##  $ SCALESCORE_CERAD_2       : num  4 4 5 11 4 6 6 6 6 4 ...
##  $ SCALESCORE_CERAD_2_STATUS: chr  NA NA NA &quot;partial&quot; ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-27" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CERAD_IMM_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-27" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 15 × 2
##    VarNames    `Data Type`
##    &lt;chr&gt;       &lt;chr&gt;      
##  1 REFCTR      VARCHAR2(6)
##  2 REVIEW_DATE date       
##  3 REVIEWER    CHAR       
##  4 WLM_1INT3   NUMBER(1)  
##  5 WLM_1INT4   NUMBER(1)  
##  6 WLM_1INT5   NUMBER(1)  
##  7 WLM_1INT6   NUMBER(1)  
##  8 WLM_2INT3   NUMBER(1)  
##  9 WLM_2INT4   NUMBER(1)  
## 10 WLM_2INT5   NUMBER(1)  
## 11 WLM_2INT6   NUMBER(1)  
## 12 WLM_3INT3   NUMBER(1)  
## 13 WLM_3INT4   NUMBER(1)  
## 14 WLM_3INT5   NUMBER(1)  
## 15 WLM_3INT6   NUMBER(1)</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)]

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;   &quot;REVIEWER&quot;

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-27" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-10-25    1967-06-15
## 2 2023-08-11    1946-06-19
## 3 2023-08-14    1952-08-29
## 4 2023-08-07    1941-09-10
## 5 2023-08-18    1931-09-20
## 6 2023-06-19    1960-06-04</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-27" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 17 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-1c87734e415302efed85" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1c87734e415302efed85">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, cmanrique, mxl2473, Anisley Martinez, v.rodriguez4, ABIGAIL LOPEZ, cxc2077, mxp1257, eir34, smm493, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-27" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 68 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;\r\n2;&quot;     
## [5] &quot;1;\r\n0;&quot;      &quot;1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-a9e8d1669e1ded33833f" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a9e8d1669e1ded33833f">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104511, 104500, 104499, 104525, 104536, 104487, 104490, 104526, 104518, 104514, 104513, 104539, 104527, 104507, 104501, 104489, 105809, 104498, 104569, 104565, 104563, 104557, 105822, 104519, 105826, 105807, 104578, 104582, 104584, 104574, 104585, 104506, 104494, 104570, 104583, 105813, 104510, 104495, 104586, 104572, 105811, 104560, 104488, 104505, 104579, 105814, 104566, 104502, 104562, 104581, 104524, 104567, 104575, 105823, 104638, 104619, 104688, 104665, 104624, 104672, 104517, 104698, 104503, 104686, 105834, 104504, 104522, 104709, 104714, 104711, 105838, 104704, 104705, 104708, 104713, 104712, 104710, 104722, 104717, 104724, 104725, 104723, 104720, 104746, 104734, 104781, 104775, 104718, 104754, 104742, 104735, 104761, 104743, 104737, 104738, 104736, 104744, 104769, 104765, 104752, 104751, 104762, 104766, 104758, 104771, 104727, 104721, 104728, 104715, 104706, 104730, 104747, 104774, 104778, 104695, 104783, 104719, 104770, 104726, 104731, 104729, 104768, 104764, 104776, 104777, 104763, 104675, 104748"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-27" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CERAD_IMM_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="cerad_recog_rc" class="section level2">
<h2>CERAD_RECOG_RC</h2>
<pre class="r"><code>df &lt;- CERAD_RECOG_RC

info(CERAD_RECOG_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:177, cols:48, inds:177</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    177 obs. of  48 variables:
##  $ SYSXM          : num  8275863 8260583 8278763 8264053 8264793 ...
##  $ SYSIND         : num  11160523 11163453 11618053 11620393 11617573 ...
##  $ SYSGP          : num  7923793 7924953 8005213 8005493 8004733 ...
##  $ SYSGPSTUDY     : num  1361903 1363063 1451923 1452203 1451443 ...
##  $ SYSINDGP       : num  7923633 7926663 8387123 8389463 8386643 ...
##  $ CGI_ORDER      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER   : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY         : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER       : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY          : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER         : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP             : num  87883 87923 104511 104500 104525 ...
##  $ IND            : num  1 9000 1 1 1 105 110 1 1 1 ...
##  $ REFCTR         : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE      : POSIXct, format: &quot;2024-02-14&quot; &quot;2023-10-25&quot; ...
##  $ EXAMINER       : chr  &quot;gsv32&quot; &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH  : POSIXct, format: &quot;1939-03-20&quot; &quot;1967-06-15&quot; ...
##  $ AGE_AT_EXAM    : num  84 56 77 70 91 63 65 76 81 69 ...
##  $ REVIEW_DATE    : logi  NA NA NA NA NA NA ...
##  $ REVIEWER       : logi  NA NA NA NA NA NA ...
##  $ WLRG_PRESENT   : num  1 1 2 2 2 1 1 1 1 2 ...
##  $ WLRG_K         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_L         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_A         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_M         : num  1 1 0 1 1 1 1 1 1 1 ...
##  $ WLRG_B         : num  0 1 1 1 0 1 1 1 1 1 ...
##  $ WLRG_C         : num  0 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_N         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_D         : num  0 1 1 1 0 1 0 0 0 1 ...
##  $ WLRG_O         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_P         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_E         : num  1 1 1 1 1 1 1 0 1 1 ...
##  $ WLRG_F         : num  0 0 1 1 1 1 1 1 1 1 ...
##  $ WLRG_Q         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_G         : num  0 1 0 1 0 1 0 1 1 1 ...
##  $ WLRG_R         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_S         : num  0 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_H         : num  0 1 1 1 0 1 1 1 0 1 ...
##  $ WLRG_T         : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ WLRG_I         : num  0 1 1 1 1 1 0 1 1 1 ...
##  $ WLRG_J         : num  0 1 1 1 1 1 0 1 1 1 ...
##  $ COMMENTS_WLRG  : chr  NA NA NA NA ...
##  $ WLRG_YES       : num  2 9 9 10 6 10 6 8 8 10 ...
##  $ WLRG_YES_STATUS: logi  NA NA NA NA NA NA ...
##  $ WLRG_NO        : num  9 10 9 10 10 10 10 10 10 10 ...
##  $ WLRG_NO_STATUS : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-28" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CERAD_RECOG_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-28" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 5 × 2
##   VarNames        `Data Type`
##   &lt;chr&gt;           &lt;chr&gt;      
## 1 REFCTR          VARCHAR2(6)
## 2 REVIEW_DATE     date       
## 3 REVIEWER        CHAR       
## 4 WLRG_YES_STATUS CHAR       
## 5 WLRG_NO_STATUS  CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;  &quot;REVIEWER&quot; &quot;WLRG_YES_STATUS&quot; &quot;WLRG_NO_STATUS&quot; 

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-28" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-14    1939-03-20
## 2 2023-10-25    1967-06-15
## 3 2023-08-11    1946-06-19
## 4 2023-08-14    1952-08-29
## 5 2023-09-18    1931-09-20
## 6 2023-06-19    1960-06-04</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-28" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 11 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-fc7f71da14178c45ba73" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-fc7f71da14178c45ba73">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["gsv32, jjs2031, cmanrique, mxd4459, Anisley Martinez, mxl2473, ABIGAIL LOPEZ, ladams4, cxc2077, v.rodriguez4, mxp1257, eir34, smm493, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-28" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 34 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;\r\n2;&quot;     
## [5] &quot;1;\r\n0;&quot;      &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-dad206b61ad5eb1608ba" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-dad206b61ad5eb1608ba">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104511, 104500, 104525, 104499, 104536, 104514, 104526, 104513, 104539, 104527, 104501, 104498, 104569, 104565, 104494, 104557, 105822, 104519, 105807, 104578, 105826, 104574, 104570, 104582, 104583, 104507, 105813, 104506, 104510, 105809, 104563, 104495, 104586, 104585, 104490, 105811, 104488, 104505, 104579, 105814, 104566, 104502, 104567, 104562, 104581, 104524, 104584, 104575, 104560, 105823, 104619, 105834, 104688, 104665, 104624, 104638, 104504, 104503, 104517, 104672, 104698, 104686, 104522, 104709, 104711, 105838, 104708, 104713, 104712, 104714, 104705, 104704, 104710, 104722, 104717, 104724, 104725, 104723, 104746, 104734, 104781, 104775, 104758, 104742, 104735, 104743, 104737, 104736, 104744, 104752, 104751, 104765, 104766, 104762, 104771, 104763, 104727, 104721, 104728, 104754, 104706, 104720, 104729, 104730, 104747, 104774, 104778, 104695, 104783, 104718, 104719, 104715, 104761, 104770, 104731, 104768, 104769, 104764, 104776, 104777, 104675, 104748"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-28" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CERAD_RECOG_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="consensus_dx" class="section level2">
<h2>CONSENSUS_DX</h2>
<pre class="r"><code>df &lt;- CONSENSUS_DX

info(CONSENSUS_DX,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1807, cols:43, inds:1584</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    1807 obs. of  43 variables:
##  $ SYSXM            : num  7583263 7583273 7583283 7583293 7583303 ...
##  $ SYSIND           : num  11039963 11063713 11063723 11063703 11064573 ...
##  $ SYSGP            : num  7896303 7896303 7896303 7896303 7896953 ...
##  $ SYSGPSTUDY       : num  1311623 1311623 1311623 1311623 1312273 ...
##  $ SYSINDGP         : num  7795703 7822643 7822653 7822633 7823493 ...
##  $ CGI_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER     : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY           : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER         : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY            : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY         : chr  &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER           : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP               : num  87663 87663 87663 87663 87682 ...
##  $ IND              : num  101 115 116 113 1008 ...
##  $ REFCTR           : logi  NA NA NA NA NA NA ...
##  $ REVIEW_DATE      : POSIXct, format: &quot;2018-07-11&quot; &quot;2018-07-11&quot; ...
##  $ REVIEWER         : chr  &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; &quot;v.rodriguez4&quot; ...
##  $ DATE_OF_BIRTH    : POSIXct, format: &quot;1943-10-18&quot; &quot;1939-08-25&quot; ...
##  $ RANK             : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ CDX              : chr  &quot;Alzheimers Disease&quot; &quot;Alzheimers Disease&quot; &quot;Alzheimers Disease&quot; &quot;Alzheimers Disease&quot; ...
##  $ SUB_DX           : chr  NA NA NA NA ...
##  $ IMPRESSION       : chr  &quot;POSSIBLE&quot; &quot;POSSIBLE&quot; &quot;POSSIBLE&quot; &quot;POSSIBLE&quot; ...
##  $ WHO_DX           : chr  &quot;MC,KC,VR&quot; &quot;MC,KC,VR&quot; &quot;MC,KC,VR&quot; &quot;MC,KC,VR&quot; ...
##  $ DATE_DX          : POSIXct, format: &quot;2018-07-11&quot; &quot;2018-07-11&quot; ...
##  $ COMMENTS         : chr  NA NA NA NA ...
##  $ CLINICAL_COMMENTS: logi  NA NA NA NA NA NA ...
##  $ OTHER_TXT1       : logi  NA NA NA NA NA NA ...
##  $ OTHER_TXT2       : logi  NA NA NA NA NA NA ...
##  $ OTHER_TXT3       : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL1        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL2        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL3        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL4        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL5        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL6        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL7        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL8        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL9        : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL10       : logi  NA NA NA NA NA NA ...
##  $ CALC_VAL11       : logi  NA NA NA NA NA NA ...
##  $ LAST_SOURCE      : chr  &quot;CHIMERA_USER&quot; &quot;CHIMERA_USER&quot; &quot;CHIMERA_USER&quot; &quot;CHIMERA_USER&quot; ...
##  $ OTHER_DATE1      : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-29" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CONSENSUS_DX&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-29" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 17 × 2
##    VarNames          `Data Type`
##    &lt;chr&gt;             &lt;chr&gt;      
##  1 REFCTR            VARCHAR2(6)
##  2 CLINICAL_COMMENTS CHAR       
##  3 OTHER_TXT1        CHAR       
##  4 OTHER_TXT2        CHAR       
##  5 OTHER_TXT3        CHAR       
##  6 CALC_VAL1         NUMBER     
##  7 CALC_VAL2         NUMBER     
##  8 CALC_VAL3         NUMBER     
##  9 CALC_VAL4         NUMBER     
## 10 CALC_VAL5         NUMBER     
## 11 CALC_VAL6         NUMBER     
## 12 CALC_VAL7         NUMBER     
## 13 CALC_VAL8         NUMBER     
## 14 CALC_VAL9         NUMBER     
## 15 CALC_VAL10        NUMBER     
## 16 CALC_VAL11        NUMBER     
## 17 OTHER_DATE1       DATE</code></pre>
<pre class="r"><code>## select the vars to be converted to numeric
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`)] 
## 11 vars

## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## OTHER_DATE1

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) 
## &quot;REFCTR&quot;  &quot;CLINICAL_COMMENTS&quot; &quot;OTHER_TXT1&quot;  &quot;OTHER_TXT2&quot;  &quot;OTHER_TXT3&quot; 

## convert
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-29" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;REVIEW_DATE&quot;   &quot;DATE_OF_BIRTH&quot; &quot;DATE_DX&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;OTHER_DATE1&quot; can ignore OTHER_DATE1, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;OTHER_DATE1&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##   REVIEW_DATE DATE_OF_BIRTH    DATE_DX
## 1  2018-07-11    1943-10-18 2018-07-11
## 2  2018-07-11    1939-08-25 2018-07-11
## 3  2018-07-11    1934-06-13 2018-07-11
## 4  2018-07-11    1924-10-24 2018-07-11
## 5  2018-07-11    1920-11-01 2018-07-11
## 6  2018-07-11    1956-06-07 2018-07-11</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-29" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 17 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-3c1bb72aca4117985cc7" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-3c1bb72aca4117985cc7">{"x":{"filter":"none","vertical":false,"data":[["REVIEWER","CDX","SUB_DX","IMPRESSION"],["REVIEWER","CDX","SUB_DX","IMPRESSION"],["v.rodriguez4, axr1589, sjt82, jjs2031, mxc2207, kxc672, avg55, g.garbiso, bxf258, mcuccaro, prm72, axm2882, mgavier, nxj184, jvance","Non - Cognitively Impaired, Major depression, Cognitively Normal, Cognitively Impaired","possible AD with secondary diagnosis, other med/vascular factors, other","POSSIBLE, PROBABLE, UNCLEAR, NOT AFFECTED, UNKNOWN, DEFINITE"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## Ignore REVIEWER, for others, waiting for confirmation from Mike, should I add those invalid values to the DD?</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-29" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 22 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-0d1b98e53e0dc09e4681" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-0d1b98e53e0dc09e4681">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104408, 104411, 104412, 104439, 104442, 104445, 104406, 104431, 104575, 104403, 104469, 104562, 104488, 104455, 104517, 104434, 104467, 104501, 104446, 104440, 104505, 104503, 104481, 104425, 104457, 104433, 104525, 104564, 104565, 104566, 104570, 104572, 104573, 104574, 104579, 104581, 104640, 104639, 104638, 104637, 104634, 104633, 104631, 104629, 104623, 104622, 104620, 104619, 104618, 104615, 104612, 104611, 104609, 104608, 104540, 104409, 104548, 104553, 104521, 104526, 104607, 104606, 104605, 104604, 104600, 104586, 104582, 105826, 104590, 104591, 104592, 104594, 104593, 104585, 104584, 104583, 104418, 104432, 104435, 104437, 104438, 104420, 104407, 104500, 104405, 104542, 104555, 104554, 104523, 104516, 104449, 104567, 104568, 104569, 104506, 104428, 104514, 104482, 104475, 104477, 104419, 104527, 104499, 104456, 104471, 104483, 104539, 104563, 104485, 104496, 104447, 104460, 104498, 104524, 104487, 104478, 104451, 104422, 104520, 104497, 104472, 104512, 104535, 104560, 104450, 104468, 104536, 104463, 104490, 104476, 104549, 104515, 104513, 105807, 105808, 104534, 104484, 104545, 104508, 104510, 104454, 104453, 104470, 104528, 104426, 104423, 104441, 104443, 104465, 104533, 104551, 104556, 104532, 104547, 104519, 104518, 104550, 104546, 104538, 104466, 104448, 104410, 104479, 104561, 104541, 104415, 104424, 104502, 104489, 104474, 104427, 104507, 104461, 104473, 104458, 104462, 104531, 104421, 104669, 104652, 104647, 104644, 104480, 104552, 104543, 104459, 104414, 104522, 104413, 104429, 104436, 104444, 104452, 104504, 104430, 104544"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-29" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CONSENSUS_DX &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="craft_21_del_rc" class="section level2">
<h2>CRAFT_21_DEL_RC</h2>
<pre class="r"><code>df &lt;- CRAFT_21_DEL_RC

info(CRAFT_21_DEL_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:523, cols:95, inds:519</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    523 obs. of  95 variables:
##  $ SYSXM            : num  8275923 8276563 8258913 8259013 8260163 ...
##  $ SYSIND           : num  11620763 11369703 11369813 11037673 11620563 ...
##  $ SYSGP            : num  8005723 7951913 7952013 7894423 8005633 ...
##  $ SYSGPSTUDY       : num  1452433 1397023 1397123 1309743 1452343 ...
##  $ SYSINDGP         : num  8389833 8138973 8139083 7793413 8389633 ...
##  $ CGI_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER     : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY           : chr  &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER         : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY            : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY         : chr  &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER           : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP               : num  104457 88299 88301 87650 104477 ...
##  $ IND              : num  1 1 1 9000 1 1 1 1 1 1 ...
##  $ REFCTR           : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE        : POSIXct, format: &quot;2023-04-17&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER         : chr  &quot;sjt82&quot; &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH    : POSIXct, format: &quot;1946-12-19&quot; &quot;1944-09-22&quot; ...
##  $ AGE_AT_EXAM      : num  76 79 76 68 73 73 81 86 86 81 ...
##  $ REVIEW_DATE      : logi  NA NA NA NA NA NA ...
##  $ REVIEWER         : logi  NA NA NA NA NA NA ...
##  $ CRAFTDVR_ENTRY   : logi  NA NA NA NA NA NA ...
##  $ CRAFTDTI         : POSIXct, format: &quot;2023-04-17 12:58:00&quot; &quot;2024-02-13 10:56:00&quot; ...
##  $ CRAFTDVR1        : num  0 0 0 1 1 1 0 1 0 0 ...
##  $ CRAFTDVR2        : num  0 1 1 1 1 1 1 1 1 1 ...
##  $ CRAFTDVR3        : num  0 1 0 0 0 1 0 0 0 0 ...
##  $ CRAFTDVR4        : num  1 1 1 1 1 0 0 1 1 0 ...
##  $ CRAFTDVR5        : num  0 0 0 1 1 1 0 1 1 1 ...
##  $ CRAFTDVR6        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR7        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR8        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR9        : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDVR10       : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDVR11       : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR12       : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR13       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR14       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR15       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR16       : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDVR17       : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDVR18       : num  0 0 0 0 0 1 0 0 1 0 ...
##  $ CRAFTDVR19       : num  0 0 0 0 0 1 0 0 1 1 ...
##  $ CRAFTDVR20       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR21       : num  1 0 0 0 1 1 1 0 0 0 ...
##  $ CRAFTDVR22       : num  1 0 1 0 1 1 0 1 1 0 ...
##  $ CRAFTDVR23       : num  1 0 0 0 0 0 0 1 0 0 ...
##  $ CRAFTDVR24       : num  1 0 0 0 0 1 0 1 0 0 ...
##  $ CRAFTDVR25       : num  0 0 0 0 0 1 0 0 0 0 ...
##  $ CRAFTDVR26       : num  1 0 0 0 1 1 0 0 0 0 ...
##  $ CRAFTDVR27       : num  0 0 0 0 1 1 0 0 0 0 ...
##  $ CRAFTDVR28       : num  0 1 0 0 0 1 1 1 1 1 ...
##  $ CRAFTDVR29       : num  0 0 0 0 1 1 0 0 0 0 ...
##  $ CRAFTDVR30       : num  0 0 0 0 1 1 0 0 1 0 ...
##  $ CRAFTDVR31       : num  0 0 0 0 1 1 0 0 1 0 ...
##  $ CRAFTDVR32       : num  0 1 0 0 1 1 0 0 1 1 ...
##  $ CRAFTDVR33       : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ CRAFTDVR34       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR35       : num  0 0 0 0 1 0 0 1 0 0 ...
##  $ CRAFTDVR36       : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDVR37       : num  0 0 0 0 0 0 0 0 1 0 ...
##  $ CRAFTDVR38       : num  0 0 0 0 0 0 0 0 1 0 ...
##  $ CRAFTDVR39       : num  0 0 0 1 1 1 0 0 1 0 ...
##  $ CRAFTDVR40       : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDVR41       : num  0 0 0 1 1 1 0 0 1 1 ...
##  $ CRAFTDVR42       : num  0 0 0 1 0 1 0 0 0 0 ...
##  $ CRAFTDVR43       : num  0 0 0 1 1 1 0 0 1 1 ...
##  $ CRAFTDVR44       : num  0 0 0 1 1 1 0 1 1 1 ...
##  $ CRAFTDRE1        : num  0 0 0 1 1 1 0 1 1 0 ...
##  $ CRAFTDRE2        : num  0 1 1 1 1 1 1 1 1 1 ...
##  $ CRAFTDRE3        : num  0 1 0 0 0 1 0 0 0 1 ...
##  $ CRAFTDRE4        : num  1 1 1 1 1 0 0 1 1 1 ...
##  $ CRAFTDRE5        : num  0 0 0 1 1 1 0 1 1 1 ...
##  $ CRAFTDRE6        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDRE7        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDRE8        : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDRE9        : num  1 1 0 0 0 0 0 0 0 0 ...
##  $ CRAFTDRE10       : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDRE11       : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ CRAFTDRE12       : num  0 0 0 0 0 1 0 0 1 1 ...
##  $ CRAFTDRE13       : num  1 0 0 0 1 1 0 0 1 1 ...
##  $ CRAFTDRE14       : num  1 0 1 1 1 1 1 1 1 0 ...
##  $ CRAFTDRE15       : num  1 0 0 0 0 1 0 1 0 0 ...
##  $ CRAFTDRE16       : num  1 0 0 1 1 1 0 0 0 0 ...
##  $ CRAFTDRE17       : num  1 1 0 1 0 1 1 1 1 1 ...
##  $ CRAFTDRE18       : num  0 0 0 0 1 1 0 0 1 0 ...
##  $ CRAFTDRE19       : num  0 0 0 1 1 1 0 0 1 0 ...
##  $ CRAFTDRE20       : num  0 1 0 0 1 1 0 0 1 0 ...
##  $ CRAFTDRE21       : num  0 0 0 0 1 1 1 1 1 1 ...
##  $ CRAFTDRE22       : num  0 0 0 0 0 0 0 0 1 0 ...
##  $ CRAFTDRE23       : num  0 0 0 1 1 1 0 0 1 0 ...
##  $ CRAFTDRE24       : num  0 0 0 1 1 1 0 0 1 1 ...
##  $ CRAFTDRE25       : num  0 0 0 1 1 1 1 0 1 1 ...
##  $ CRAFTCUE         : num  0 1 0 0 1 1 1 1 1 0 ...
##  $ COMMENTS_CRAFTDRE: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-30" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CRAFT_21_DEL_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-30" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 4 × 2
##   VarNames       `Data Type`  
##   &lt;chr&gt;          &lt;chr&gt;        
## 1 REFCTR         VARCHAR2(6)  
## 2 REVIEW_DATE    date         
## 3 REVIEWER       CHAR         
## 4 CRAFTDVR_ENTRY VARCHAR2(500)</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;         &quot;REVIEWER&quot;       &quot;CRAFTDVR_ENTRY&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-30" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; &quot;CRAFTDTI&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH            CRAFTDTI
## 1 2023-04-17    1946-12-19 2023-04-17 12:58:00
## 2 2024-02-13    1944-09-22 2024-02-13 10:56:00
## 3 2024-02-13    1947-05-13 2024-02-13 10:59:00
## 4 2023-10-24    1954-10-29 2023-10-24 14:33:00
## 5 2023-05-15    1949-12-01 2023-05-15 10:23:00
## 6 2023-05-15    1950-04-02 2023-05-15 12:07:00</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-30" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 10 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-eb5337b528a4c089159b" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-eb5337b528a4c089159b">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["sjt82, gsv32, jjs2031, cmanrique, prm72, mxp1257, kxc672, axl4418, mxl2473, v.rodriguez4, cxc2077, smm493, Katalina McInerney, Izri Martinez, ABIGAIL LOPEZ, Katalina Fernandez M, Anisley Martinez, lxi119, eir34, Elias Rojas, Maryenela Illanes, Mario Cornejo, Koni Mejia, Julia Rios, Sheila Castro, Henry Palomino, Ivan Cornejo, Noemi Herrera, Aldo Vences, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-30" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 81 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-e09fee1799a55e85120d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-e09fee1799a55e85120d">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104457, 104477, 104476, 104540, 104528, 104455, 104556, 104511, 104549, 104548, 104452, 104459, 104500, 104499, 104525, 104497, 104531, 104536, 104472, 104530, 105806, 104469, 104521, 104496, 104487, 104515, 104490, 104526, 104453, 105804, 104518, 104454, 104514, 104513, 104554, 104481, 105805, 104508, 104475, 104539, 104527, 104532, 104552, 104512, 104516, 104456, 104471, 104507, 104529, 104464, 105801, 104501, 104489, 104553, 104551, 105817, 104589, 104564, 104563, 104535, 105809, 104542, 104557, 104498, 105815, 105808, 105814, 104519, 105826, 105807, 104578, 104470, 104474, 104590, 104465, 104582, 104584, 104447, 104550, 104506, 104573, 105824, 104494, 104545, 104570, 104567, 104583, 104541, 104450, 104559, 105813, 104591, 104568, 104462, 104546, 104473, 104586, 104585, 104544, 105821, 104482, 104484, 104571, 104569, 104572, 105827, 104495, 105819, 104510, 105803, 104479, 105811, 104560, 104523, 104509, 104488, 104505, 105822, 104579, 104534, 104561, 104520, 104566, 104448, 105812, 104562, 104580, 104581, 104533, 105810, 104467, 104555, 104468, 104524, 104485, 104547, 104574, 104449, 104575, 104502, 104451, 105800, 105818, 105816, 104480, 104478, 104483, 105823, 105825, 105820, 104594, 104662, 104664, 104652, 104666, 104632, 104659, 104656, 104640, 104629, 104614, 104658, 104588, 104626, 104651, 104660, 104634, 104616, 104610, 104621, 104617, 104679, 104696, 104697, 105833, 105829, 104604, 104619, 104612, 104503, 104655, 104668, 104643, 104657, 104602, 104645, 104680, 104685, 104688, 104665, 105830, 104597, 104595, 104681, 104669, 104624, 104648, 104635, 104663, 104558, 104672, 104599, 104684, 104649, 104638, 104522, 104517, 104667, 105832, 104592, 104636, 104699, 104698, 104701, 104593, 105831, 104689, 104682, 104686, 104630, 104611, 104644, 104646, 104654, 104615, 104605, 104606, 104622, 104647, 104623, 104608, 105828, 104537, 104637, 104631, 104639, 104661, 104642, 104598, 104600, 104618, 104504, 105834, 104538, 104620, 104609, 104607, 104596, 104673, 104650, 104677, 104641, 104683, 104613, 105838, 107011, 107007, 107132, 107024, 104754, 107003, 107005, 107009, 104674, 104703, 104736, 104744, 107179, 104627, 104702, 104690, 104695, 104628, 104700, 107175, 104706, 104746, 107020, 107100, 104774, 107181, 107104, 104783, 107012, 104768, 104625, 104675, 104676, 104603, 107016"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-30" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CRAFT_21_DEL_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="craft_21_imm_rc" class="section level2">
<h2>CRAFT_21_IMM_RC</h2>
<pre class="r"><code>df &lt;- CRAFT_21_IMM_RC

info(CRAFT_21_IMM_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:530, cols:98, inds:525</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    530 obs. of  98 variables:
##  $ SYSXM                : num  8258833 8258863 8260063 8277603 8277783 ...
##  $ SYSIND               : num  11369813 11037673 11620563 11435853 11638763 ...
##  $ SYSGP                : num  7952013 7894423 8005633 7962813 8007323 ...
##  $ SYSGPSTUDY           : num  1397123 1309743 1452343 1407923 1454033 ...
##  $ SYSINDGP             : num  8139083 7793413 8389633 8205123 8407833 ...
##  $ CGI_ORDER            : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER            : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER         : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY               : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER             : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY             : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER               : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                   : num  88301 87650 104477 88452 104540 ...
##  $ IND                  : num  1 9000 1 1 1 1 105 1 1 1 ...
##  $ REFCTR               : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE            : POSIXct, format: &quot;2024-02-13&quot; &quot;2023-10-24&quot; ...
##  $ EXAMINER             : chr  &quot;jjs2031&quot; &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH        : POSIXct, format: &quot;1947-05-13&quot; &quot;1954-10-29&quot; ...
##  $ AGE_AT_EXAM          : num  76 68 73 81 86 86 71 73 81 79 ...
##  $ REVIEW_DATE          : logi  NA NA NA NA NA NA ...
##  $ REVIEWER             : logi  NA NA NA NA NA NA ...
##  $ CRAFTVRS_ENTRY       : logi  NA NA NA NA NA NA ...
##  $ CRAFTVRS_TIME        : POSIXct, format: &quot;2024-02-13 10:41:00&quot; &quot;2023-10-24 14:18:00&quot; ...
##  $ CRAFTVRS1            : num  1 1 1 1 1 1 0 1 0 0 ...
##  $ CRAFTVRS2            : num  1 1 1 1 1 1 0 1 1 1 ...
##  $ CRAFTVRS3            : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ CRAFTVRS4            : num  1 1 1 1 1 0 0 0 1 1 ...
##  $ CRAFTVRS6            : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS7            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS8            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS5            : num  0 1 1 0 1 1 0 0 1 1 ...
##  $ CRAFTVRS9            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS10           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS11           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS12           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS13           : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ CRAFTVRS14           : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ CRAFTVRS15           : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ CRAFTVRS16           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS17           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS18           : num  0 0 1 0 0 0 0 0 1 1 ...
##  $ CRAFTVRS19           : num  0 0 1 0 0 0 0 0 1 1 ...
##  $ CRAFTVRS20           : num  0 0 1 0 0 1 0 0 0 1 ...
##  $ CRAFTVRS21           : num  0 1 1 0 0 0 0 1 1 1 ...
##  $ CRAFTVRS22           : num  1 1 1 1 1 1 0 1 1 1 ...
##  $ CRAFTVRS23           : num  0 0 1 0 0 0 0 1 0 0 ...
##  $ CRAFTVRS24           : num  0 0 1 0 0 0 0 1 1 0 ...
##  $ CRAFTVRS25           : num  0 1 1 0 0 0 0 1 0 1 ...
##  $ CRAFTVRS26           : num  0 1 1 0 1 0 0 1 0 1 ...
##  $ CRAFTVRS27           : num  0 1 1 0 1 0 0 1 0 1 ...
##  $ CRAFTVRS28           : num  1 1 1 1 1 0 1 0 1 0 ...
##  $ CRAFTVRS29           : num  0 1 0 0 0 1 0 0 0 0 ...
##  $ CRAFTVRS30           : num  0 1 1 0 0 1 0 0 0 0 ...
##  $ CRAFTVRS31           : num  0 0 0 0 0 1 0 0 1 0 ...
##  $ CRAFTVRS32           : num  0 1 1 0 1 1 0 1 1 1 ...
##  $ CRAFTVRS33           : num  0 1 1 0 1 0 0 1 0 1 ...
##  $ CRAFTVRS34           : num  0 1 1 0 1 0 0 0 0 1 ...
##  $ CRAFTVRS35           : num  0 0 1 0 1 1 0 0 0 1 ...
##  $ CRAFTVRS36           : num  0 0 1 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS37           : num  0 0 1 0 0 0 0 0 0 0 ...
##  $ CRAFTVRS38           : num  0 0 1 0 0 1 0 0 0 0 ...
##  $ CRAFTVRS39           : num  0 1 0 0 0 1 0 0 0 1 ...
##  $ CRAFTVRS40           : num  0 1 0 0 0 0 0 0 0 1 ...
##  $ CRAFTVRS41           : num  0 1 1 0 1 1 0 0 1 1 ...
##  $ CRAFTVRS42           : num  0 1 1 0 1 0 0 0 0 1 ...
##  $ CRAFTVRS43           : num  0 1 1 0 1 1 0 0 1 0 ...
##  $ CRAFTVRS44           : num  0 1 1 1 1 0 1 0 1 0 ...
##  $ CRAFTURS1            : num  1 1 1 1 1 1 0 1 0 0 ...
##  $ CRAFTURS2            : num  1 1 1 1 1 1 0 1 1 1 ...
##  $ CRAFTURS3            : num  0 1 0 0 0 0 0 0 0 1 ...
##  $ CRAFTURS4            : num  1 1 1 1 1 1 0 0 1 1 ...
##  $ CRAFTURS5            : num  0 1 1 0 1 1 0 0 1 1 ...
##  $ CRAFTURS6            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTURS7            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTURS8            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ CRAFTURS9            : num  1 0 0 0 1 0 0 0 0 0 ...
##  $ CRAFTURS10           : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ CRAFTURS11           : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ CRAFTURS12           : num  0 1 1 0 0 0 0 0 1 1 ...
##  $ CRAFTURS13           : num  0 1 1 0 0 1 0 1 1 1 ...
##  $ CRAFTURS14           : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ CRAFTURS15           : num  0 1 1 0 0 0 0 1 1 0 ...
##  $ CRAFTURS16           : num  0 1 1 0 1 0 0 1 0 1 ...
##  $ CRAFTURS17           : num  1 1 1 1 1 1 1 0 1 0 ...
##  $ CRAFTURS18           : num  0 1 0 0 0 1 0 0 0 0 ...
##  $ CRAFTURS19           : num  0 1 1 0 0 1 0 1 0 1 ...
##  $ CRAFTURS20           : num  0 0 1 0 1 1 1 1 1 1 ...
##  $ CRAFTURS21           : num  0 0 1 1 1 1 0 0 1 1 ...
##  $ CRAFTURS22           : num  0 0 1 0 0 1 0 0 0 0 ...
##  $ CRAFTURS24           : num  0 1 1 0 1 0 0 0 1 1 ...
##  $ CRAFTURS23           : num  0 1 0 0 1 1 0 0 0 1 ...
##  $ CRAFTURS25           : num  0 1 1 1 1 1 0 0 1 0 ...
##  $ COMMENTS_CRAFTVRS    : chr  NA NA NA NA ...
##  $ SCORE_CRAFTVRS       : num  5 22 27 6 19 14 2 11 14 20 ...
##  $ SCORE_CRAFTVRS_STATUS: chr  NA NA NA NA ...
##  $ SCORE_CRAFTURS       : num  6 18 16 7 13 14 3 8 12 13 ...
##  $ SCORE_CRAFTURS_STATUS: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-31" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;CRAFT_21_IMM_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-31" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 4 × 2
##   VarNames       `Data Type`  
##   &lt;chr&gt;          &lt;chr&gt;        
## 1 REFCTR         VARCHAR2(6)  
## 2 REVIEW_DATE    date         
## 3 REVIEWER       CHAR         
## 4 CRAFTVRS_ENTRY VARCHAR2(500)</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## &quot;REFCTR&quot;         &quot;REVIEWER&quot;       &quot;CRAFTVRS_ENTRY&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-31" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; &quot;CRAFTVRS_TIME&quot; 

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH       CRAFTVRS_TIME
## 1 2024-02-13    1947-05-13 2024-02-13 10:41:00
## 2 2023-10-24    1954-10-29 2023-10-24 14:18:00
## 3 2023-05-15    1949-12-01 2023-05-15 10:12:00
## 4 2024-02-15    1942-09-30 2024-02-15 14:22:00
## 5 2023-09-13    1937-08-13 2023-09-13 10:02:00
## 6 2023-05-09    1936-05-22 2023-05-09 11:46:00</code></pre>
<pre class="r"><code>## convert format
## I will leave CRAFTVRS_TIME with format POSIXct since it contains the timestamp
## and I will convert the other two to date format
datecols &lt;- setdiff(datecols, &quot;CRAFTVRS_TIME&quot;)
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;Date&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-31" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 12 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-c9c3b97eee11141c7628" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-c9c3b97eee11141c7628">{"x":{"filter":"none","vertical":false,"data":[["EXAMINER"],["EXAMINER"],["jjs2031, gsv32, prm72, cmanrique, sjt82, mxp1257, kxc672, mxl2473, axl4418, v.rodriguez4, cxc2077, smm493, Katalina McInerney, Izri Martinez, ABIGAIL LOPEZ, eir34, Anisley Martinez, Katalina Fernandez M, lxi119, Maryenela Illanes, Mario Cornejo, Koni Mejia, Julia Rios, Ivan Cornejo, Sheila Castro, Henry Palomino, Aldo Vences, Noemi Herrera, tfg30"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-31" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 82 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;0;\r\n1;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-ece19748e9d5de357be0" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-ece19748e9d5de357be0">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104540, 104528, 104456, 104455, 104556, 104471, 104511, 104519, 104549, 104548, 104459, 104531, 104497, 104454, 104521, 104496, 104487, 104500, 104525, 105804, 104515, 104508, 104472, 104490, 104453, 104513, 104499, 104536, 104518, 104514, 104554, 104481, 105805, 104475, 104526, 104539, 104527, 104532, 104552, 104452, 104512, 104469, 105806, 104507, 104457, 104529, 104464, 104476, 104516, 105801, 104530, 104501, 104489, 104524, 104449, 104553, 104551, 104571, 104569, 105817, 105800, 105821, 104589, 104564, 104563, 104535, 105809, 104542, 104461, 104541, 104557, 104498, 104473, 105815, 105808, 105814, 104578, 104474, 104591, 104586, 104582, 104574, 104447, 104506, 104550, 104573, 105824, 104468, 104545, 104570, 105807, 104583, 105811, 104450, 104559, 105813, 104546, 104555, 104590, 104568, 104585, 104483, 104478, 104544, 104482, 105818, 105820, 105816, 104494, 104484, 105827, 104572, 104495, 105826, 105819, 105803, 104462, 104479, 104560, 104523, 104488, 104509, 104465, 104505, 105822, 104485, 104579, 104448, 104534, 104561, 104520, 104566, 104567, 104502, 105812, 104562, 104580, 104581, 104584, 104533, 105810, 104467, 104451, 104510, 104547, 104470, 104575, 104480, 105823, 105825, 104636, 104594, 104662, 104664, 104599, 104616, 104652, 104666, 104632, 104626, 104659, 104656, 104640, 104614, 104658, 104588, 104651, 104657, 104660, 104634, 104621, 104617, 104684, 104679, 104696, 104697, 104619, 104612, 104503, 104655, 104643, 104654, 104623, 104602, 104645, 104680, 104685, 104688, 104665, 105830, 104597, 104681, 104669, 104610, 105829, 104595, 104504, 104538, 104648, 104663, 104672, 105831, 104624, 105834, 104638, 105833, 104631, 104635, 104522, 104517, 104558, 104677, 104667, 104604, 105832, 104699, 104698, 104701, 104593, 104689, 104682, 104686, 104630, 104611, 104644, 104646, 104615, 104605, 104606, 104622, 104647, 104608, 105828, 104537, 104639, 104629, 104661, 104642, 104598, 104600, 104637, 104618, 104620, 104668, 104609, 104596, 104607, 104673, 104650, 104592, 104641, 104683, 104649, 104613, 105838, 107011, 107007, 104675, 104676, 107132, 107024, 104754, 107175, 107003, 107005, 107009, 104674, 104703, 104736, 104744, 107179, 104627, 104702, 107124, 104628, 104700, 104706, 104746, 107020, 107100, 104774, 107181, 104695, 107104, 107012, 104768, 104690, 104783, 104625, 104603, 107016"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-31" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>CRAFT_21_IMM_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="medcon_rc" class="section level2">
<h2>MEDCON_RC</h2>
<pre class="r"><code>df &lt;- MEDCON_RC

info(MEDCON_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:627, cols:237, inds:618</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    627 obs. of  237 variables:
##  $ SYSXM                     : num  8258763 8258803 8260083 8277583 8277993 ...
##  $ SYSIND                    : num  11037673 11369813 11362953 11435853 11621333 ...
##  $ SYSGP                     : num  7894423 7952013 7946353 7962813 8006293 ...
##  $ SYSGPSTUDY                : num  1309743 1397123 1387463 1407923 1453003 ...
##  $ SYSINDGP                  : num  7793413 8139083 8132223 8205123 8390403 ...
##  $ CGI_ORDER                 : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                 : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER              : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                    : chr  &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ DB_OWNER                  : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                     : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                  : chr  &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; ...
##  $ CENTER                    : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                        : num  87650 88301 87545 88452 104528 ...
##  $ IND                       : num  9000 1 106 1 1 ...
##  $ REFCTR                    : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                 : POSIXct, format: &quot;2023-10-24&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER                  : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;gsv32&quot; ...
##  $ DATE_OF_BIRTH             : POSIXct, format: &quot;1954-10-29&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM               : num  68 76 66 81 86 86 60 81 79 67 ...
##  $ REVIEW_DATE               : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                  : logi  NA NA NA NA NA NA ...
##  $ MEMORY_COMPLAINTS         : num  0 0 1 0 0 1 0 0 0 1 ...
##  $ DATE_OF_ONSET             : POSIXct, format: NA NA ...
##  $ DOA_UNK                   : chr  NA NA NA NA ...
##  $ DESCRIBE                  : chr  &quot;hysterectomy (1987), no HET, knee surgery 2010, carpal tunnel surgery 2011&quot; NA NA &quot;Hypertension x 20yrs; left knee prothesis due to osteoarthrosis, right knee in need of surgery; hypercholest.; &quot;| __truncated__ ...
##  $ MEM_COMPLAINTS            : chr  &quot;68 y/o mixed female born in PR. Oriented in time, space and person. No memory complaints, however complaints of&quot;| __truncated__ &quot;NO MEMORY COMPLAINTS. PERSON ORIENTED IN TIME, SPACE, AND PERSON. HE LIVES ALONE, HE DOESN&#39;T NEED HELP TO CHANG&quot;| __truncated__ &quot;YES MEMORY COMPLAINTS. ORIENTED EN TIME, SPACE, AND PERSONA. SHE SAYS THAT HER MEMORY WAS FULL AND WELL DURING &quot;| __truncated__ &quot;Refers no major changes in memory.  Remembers phone numbers and addresses well.  He is 81y/o, with 9yrs of educ&quot;| __truncated__ ...
##  $ CURRENT_MED               : chr  &quot;high blood pressure, sleep apnea, diabetes (10 years ago) arthritis (13 years ago)&quot; &quot;DM 10 Y/0 HIGH BLOOD PRESSURE 10 Y/0&quot; &quot;HYPOTHYROIDISM 30 Y/O CHOLESTEROL 10 Y/O DM 5 YEARS AGO BREAST CANCER 2013 DEPRESSION 2013 ASTHMA 4 Y/O ARTHIRITIS 2017.&quot; &quot;see above&quot; ...
##  $ PMH                       : chr  NA NA NA &quot;see above&quot; ...
##  $ MOOD_CHANGES              : chr  &quot;None reported&quot; &quot;NO DEPRESSION OR ANXIETY&quot; &quot;YES DEPRESSION AND ANXEITY&quot; &quot;H/o depression and anxiety x 20yrs, with meds, was with psychiatrist but not anymore&quot; ...
##  $ HYPERTENSION_DX           : num  1 1 0 1 1 1 0 0 1 1 ...
##  $ HYPERTENSION_TREATED      : num  1 1 -1 1 1 1 0 -1 1 1 ...
##  $ DIABETES_DX               : num  1 1 1 1 1 0 0 0 1 1 ...
##  $ DIABETES_TREATED          : num  1 1 1 1 1 0 0 -1 1 1 ...
##  $ MYOCARDIAL_DX             : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ MYOCARDIAL_TREATED        : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ HEART_FAILURE_DX          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ HEART_FAILURE_TREATED     : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ HEART_DISEASE_DX          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ HEART_DISEASE_TREATED     : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ COPD_DX                   : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ COPD_TREATED              : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ THYROID_DX                : num  0 0 1 0 0 0 0 0 0 0 ...
##  $ THYROID_TREATED           : num  0 -1 1 NA -1 0 0 -1 NA -1 ...
##  $ LIVER_DX                  : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ LIVER_TREATED             : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ RENAL_DX                  : num  0 0 0 0 1 0 0 0 1 0 ...
##  $ RENAL_TREATED             : num  0 -1 -1 NA 1 0 0 -1 NA -1 ...
##  $ PEPTIC_DX                 : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ PEPTIC_TREATED            : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ PERIPHERAL_DX             : num  1 0 0 1 0 0 0 0 0 1 ...
##  $ PERIPHERAL_TREATED        : num  0 -1 -1 1 -1 0 0 -1 NA 0 ...
##  $ STROKE_DX                 : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ STROKE_TREATED            : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ TIA_DX                    : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TIA_TREATED               : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ HEAD_INJURY_DX            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ HEAD_INJURY_TREATED       : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ SEIZURE_DX                : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ SEIZURE_TREATED           : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ CANCER_DX                 : num  0 0 1 0 1 0 0 0 0 0 ...
##  $ CANCER_TREATED            : num  0 -1 0 NA 1 0 0 -1 NA -1 ...
##  $ ARTHRITIS_DX              : num  1 0 1 1 1 1 0 1 1 1 ...
##  $ ARTHRITIS_TREATED         : num  1 -1 1 1 1 1 0 1 1 0 ...
##  $ SYPHILIS_DX               : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ SYPHILIS_TREATED          : num  0 -1 -1 0 -1 0 0 -1 NA -1 ...
##  $ ALCOHOL_DX                : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ ALCOHOL_TREATED           : num  0 -1 -1 0 -1 0 0 -1 NA -1 ...
##  $ ILLICIT_DRUG_DX           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ ILLICIT_DRUG_TREATED      : num  0 -1 -1 0 -1 0 0 -1 NA -1 ...
##  $ SMOKING_DX                : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ SMOKING_TREATED           : num  0 -1 -1 0 -1 0 0 -1 NA -1 ...
##  $ PD_DX                     : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ PD_TREATED                : num  0 -1 -1 0 -1 0 0 -1 NA -1 ...
##  $ HUNTINGTON_DX             : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ HUNTINGTON_TREATED        : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ MULTIPLE_SCLEROSIS_DX     : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ MULTIPLE_SCLEROSIS_TREATED: num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ B12_DX                    : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ B12_TREATED               : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ HYDROCEPHALUS_DX          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ HYDROCEPHALUS_TREATED     : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ TREMOR_DX                 : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TREMOR_TREATED            : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ DOWN_SYNDROME_DX          : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ DOWN_SYNDROME_TREATED     : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...
##  $ MED_CONDITIONS_DX         : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ MED_CONDITIONS_TREATED    : num  0 -1 -1 1 -1 0 0 -1 NA -1 ...
##  $ OTH_MED_COND_SP           : chr  NA NA NA &quot;depression and anxiety&quot; ...
##  $ STROKE_BRAIN              : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ DOCTOR                    : num  NA 9 9 NA 9 0 NA 9 0 9 ...
##  $ STROKE_PAST               : num  NA 9 9 NA 9 0 NA 9 0 9 ...
##  $ STROKE_24HRS              : num  NA 9 9 NA 9 0 NA 9 0 9 ...
##  $ SYMPTOMS                  : num  NA 9 9 NA 9 0 NA 9 0 9 ...
##  $ LOST_SPEECH               : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ LOST_UNDERSTAND           : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ LOSS_CONSCIOUS            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ WEAKNESS                  : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ NUMBNESS                  : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ LOSS_VISION               : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ HALF_VISION               : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ PERIOD                    : num  1 0 1 1 1 1 0 1 1 0 ...
##  $ AGE_C24A                  : num  67 NA 55 60 59 86 NA 77 70 NA ...
##  $ DONT_KNOW                 : chr  NA NA NA NA ...
##  $ SEEK_HELP                 : num  1 NA 1 1 0 1 NA 1 1 NA ...
##  $ TREATMENT                 : num  0 NA 0 0 0 0 NA 0 0 NA ...
##  $ MEDS                      : num  1 NA 1 1 0 0 NA 1 1 NA ...
##  $ PSYCHOTHERAPY             : num  1 NA 1 1 0 1 NA 1 1 NA ...
##  $ OTHER                     : num  0 NA 0 0 0 0 NA 0 0 NA ...
##  $ UNKNOWN                   : num  0 NA 0 0 0 0 NA 0 0 NA ...
##  $ SPECIFY_OTHER             : chr  NA NA NA NA ...
##  $ TAKING_MEDS               : num  1 0 1 1 1 1 1 1 1 1 ...
##  $ MEDICATION1               : chr  &quot;aspirin&quot; NA &quot;LEVOTHYROXINE&quot; &quot;doesn&#39;t remember medications&quot; ...
##  $ STRENGTH1                 : chr  &quot;81 mg&quot; NA &quot;112 MG DAILY&quot; NA ...
##  $ SEEN1                     : num  0 NA 0 0 0 NA 0 0 NA 0 ...
##  $ MEDICATION2               : chr  &quot;lipidol&quot; NA &quot;MEMANTINE HCL&quot; NA ...
##  $ STRENGTH2                 : chr  &quot;20 mg&quot; NA &quot;10 MG TWICE DAILY&quot; NA ...
##  $ SEEN2                     : chr  &quot;0&quot; NA &quot;0&quot; NA ...
##  $ MEDICATION3               : chr  &quot;zyrtec&quot; NA &quot;XISDUO XR(METFORMIN HCL)&quot; NA ...
##  $ STRENGTH3                 : chr  &quot;10 mg&quot; NA &quot;5MG/1000MG&quot; NA ...
##  $ SEEN3                     : num  0 NA 0 NA 0 NA NA 0 NA 0 ...
##  $ MEDICATION4               : chr  &quot;vitamin D3&quot; NA &quot;ESCITALOPRAM&quot; NA ...
##  $ STRENGTH4                 : chr  &quot;50,000 d&quot; NA &quot;20 MG 1 DAILY&quot; NA ...
##  $ SEEN4                     : chr  &quot;0&quot; NA &quot;0&quot; NA ...
##  $ MEDICATION5               : chr  &quot;folic acid&quot; NA &quot;ATORVASTATIN CALCIUM&quot; NA ...
##  $ STRENGTH5                 : chr  &quot;1 mg&quot; NA &quot;20 MG&quot; NA ...
##  $ SEEN5                     : num  0 NA 0 NA 0 NA NA 0 NA NA ...
##  $ MEDICATION6               : chr  &quot;daflonex&quot; NA &quot;FOROTIDINE&quot; NA ...
##  $ STRENGTH6                 : chr  &quot;XL as indicated&quot; NA &quot;20 MG DAILY&quot; NA ...
##  $ SEEN6                     : chr  &quot;0&quot; NA &quot;0&quot; NA ...
##  $ MEDICATION7               : chr  &quot;methenamine&quot; NA &quot;LISINIPROL&quot; NA ...
##  $ STRENGTH7                 : chr  &quot;500 mg&quot; NA &quot;10 MG DAILY&quot; NA ...
##  $ SEEN7                     : num  0 NA 0 NA 0 NA NA 0 NA NA ...
##  $ MEDICATION8               : chr  &quot;methnotexate&quot; NA &quot;MONTELUKAST SODIUM&quot; NA ...
##  $ STRENGTH8                 : chr  &quot;2.5 mg&quot; NA &quot;10 MG DAILY&quot; NA ...
##  $ SEEN8                     : chr  &quot;0&quot; NA &quot;0&quot; NA ...
##  $ MEDICATION9               : chr  &quot;lexapro&quot; NA &quot;FOLIC ACID&quot; NA ...
##  $ STRENGTH9                 : chr  &quot;10 mg&quot; NA &quot;1 MG DAILY&quot; NA ...
##  $ SEEN9                     : num  0 NA 0 NA 0 NA NA NA NA NA ...
##  $ MEDICATION10              : chr  &quot;frova&quot; NA &quot;VITAMIN D&quot; NA ...
##  $ STRENGTH10                : chr  &quot;2.5 mg&quot; NA NA NA ...
##  $ SEEN10                    : chr  &quot;0&quot; NA &quot;0&quot; NA ...
##  $ MEDICATION11              : chr  &quot;mirapen&quot; NA &quot;BIOTIN&quot; NA ...
##  $ STRENGTH11                : chr  &quot;.5 mg&quot; NA NA NA ...
##  $ SEEN11                    : num  0 NA 0 NA NA NA NA NA NA NA ...
##  $ MEDICATION12              : chr  &quot;lyrica&quot; NA NA NA ...
##  $ STRENGTH12                : chr  &quot;25 mg&quot; NA NA NA ...
##  $ SEEN12                    : chr  NA NA NA NA ...
##  $ MEDICATION13              : chr  &quot;lisinopril&quot; NA NA NA ...
##  $ STRENGTH13                : chr  &quot;5 mg&quot; NA NA NA ...
##  $ SEEN13                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEDICATION14              : chr  &quot;pepcid&quot; NA NA NA ...
##  $ STRENGTH14                : chr  &quot;20 mg&quot; NA NA NA ...
##  $ SEEN14                    : chr  NA NA NA NA ...
##  $ MEDICATION15              : chr  NA NA NA NA ...
##  $ STRENGTH15                : chr  NA NA NA NA ...
##  $ SEEN15                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEDICATION16              : chr  NA NA NA NA ...
##  $ STRENGTH16                : chr  NA NA NA NA ...
##  $ SEEN16                    : chr  NA NA NA NA ...
##  $ MEDICATION17              : chr  NA NA NA NA ...
##  $ STRENGTH17                : chr  NA NA NA NA ...
##  $ SEEN17                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEDICATION18              : chr  NA NA NA NA ...
##  $ STRENGTH18                : logi  NA NA NA NA NA NA ...
##  $ SEEN18                    : chr  NA NA NA NA ...
##  $ MEDICATION19              : chr  NA NA NA NA ...
##  $ STRENGTH19                : chr  NA NA NA NA ...
##  $ SEEN19                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEDICATION20              : logi  NA NA NA NA NA NA ...
##  $ STRENGTH20                : logi  NA NA NA NA NA NA ...
##  $ SEEN20                    : logi  NA NA NA NA NA NA ...
##  $ NOTES_MEDLIST             : chr  NA NA NA NA ...
##  $ WARFARIN                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ASPIRIN                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTIPLATELETS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DIURETICS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTICONVULSANTS           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ INSULIN                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYPOGLYCEMICS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SULFONYLUREA              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ METFORMIN                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GLITAZONES                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DIGITALIS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NITRATES                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CALCIUM_CHANNEL           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BETA_2_AGAONIST           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ BETA_BLOCKERS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ACE                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTI_ARRHYTHMICS          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTI_HYPERLIPIDEMICS      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ STATIN_DRUG               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ FIBRATE_DRUG              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ THYROID                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTICHOLINERGICS          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ LEVODOPA                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DOPAMINE1                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTIDEPRESSANTS           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANTIPSYCHOTICS            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ANXIOLYTICS               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CHOLINESTERASE            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ RIVASTIGMINE              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ TACRINE                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DONEPEZIL                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GALANTAMINE               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NMDA                      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEMANTINE                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ALPHA_BLOCKERS            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYPNOTICS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ H1_BLOCKERS               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ H2_BLOCKERS               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NSAID                     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COX2                      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ NARCOTICS                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ HYDERGINE                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DEPRENYL                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ ESTROGEN_SUPP             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ PRESCRIPTION              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OTC                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ STEROIDS                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OTHER_MEDS                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ C57_SPEC_MEDS             : chr  NA NA NA NA ...
##  $ MULTIVITAMINS             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_C                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_E                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMINE_B12              : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ COENZYME_Q                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ DHA                       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ LECITHIN                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GINKGO                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ FOLIC_ACID                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_B6                : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ VITAMIN_D                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ OMEGA3                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MEDCOND_COMENTS           : chr  NA NA NA NA ...
##  $ MED_CONDITIONS_HIV        : num  0 0 0 0 0 0 0 0 NA 0 ...
##  $ MED_CONDITIONS_HIV_TX     : num  0 -1 -1 NA -1 0 0 -1 NA -1 ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-32" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;MEDCON_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-32" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 7 vars

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 7 × 2
##   VarNames     `Data Type` 
##   &lt;chr&gt;        &lt;chr&gt;       
## 1 REFCTR       VARCHAR2(6) 
## 2 REVIEW_DATE  DATE        
## 3 REVIEWER     CHAR        
## 4 STRENGTH18   VARCHAR2(30)
## 5 MEDICATION20 VARCHAR2(30)
## 6 STRENGTH20   VARCHAR2(30)
## 7 SEEN20       NUMBER(1)</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)]
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`,ignore.case = T)]
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`,ignore.case = T)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2num] &lt;- lapply(df[convert2num], as.numeric)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-32" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot; &quot;DATE_OF_ONSET&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH DATE_OF_ONSET
## 1 2023-10-24    1954-10-29          &lt;NA&gt;
## 2 2024-02-13    1947-05-13          &lt;NA&gt;
## 3 2024-02-20    1957-08-05    2021-06-01
## 4 2024-02-15    1942-09-30          &lt;NA&gt;
## 5 2023-05-09    1936-05-22          &lt;NA&gt;
## 6 2023-09-13    1937-08-13    2023-04-01</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-32" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 69 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## 9 vars
## [1] &quot;SEEN2&quot;  &quot;SEEN4&quot;  &quot;SEEN6&quot;  &quot;SEEN8&quot;  &quot;SEEN10&quot; &quot;SEEN12&quot; &quot;SEEN14&quot; &quot;SEEN16&quot; &quot;SEEN18&quot;
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## convert mismatchChrs_1 vars to numeric
df[mismatchChrs_1] &lt;- lapply(df[mismatchChrs_1], as.numeric)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-e4d8ce81c0822a8d90aa" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-e4d8ce81c0822a8d90aa">{"x":null,"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-32" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 164 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA                           &quot;1 thru 99999;&quot;             
## [3] &quot;1 thru 9999;&quot;               &quot;0;\r\n1;&quot;                  
## [5] &quot;0;\r\n1;\r\n9;\r\n-1;&quot;      &quot;0;\r\n1;\r\n7;\r\n8;\r\n9;&quot;
## [7] &quot;0;\r\n1;\r\n9;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-4b88673b9ad69584a3be" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-4b88673b9ad69584a3be">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104528, 104540, 104455, 104556, 104471, 104511, 104548, 104532, 104549, 104459, 104452, 104497, 104531, 104518, 105801, 104499, 104525, 104514, 104496, 104515, 104508, 104521, 104487, 104490, 104453, 104526, 104513, 105802, 104552, 104500, 104536, 104454, 104481, 105805, 104475, 104554, 104527, 104456, 104539, 104463, 104512, 104507, 104472, 104469, 105806, 104477, 104457, 104529, 104516, 104476, 104460, 105804, 104502, 105809, 104569, 105807, 105817, 105821, 105820, 105827, 104434, 104564, 104563, 104535, 104560, 104574, 104542, 104461, 104557, 105815, 104421, 105808, 105803, 105814, 104430, 104553, 104474, 104586, 104467, 105819, 104582, 104575, 104585, 104550, 104573, 105824, 104468, 104547, 104545, 104506, 104570, 104583, 105811, 104485, 104450, 105813, 104546, 104519, 104590, 104568, 104581, 104551, 104447, 104571, 104473, 104483, 104414, 104482, 104494, 105822, 104559, 104565, 104572, 104495, 104591, 105826, 104489, 104462, 104479, 104523, 104488, 104509, 104505, 104458, 104580, 104579, 104555, 104448, 104534, 104520, 104465, 104578, 104566, 104470, 104567, 105812, 104464, 104484, 104562, 104584, 104533, 104541, 105810, 104451, 104498, 104510, 104524, 104449, 104561, 105800, 105816, 104436, 104480, 105818, 105823, 104478, 104544, 105825, 104486, 104654, 104662, 104661, 104652, 104666, 104632, 104659, 104660, 104658, 104614, 104588, 104623, 104656, 104657, 104634, 104599, 104616, 104612, 104621, 104617, 104684, 104697, 104619, 105829, 104501, 104640, 104643, 104602, 104639, 104645, 104685, 104681, 104503, 104665, 105830, 104597, 104669, 104610, 104618, 105832, 104624, 104595, 104538, 104543, 104537, 104672, 105833, 105834, 104650, 104638, 104635, 104522, 104558, 104667, 104517, 104604, 104698, 104701, 104688, 104593, 105831, 105828, 104689, 104663, 104686, 104674, 104630, 104611, 104644, 104646, 104615, 104605, 104606, 104622, 104683, 104647, 104631, 104608, 104696, 104679, 104677, 104699, 104594, 104648, 104664, 104629, 104680, 104466, 104642, 104598, 104600, 104596, 104637, 104504, 104620, 104668, 104655, 104651, 104609, 104682, 104607, 104404, 104673, 104592, 104633, 104416, 104641, 104636, 104626, 104649, 104709, 104714, 104711, 105838, 104708, 104704, 104705, 104712, 104713, 104710, 104613, 104724, 104725, 104723, 104720, 104771, 104675, 104676, 104775, 104718, 104719, 104717, 104742, 104743, 104735, 104736, 104740, 104744, 104769, 104706, 104765, 104754, 104752, 104758, 104762, 104766, 104770, 104627, 104747, 104695, 104628, 104727, 104721, 104728, 104726, 104700, 104734, 104715, 104746, 104722, 104730, 104690, 104774, 104781, 104778, 104748, 104738, 104737, 104751, 104703, 104731, 104729, 104768, 104776, 104777, 104761, 104764, 104763, 104625, 104603, 104702"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-32" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>MEDCON_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="medical_hist" class="section level2">
<h2>MEDICAL_HIST</h2>
<pre class="r"><code>df &lt;- MEDICAL_HIST

info(MEDICAL_HIST,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:889, cols:53, inds:871</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    889 obs. of  53 variables:
##  $ SYSXM          : num  7606563 7493573 7592623 7576033 7596083 ...
##  $ SYSIND         : num  11163223 11037553 11160533 11158043 11007943 ...
##  $ SYSGP          : num  7924813 7894373 7896973 7896073 7888893 ...
##  $ SYSGPSTUDY     : num  1362923 1309693 1312293 1311393 1304233 ...
##  $ SYSINDGP       : num  7926433 7793293 7923643 7921153 7762743 ...
##  $ CGI_ORDER      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER   : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY         : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ DB_OWNER       : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY          : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY       : chr  &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADFAMPRADI&quot; ...
##  $ CENTER         : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP             : num  87927 87502 87684 87511 87564 ...
##  $ IND            : num  1 1 103 9006 100 ...
##  $ REFCTR         : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE      : POSIXct, format: &quot;2018-10-17&quot; &quot;2018-01-08&quot; ...
##  $ EXAMINER       : chr  &quot;v.rodriguez4&quot; &quot;axr1589&quot; &quot;axr1589&quot; &quot;axr1589&quot; ...
##  $ DATE_OF_BIRTH  : POSIXct, format: &quot;1933-05-18&quot; &quot;1952-07-06&quot; ...
##  $ AGE_AT_EXAM    : num  85 65 59 60 68 72 77 72 67 88 ...
##  $ XMSTUDY        : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ RELATION       : chr  &quot;Parent&quot; &quot;Spouse&quot; &quot;Spouse&quot; &quot;Spouse&quot; ...
##  $ ANXIETY        : chr  &quot;Y&quot; &quot;N&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ ASTHMA         : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ A_D_D          : chr  &quot;N&quot; &quot;U&quot; &quot;N&quot; &quot;N&quot; ...
##  $ AUTISM         : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ CANCER         : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ CANCER_TYPE    : chr  NA NA NA NA ...
##  $ DEPRESSION     : chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;Y&quot; ...
##  $ DIABETES_TYPE1 : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ DIABETES_TYPE2 : chr  &quot;N&quot; &quot;N&quot; &quot;Y&quot; &quot;N&quot; ...
##  $ DIABETES       : chr  &quot;N&quot; &quot;N&quot; &quot;Y&quot; &quot;N&quot; ...
##  $ LIPIDS_CHOL    : chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;Y&quot; ...
##  $ EPILEPSY       : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ GASTRIC_ULCERS : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ HEART_DISEASE  : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ HYPERTENSION   : chr  &quot;Y&quot; &quot;N&quot; &quot;Y&quot; &quot;N&quot; ...
##  $ KIDNEY_DISEASE : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ LIVER_DISEASE  : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ DEMENTIA       : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ MIGRAINES      : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;U&quot; ...
##  $ M_SCLEROSIS    : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ OBS_COMPULSIVE : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;Y&quot; ...
##  $ OSTEOARTHRITIS : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ OSTEOPOROSIS   : chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ PD             : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ ARTHRITIS      : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ RHINITIS       : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ SPINA_BIFIDA   : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ STROKE         : chr  &quot;N&quot; &quot;N&quot; &quot;N&quot; &quot;N&quot; ...
##  $ THYROID_DISEASE: chr  &quot;Y&quot; &quot;N&quot; &quot;N&quot; &quot;Y&quot; ...
##  $ CIGARETTES     : logi  NA NA NA NA NA NA ...
##  $ CURR_MEDS      : logi  NA NA NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-33" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;MEDICAL_HIST&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-33" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames   `Data Type`
##   &lt;chr&gt;      &lt;chr&gt;      
## 1 REFCTR     VARCHAR2(6)
## 2 CIGARETTES CHAR       
## 3 CURR_MEDS  CHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`)]

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-33" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2018-10-17    1933-05-18
## 2 2018-01-08    1952-07-06
## 3 2018-08-21    1958-10-31
## 4 2018-06-08    1957-10-06
## 5 2018-06-07    1949-07-20
## 6 2018-06-28    1946-01-30</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-33" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 40 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-c905506e3fa21ec4600c" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-c905506e3fa21ec4600c">{"x":{"filter":"none","vertical":false,"data":[["CANCER_TYPE"],["CANCER_TYPE"],["V  O, P  O, S  C  L  O, S  V  O, C  P, L  P"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore CANCER_TYPE, as it is a multiple values variable</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-33" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 11 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<pre><code>## All numeric values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-20e1cb8a70150e9ee020" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-20e1cb8a70150e9ee020">{"x":null,"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-33" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>MEDICAL_HIST &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="mint_rc" class="section level2">
<h2>MINT_RC</h2>
<pre class="r"><code>df &lt;- MINT_RC

info(MINT_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:3, cols:221, inds:3</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    3 obs. of  221 variables:
##  $ SYSXM                    : num  8247903 8300263 8342313
##  $ SYSIND                   : num  11660243 11676853 11667133
##  $ SYSGP                    : num  8011553 8017323 7946313
##  $ SYSGPSTUDY               : num  1458263 1464033 1387423
##  $ SYSINDGP                 : num  8429313 8445923 8436203
##  $ CGI_ORDER                : num  1 1 1
##  $ GPS_ORDER                : num  1 1 1
##  $ STDCGI_ORDER             : num  11 11 11
##  $ LSTUDY                   : chr  &quot;HAFS&quot; &quot;HAFS&quot; &quot;ADCONTROL&quot;
##  $ DB_OWNER                 : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot;
##  $ STUDY                    : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot;
##  $ SUBSTUDY                 : chr  &quot;HAFS&quot; &quot;HAFS&quot; &quot;ADCONTROL&quot;
##  $ CENTER                   : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot;
##  $ GP                       : num  105805 105811 88254
##  $ IND                      : num  1 1 9005
##  $ REFCTR                   : logi  NA NA NA
##  $ EXAM_DATE                : POSIXct, format: &quot;2023-03-17&quot; &quot;2024-03-18&quot; ...
##  $ EXAMINER                 : chr  &quot;gsv32&quot; &quot;mxp1257&quot; &quot;gsv32&quot;
##  $ DATE_OF_BIRTH            : POSIXct, format: &quot;1955-09-07&quot; &quot;1950-03-22&quot; ...
##  $ AGE_AT_EXAM              : num  67 73 62
##  $ REVIEW_DATE              : logi  NA NA NA
##  $ REVIEWER                 : logi  NA NA NA
##  $ MINT1A                   : logi  NA NA NA
##  $ MINT1B                   : num  1 1 1
##  $ MINT1C                   : logi  NA NA NA
##  $ MINT1D                   : num  1 1 1
##  $ MINT1F                   : logi  NA NA NA
##  $ BUTTERFLY_OTHER          : logi  NA NA NA
##  $ MINT2A                   : logi  NA NA NA
##  $ MINT2B                   : num  1 1 1
##  $ MINT2C                   : logi  NA NA NA
##  $ MINT2D                   : num  1 1 1
##  $ MINT2F                   : logi  NA NA NA
##  $ GLOVE_OTHER              : logi  NA NA NA
##  $ MINT3A                   : logi  NA NA NA
##  $ MINT3B                   : num  1 1 1
##  $ MINT3C                   : logi  NA NA NA
##  $ MINT3D                   : num  1 1 1
##  $ MINT3F                   : logi  NA NA NA
##  $ LIGHTBULB_OTHER          : logi  NA NA NA
##  $ MINT4A                   : logi  NA NA NA
##  $ MINT4B                   : num  1 1 1
##  $ MINT4C                   : logi  NA NA NA
##  $ MINT4D                   : num  1 1 1
##  $ MINT4F                   : logi  NA NA NA
##  $ WATCH_OTHER              : logi  NA NA NA
##  $ MINT5A                   : logi  NA NA NA
##  $ MINT5B                   : num  1 1 1
##  $ MINT5C                   : logi  NA NA NA
##  $ MINT5D                   : num  1 1 1
##  $ MINT5F                   : logi  NA NA NA
##  $ CANDLE_OTHER             : logi  NA NA NA
##  $ MINT6A                   : logi  NA NA NA
##  $ MINT6B                   : num  1 1 1
##  $ MINT6C                   : logi  NA NA NA
##  $ MINT6D                   : num  1 1 1
##  $ MINT6F                   : logi  NA NA NA
##  $ CLOWN_OTHER              : logi  NA NA NA
##  $ MINT7A                   : logi  NA NA NA
##  $ MINT7B                   : num  1 1 1
##  $ MINT7C                   : logi  NA NA NA
##  $ MINT7D                   : num  1 1 1
##  $ MINT7F                   : logi  NA NA NA
##  $ KITE_OTHER               : logi  NA NA NA
##  $ MINT8A                   : logi  NA NA NA
##  $ MINT8B                   : num  1 1 1
##  $ MINT8C                   : logi  NA NA NA
##  $ MINT8D                   : num  1 1 1
##  $ MINT8F                   : logi  NA NA NA
##  $ RAINBOW_OTHER            : logi  NA NA NA
##  $ MINT9A                   : logi  NA NA NA
##  $ MINT9B                   : num  1 1 1
##  $ MINT9C                   : logi  NA NA NA
##  $ MINT9D                   : num  1 1 1
##  $ MINT9F                   : logi  NA NA NA
##  $ WITCH_OTHER              : logi  NA NA NA
##  $ MINT10A                  : logi  NA NA NA
##  $ MINT10B                  : num  1 1 1
##  $ MINT10C                  : logi  NA NA NA
##  $ MINT10D                  : num  1 1 1
##  $ MINT10F                  : logi  NA NA NA
##  $ SEESAW_OTHER             : logi  NA NA NA
##  $ MINT11A                  : logi  NA NA NA
##  $ MINT11B                  : num  1 1 1
##  $ MINT11C                  : logi  NA NA NA
##  $ MINT11D                  : num  1 1 1
##  $ MINT11F                  : logi  NA NA NA
##  $ FLASHLIGHT_OTHER         : logi  NA NA NA
##  $ MINT12A                  : logi  NA NA NA
##  $ MINT12B                  : num  1 1 1
##  $ MINT12C                  : logi  NA NA NA
##  $ MINT12D                  : num  1 1 1
##  $ MINT12F                  : logi  NA NA NA
##  $ PEACOCK_OTHER            : logi  NA NA NA
##  $ MINT13A                  : logi  NA NA NA
##  $ MINT13B                  : num  1 1 1
##  $ MINT13C                  : logi  NA NA NA
##  $ MINT13D                  : num  1 1 1
##  $ MINT13F                  : logi  NA NA NA
##  $ SNAIL_OTHER              : logi  NA NA NA
##  $ MINT14A                  : logi  NA NA NA
##  $ MINT14B                  : num  1 1 1
##  $ MINT14C                  : logi  NA NA NA
##  $ MINT14D                  : num  1 1 1
##  $ MINT14F                  : logi  NA NA NA
##  $ WHALE_OTHER              : logi  NA NA NA
##  $ MINT15A                  : logi  NA NA NA
##  $ MINT15B                  : num  1 1 1
##  $ MINT15C                  : logi  NA NA NA
##  $ MINT15D                  : num  1 1 1
##  $ MINT15F                  : logi  NA NA NA
##  $ CAGE_OTHER               : logi  NA NA NA
##  $ MINT16A                  : logi  NA NA NA
##  $ MINT16B                  : num  1 1 1
##  $ MINT16C                  : logi  NA NA NA
##  $ MINT16D                  : num  1 1 1
##  $ MINT16F                  : logi  NA NA NA
##  $ NEST_OTHER               : logi  NA NA NA
##  $ MINT17A                  : logi  NA NA NA
##  $ MINT17B                  : num  1 1 1
##  $ MINT17C                  : logi  NA NA NA
##  $ MINT17D                  : num  1 1 1
##  $ MINT17F                  : logi  NA NA NA
##  $ PLUG_OTHER               : logi  NA NA NA
##  $ MINT18A                  : logi  NA NA NA
##  $ MINT18B                  : num  1 1 1
##  $ MINT18C                  : logi  NA NA NA
##  $ MINT18D                  : num  1 1 1
##  $ MINT18F                  : logi  NA NA NA
##  $ WIG_OTHER                : logi  NA NA NA
##  $ MINT19A                  : logi  NA NA NA
##  $ MINT19B                  : num  1 1 1
##  $ MINT19C                  : logi  NA NA NA
##  $ MINT19D                  : num  1 1 1
##  $ MINT19F                  : logi  NA NA NA
##  $ SCREW_OTHER              : logi  NA NA NA
##  $ MINT20A                  : logi  NA NA NA
##  $ MINT20B                  : num  1 1 1
##  $ MINT20C                  : logi  NA NA NA
##  $ MINT20D                  : num  1 1 1
##  $ MINT20F                  : logi  NA NA NA
##  $ SCARF_OTHER              : logi  NA NA NA
##  $ MINT21A                  : logi  NA NA NA
##  $ MINT21B                  : num  1 1 1
##  $ MINT21C                  : logi  NA NA NA
##  $ MINT21D                  : num  1 1 1
##  $ MINT21F                  : logi  NA NA NA
##  $ WELL_OTHER               : logi  NA NA NA
##  $ MINT22A                  : logi  NA NA NA
##  $ MINT22B                  : num  1 1 1
##  $ MINT22C                  : logi  NA NA NA
##  $ MINT22D                  : num  1 1 1
##  $ MINT22F                  : logi  NA NA NA
##  $ DUSTPAN_OTHER            : logi  NA NA NA
##  $ MINT23A                  : logi  NA NA NA
##  $ MINT23B                  : num  1 1 1
##  $ MINT23C                  : logi  NA NA NA
##  $ MINT23D                  : num  1 1 1
##  $ MINT23F                  : logi  NA NA NA
##  $ PARACHUTE_OTHER          : logi  NA NA NA
##  $ MINT24A                  : num  NA 1 NA
##  $ MINT24B                  : num  1 NA 1
##  $ MINT24C                  : num  NA 1 NA
##  $ MINT24D                  : num  1 1 1
##  $ MINT24F                  : logi  NA NA NA
##  $ BLIND_OTHER              : chr  NA &quot;BALLENA&quot; NA
##  $ MINT25A                  : logi  NA NA NA
##  $ MINT25B                  : num  1 1 1
##  $ MINT25C                  : logi  NA NA NA
##  $ MINT25D                  : num  1 1 1
##  $ MINT25F                  : logi  NA NA NA
##  $ HINGE_OTHER              : logi  NA NA NA
##  $ MINT26A                  : logi  NA NA NA
##  $ MINT26B                  : num  1 1 1
##  $ MINT26C                  : logi  NA NA NA
##  $ MINT26D                  : num  1 1 1
##  $ MINT26F                  : logi  NA NA NA
##  $ FUNNEL_OTHER             : logi  NA NA NA
##  $ MINT27A                  : num  NA 1 NA
##  $ MINT27B                  : num  1 NA 1
##  $ MINT27C                  : num  NA 1 NA
##  $ MINT27D                  : num  1 1 1
##  $ MINT27F                  : logi  NA NA NA
##  $ GAUGE_OTHER              : chr  NA &quot;BISAGRA&quot; NA
##  $ MINT28A                  : num  NA 1 NA
##  $ MINT28B                  : num  1 NA 1
##  $ MINT28C                  : num  NA 0 NA
##  $ MINT28D                  : num  1 0 1
##  $ MINT28F                  : num  NA 0 NA
##  $ PORTHOLE_OTHER           : chr  NA &quot;NONE&quot; NA
##  $ MINT29A                  : num  1 1 NA
##  $ MINT29B                  : num  NA NA 1
##  $ MINT29C                  : num  0 1 NA
##  $ MINT29D                  : num  0 1 1
##  $ MINT29F                  : num  0 NA NA
##  $ ANVIL_OTHER              : chr  &quot;doesn&#39;t know&quot; &quot;yunque&quot; NA
##  $ MINT30A                  : logi  NA NA NA
##  $ MINT30B                  : num  1 1 1
##  $ MINT30C                  : logi  NA NA NA
##  $ MINT30D                  : num  1 1 1
##  $ MINT30F                  : logi  NA NA NA
##  $ MORTAR_OTHER             : logi  NA NA NA
##  $ MINT31A                  : num  NA 1 NA
##  $ MINT31B                  : num  1 NA 1
##  $ MINT31C                  : num  NA 0 NA
##  $ MINT31D                  : num  1 0 1
##  $ MINT31F                  : num  NA 0 NA
##  $ PESTLE_OTHER             : chr  NA &quot;none&quot; NA
##  $ MINT32A                  : logi  NA NA NA
##  $ MINT32B                  : num  1 1 1
##  $ MINT32C                  : logi  NA NA NA
##  $ MINT32D                  : num  1 1 1
##  $ MINT32F                  : logi  NA NA NA
##  $ AXLE_OTHER               : logi  NA NA NA
##  $ COMMENTS_MINT            : logi  NA NA NA
##  $ MINT_TOT_NO_CUE          : num  31 27 32
##  $ MINT_STIM_CUE            : num  0 3 0
##  $ MINT_PHON_CUE            : num  1 2 0
##  $ MINT_CORR_PHON_CUE       : num  0 0 0
##  $ MINT_CORR_STIM_CUE       : num  31 30 32
##  $ MINT_CORR_STIM_CUE_STATUS: logi  NA NA NA</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-34" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;MINT_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-34" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)] ## 115 vars 

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 115 × 2
##    VarNames        `Data Type`
##    &lt;chr&gt;           &lt;chr&gt;      
##  1 REFCTR          VARCHAR2(6)
##  2 REVIEW_DATE     date       
##  3 REVIEWER        CHAR       
##  4 MINT1A          NUMBER(1)  
##  5 MINT1C          NUMBER(1)  
##  6 MINT1F          NUMBER(1)  
##  7 BUTTERFLY_OTHER CHAR       
##  8 MINT2A          NUMBER(1)  
##  9 MINT2C          NUMBER(1)  
## 10 MINT2F          NUMBER(1)  
## # ℹ 105 more rows</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)] ## 31 vars
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`,,ignore.case = T)] ## 1 var
convert2num &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;NUMBER&quot;, dfDD$`Data Type`,,ignore.case = T)] ## 83 vars

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2num] &lt;- lapply(df[convert2date], as.numeric)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-34" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-03-17    1955-09-07
## 2 2024-03-18    1950-03-22
## 3 2023-01-18    1960-05-04</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-34" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 42 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-895e5d7efd621fb3bfaa" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-895e5d7efd621fb3bfaa">{"x":null,"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-34" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 176 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;&quot;           
## [5] &quot;0;\r\n1;&quot;      &quot;1;\r\n0;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-13e0521a883a5d56d86b" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-13e0521a883a5d56d86b">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["105805, 105811"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-34" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>MINT_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="mint_sp_rc" class="section level2">
<h2>MINT_SP_RC</h2>
<pre class="r"><code>df &lt;- MINT_SP_RC

info(MINT_SP_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:303, cols:221, inds:301</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    303 obs. of  221 variables:
##  $ SYSXM                       : num  8260003 8260193 8277393 8278083 8260823 ...
##  $ SYSIND                      : num  11163453 11620563 11620453 11621333 11621203 ...
##  $ SYSGP                       : num  7924953 8005633 8005523 8006293 8006163 ...
##  $ SYSGPSTUDY                  : num  1363063 1452343 1452233 1453003 1452873 ...
##  $ SYSINDGP                    : num  7926663 8389633 8389523 8390403 8390273 ...
##  $ CGI_ORDER                   : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                   : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER                : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                      : chr  &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER                    : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                       : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                    : chr  &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                      : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                          : num  87923 104477 104476 104528 104455 ...
##  $ IND                         : num  9000 1 1 1 1 1 1 1 1 1 ...
##  $ REFCTR                      : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                   : POSIXct, format: &quot;2023-10-25&quot; &quot;2023-05-15&quot; ...
##  $ EXAMINER                    : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH               : POSIXct, format: &quot;1967-06-15&quot; &quot;1949-12-01&quot; ...
##  $ AGE_AT_EXAM                 : num  56 73 73 86 81 77 67 80 74 73 ...
##  $ REVIEW_DATE                 : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                    : logi  NA NA NA NA NA NA ...
##  $ MINT1A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT1B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT1C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT1D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT1F_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ TAMBOR_OTHER_SP             : chr  NA NA NA NA ...
##  $ MINT2A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT2B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT2C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT2D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT2F_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ GLOVE_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT3A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT3B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT3C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT3D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT3F_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ LIGHTBULB_OTHER_SP          : chr  NA NA NA NA ...
##  $ MINT4A_SP                   : num  NA NA NA 1 1 NA NA NA NA 1 ...
##  $ MINT4B_SP                   : num  1 1 1 NA NA 1 1 1 1 NA ...
##  $ MINT4C_SP                   : num  NA NA NA 1 1 NA NA NA NA 0 ...
##  $ MINT4D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT4F_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ WATCH_OTHER_SP              : chr  NA NA NA &quot;-&quot; ...
##  $ MINT5A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT5B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT5C_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT5D_SP                   : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT5F_SP                   : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CANDLE_OTHER_SP             : chr  NA NA NA NA ...
##  $ MINT6A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT6B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT6C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT6D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT6F_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ CLOWN_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT7A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT7B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT7C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT7D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT7F_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ KITE_OTHER_SP               : chr  NA NA NA NA ...
##  $ MINT8A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT8B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT8C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT8D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT8F_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ RAINBOW_OTHER_SP            : chr  NA NA NA NA ...
##  $ MINT9A_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT9B_SP                   : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT9C_SP                   : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT9D_SP                   : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT9F_SP                   : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ WITCH_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT10A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT10B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT10C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT10D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT10F_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ SEESAW_OTHER_SP             : chr  NA NA NA NA ...
##  $ MINT11A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT11B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT11C_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT11D_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT11F_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ FLASHLIGHT_OTHER_SP         : chr  NA NA NA NA ...
##  $ MINT12A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT12B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT12C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT12D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT12F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ PEACOCK_OTHER_SP            : chr  NA NA NA NA ...
##  $ MINT13A_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MINT13B_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT13C_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MINT13D_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT13F_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SNAIL_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT14A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT14B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT14C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT14D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT14F_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ WHALE_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT15A_SP                  : num  NA NA 1 NA 1 NA NA NA NA 1 ...
##  $ MINT15B_SP                  : num  1 1 NA 1 NA 1 1 1 1 NA ...
##  $ MINT15C_SP                  : num  NA NA 1 NA 1 NA NA NA NA 1 ...
##  $ MINT15D_SP                  : num  NA NA 1 NA 1 NA NA NA NA 1 ...
##  $ MINT15F_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ CAGE_OTHER_SP               : chr  NA NA &quot;---&quot; NA ...
##  $ MINT16A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT16B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT16C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT16D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT16F_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ NEST_OTHER_SP               : chr  NA NA NA NA ...
##  $ MINT17A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT17B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT17C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT17D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT17F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ PLUG_OTHER_SP               : chr  NA NA NA NA ...
##  $ MINT18A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT18B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT18C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT18D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT18F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ WIG_OTHER_SP                : chr  NA NA NA NA ...
##  $ MINT19A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT19B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT19C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT19D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT19F_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ SCREW_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT20A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT20B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT20C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT20D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT20F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ SCARF_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT21A_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MINT21B_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT21C_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MINT21D_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT21F_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ WELL_OTHER_SP               : chr  NA NA NA NA ...
##  $ MINT22A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT22B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT22C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT22D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT22F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ DUSTPAN_OTHER_SP            : chr  NA NA NA NA ...
##  $ MINT23A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT23B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT23C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT23D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT23F_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ PARACHUTE_OTHER_SP          : chr  NA NA NA NA ...
##  $ MINT24A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT24B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT24C_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ MINT24D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT24F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ BLIND_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT25A_SP                  : num  NA NA NA NA NA NA 1 NA NA 1 ...
##  $ MINT25B_SP                  : num  1 1 1 1 1 1 NA 1 1 NA ...
##  $ MINT25C_SP                  : num  NA NA NA NA NA NA 0 NA NA 1 ...
##  $ MINT25D_SP                  : num  1 1 1 1 1 1 0 1 1 1 ...
##  $ MINT25F_SP                  : num  NA NA NA NA NA NA 1 NA NA NA ...
##  $ HINGE_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT26A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT26B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT26C_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT26D_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT26F_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ FUNNEL_OTHER_SP             : chr  NA NA NA NA ...
##  $ MINT27A_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT27B_SP                  : num  1 1 1 1 1 1 1 1 1 NA ...
##  $ MINT27C_SP                  : num  NA NA NA NA NA NA NA NA NA 1 ...
##  $ MINT27D_SP                  : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MINT27F_SP                  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ GAUGE_OTHER_SP              : chr  NA NA NA NA ...
##  $ MINT28A_SP                  : num  1 NA NA NA 1 NA NA NA NA 1 ...
##  $ MINT28B_SP                  : num  NA 1 1 1 NA 1 1 1 1 NA ...
##  $ MINT28C_SP                  : num  0 NA NA NA 1 NA NA NA NA 1 ...
##  $ MINT28D_SP                  : num  0 1 1 1 1 1 1 1 1 1 ...
##  $ MINT28F_SP                  : num  1 NA NA NA NA NA NA NA NA NA ...
##  $ PORTHOLE_OTHER_SP           : chr  &quot;bisagra&quot; NA NA NA ...
##  $ MINT29A_SP                  : num  1 1 NA NA NA NA 1 NA NA NA ...
##  $ MINT29B_SP                  : num  NA NA 1 1 1 1 NA 1 1 1 ...
##  $ MINT29C_SP                  : num  0 0 NA NA NA NA 0 NA NA NA ...
##  $ MINT29D_SP                  : num  0 0 1 1 1 1 0 1 1 1 ...
##  $ MINT29F_SP                  : num  0 0 NA NA NA NA 0 NA NA NA ...
##  $ ANVIL_OTHER_SP              : chr  &quot;n/a&quot; NA NA NA ...
##  $ MINT30A_SP                  : num  NA 1 NA NA NA NA NA NA NA 1 ...
##  $ MINT30B_SP                  : num  1 NA 1 1 1 1 1 1 1 NA ...
##  $ MINT30C_SP                  : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ MINT30D_SP                  : num  1 0 1 1 1 1 1 1 1 0 ...
##  $ MINT30F_SP                  : num  NA 0 NA NA NA NA NA NA NA 0 ...
##  $ MORTAR_OTHER_SP             : chr  NA NA NA NA ...
##  $ MINT31A_SP                  : num  1 1 NA NA NA NA 1 NA NA 1 ...
##  $ MINT31B_SP                  : num  NA NA 1 1 1 1 NA 1 1 NA ...
##  $ MINT31C_SP                  : num  0 0 NA NA NA NA 0 NA NA 0 ...
##  $ MINT31D_SP                  : num  0 0 1 1 1 1 0 1 1 0 ...
##  $ MINT31F_SP                  : num  0 0 NA NA NA NA 0 NA NA 0 ...
##  $ PESTLE_OTHER_SP             : chr  &quot;n/a&quot; NA NA NA ...
##  $ MINT32A_SP                  : num  NA NA NA NA NA NA 1 NA NA 1 ...
##  $ MINT32B_SP                  : num  1 1 1 1 1 1 NA 1 1 NA ...
##  $ MINT32C_SP                  : num  NA NA NA NA NA NA 1 NA NA 0 ...
##  $ MINT32D_SP                  : num  1 1 1 1 1 1 1 1 1 0 ...
##  $ MINT32F_SP                  : num  NA NA NA NA NA NA NA NA NA 0 ...
##  $ AXLE_OTHER_SP               : chr  NA NA NA NA ...
##  $ COMMENTS_MINT_SP            : chr  NA NA NA NA ...
##  $ MINT_TOT_NO_CUE_SP          : num  29 29 31 31 29 32 28 32 32 3 ...
##  $ MINT_STIM_CUE_SP            : num  0 0 1 1 3 0 1 0 0 7 ...
##  $ MINT_PHON_CUE_SP            : num  3 3 0 0 0 0 3 0 0 22 ...
##  $ MINT_CORR_PHON_CUE_SP       : num  1 0 0 0 0 0 1 0 0 8 ...
##  $ MINT_CORR_STIM_CUE_SP       : num  29 29 32 32 32 32 29 32 32 10 ...
##  $ MINT_CORR_STIM_CUE_SP_STATUS: chr  NA NA NA NA ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-35" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;MINT_SP_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-35" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## converted to character
convert2chr &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;CHAR&quot;, dfDD$`Data Type`,ignore.case = T)] ## 2 vars
convert2date &lt;- dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;, dfDD$`Data Type`,,ignore.case = T)] ## 1 var

## convert
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)
df[convert2date] &lt;- lapply(df[convert2date], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-35" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## REVIEW_DATE, ignore it, it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2023-10-25    1967-06-15
## 2 2023-05-15    1949-12-01
## 3 2023-05-15    1950-04-02
## 4 2023-05-09    1936-05-22
## 5 2023-02-24    1941-10-04
## 6 2023-08-11    1946-06-19</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-35" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 42 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-b16fe2ecb6bb6dd70e3b" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-b16fe2ecb6bb6dd70e3b">{"x":null,"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore EXAMINER</code></pre>
<p><br></p>
</div>
<div id="handling-numeric-variables-35" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 176 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;&quot;           
## [5] &quot;0;\r\n1;&quot;      &quot;1;\r\n0;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-d803526b3b005a26b4c4" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-d803526b3b005a26b4c4">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104476, 104528, 104455, 104511, 104471, 104548, 104452, 104459, 104500, 104499, 104525, 105801, 104497, 104531, 104536, 104472, 104469, 104487, 104496, 104490, 104453, 104526, 105804, 104518, 104454, 104514, 104513, 104508, 104475, 104481, 104539, 104527, 104532, 104456, 104466, 104507, 104529, 104464, 104530, 104501, 105809, 104489, 104569, 104564, 104563, 104468, 104557, 104465, 105803, 104519, 105826, 105807, 104578, 104470, 104474, 104582, 104584, 104447, 104506, 104573, 104494, 104570, 104583, 104450, 105813, 104510, 104473, 104480, 104586, 104585, 104562, 104482, 104484, 104572, 104495, 104462, 104479, 104560, 105808, 104488, 104505, 104579, 105814, 104534, 104566, 104581, 104533, 104467, 104451, 104498, 104524, 104485, 104567, 104574, 104449, 104575, 104502, 105811, 105800, 104483, 104478, 105823, 104640, 104611, 104623, 104621, 104617, 104697, 105833, 105829, 104619, 104643, 104680, 104685, 104688, 104665, 104616, 104624, 104648, 104599, 104638, 104522, 104517, 104672, 104698, 104593, 104682, 104686, 104646, 105830, 104622, 104608, 105828, 105832, 105834, 105831, 104642, 104504, 104503, 104620, 104650, 105838, 104746, 107011, 107007, 104775, 107132, 107024, 104754, 107003, 107005, 107009, 104674, 107175, 104736, 104744, 104751, 104765, 104690, 107124, 104706, 107020, 107100, 104774, 107181, 104695, 107104, 104783, 107012, 104768, 104764, 104675, 104676, 104748, 104603, 107016"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-35" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>MINT_SP_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="moca_rc" class="section level2">
<h2>MOCA_RC</h2>
<pre class="r"><code>df &lt;- MOCA_RC

info(MOCA_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:585, cols:140, inds:580</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    585 obs. of  140 variables:
##  $ SYSXM                         : num  8258783 8258823 8259093 8260053 8260123 ...
##  $ SYSIND                        : num  11037673 11369813 11024163 11620563 11362953 ...
##  $ SYSGP                         : num  7894423 7952013 7889113 8005633 7946353 ...
##  $ SYSGPSTUDY                    : num  1309743 1397123 1304453 1452343 1387463 ...
##  $ SYSINDGP                      : num  7793413 8139083 7779783 8389633 8132223 ...
##  $ CGI_ORDER                     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER                     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER                  : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY                        : chr  &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER                      : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                         : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY                      : chr  &quot;ADFAMPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER                        : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                            : num  87650 88301 87536 104477 87545 ...
##  $ IND                           : num  9000 1 112 1 106 ...
##  $ REFCTR                        : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE                     : POSIXct, format: &quot;2023-10-24&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER                      : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH                 : POSIXct, format: &quot;1954-10-29&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM                   : num  68 76 79 73 66 81 86 73 81 60 ...
##  $ REVIEW_DATE                   : logi  NA NA NA NA NA NA ...
##  $ REVIEWER                      : logi  NA NA NA NA NA NA ...
##  $ MOCALOC                       : num  2 2 3 3 2 2 3 2 2 2 ...
##  $ MOCALOC_OTHER                 : chr  NA NA NA NA ...
##  $ MOCALAN                       : num  2 2 2 2 2 2 2 2 2 2 ...
##  $ MOCALANX                      : logi  NA NA NA NA NA NA ...
##  $ MOCATRAI                      : num  0 1 1 1 0 1 1 1 1 1 ...
##  $ MOCACUBE                      : num  0 0 1 0 0 0 0 0 1 1 ...
##  $ MOCACLOC                      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCACLON                      : num  1 0 1 1 1 1 1 0 0 1 ...
##  $ MOCACLOH                      : num  1 0 1 1 0 0 0 1 1 0 ...
##  $ MOCANAMI_LION                 : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCANAMI_LION_OTH             : chr  NA NA NA NA ...
##  $ MOCANAMI_RHINO                : num  1 0 0 1 1 1 1 1 1 1 ...
##  $ MOCANAMI_RHINO_OTH            : chr  NA NA NA NA ...
##  $ MOCANAMI_CAMEL                : num  1 1 1 1 1 1 1 0 1 1 ...
##  $ MOCANAMI_CAMEL_OTH            : chr  NA NA NA NA ...
##  $ MOCAREGI1                     : num  0 0 1 1 1 1 0 1 1 1 ...
##  $ MOCAREGI2                     : num  1 1 1 0 1 0 0 1 1 1 ...
##  $ MOCAREGI3                     : num  1 1 0 0 0 1 1 1 1 0 ...
##  $ MOCAREGI4                     : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCAREGI5                     : num  1 0 1 1 1 1 1 0 0 1 ...
##  $ MOCAREGI6                     : num  1 1 1 1 1 0 1 1 1 1 ...
##  $ MOCAREGI7                     : num  0 1 1 1 1 1 1 1 1 1 ...
##  $ MOCAREGI8                     : num  1 1 1 1 1 1 1 1 0 1 ...
##  $ MOCAREGI9                     : num  1 1 0 1 1 1 0 1 1 1 ...
##  $ MOCAREGI10                    : num  1 1 1 1 1 1 0 1 1 1 ...
##  $ MOCADIGI_FORW                 : num  1 1 1 1 1 0 0 1 1 1 ...
##  $ MOCADIGI_FORW_INCORRECT       : chr  NA NA NA NA ...
##  $ MOCADIGI_BACK                 : num  1 1 1 0 1 1 0 0 1 1 ...
##  $ MOCADIGI_BACK_INCORRECT       : chr  NA NA NA NA ...
##  $ MOCALETT                      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCASER7_93                   : num  1 0 1 1 1 1 1 1 1 1 ...
##  $ MOCASER7_93_OTH               : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_86                   : num  0 0 1 1 0 1 1 0 1 1 ...
##  $ MOCASER7_86_OTH               : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_79                   : num  1 0 1 1 1 1 1 0 0 1 ...
##  $ MOCASER7_79_OTH               : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_72                   : num  1 0 1 1 1 1 1 0 1 1 ...
##  $ MOCASER7_72_OTH               : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_65                   : num  0 0 1 1 0 0 1 0 0 1 ...
##  $ MOCASER7_65_OTH               : logi  NA NA NA NA NA NA ...
##  $ MOCAREPE_1                    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCAREPE_2                    : num  1 0 1 1 0 0 0 1 1 1 ...
##  $ MOCAFLUEF_60SEC               : chr  &quot;finca, feo, flor, farmacia, fosforo, freno, ficticio&quot; &quot;FRACCION FAMILIA FRACCION (X) FUERTE&quot; &quot;Feo Fricos Farmacia Faro&quot; &quot;FALSO FEO FRIALDAD FENOMENO FACILIDAD FELICIDAD&quot; ...
##  $ MOCAFLUE_SCORE                : num  0 0 0 0 1 0 0 1 1 1 ...
##  $ MOCAABST_TRAIN                : num  1 1 1 1 0 0 1 1 1 1 ...
##  $ MOCAABST_RULER                : num  1 1 1 1 0 1 0 1 1 1 ...
##  $ MOCARECN_1                    : num  1 NA NA NA 1 NA NA NA NA NA ...
##  $ MOCARECN_2                    : num  1 NA NA NA NA NA NA NA 1 1 ...
##  $ MOCARECN_3                    : num  1 NA NA NA 1 NA 1 NA NA 1 ...
##  $ MOCARECN_4                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MOCARECN_5                    : num  NA NA NA NA NA NA 1 NA 1 NA ...
##  $ MOCARECC_1                    : num  NA NA NA 1 NA NA NA NA NA NA ...
##  $ MOCARECC_2                    : num  NA NA NA 1 1 NA 1 NA NA NA ...
##  $ MOCARECC_3                    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MOCARECC_4                    : num  NA NA NA 1 NA NA 1 NA NA NA ...
##  $ MOCARECC_5                    : num  1 1 NA 1 NA 1 NA NA NA NA ...
##  $ MOCARECR_1                    : num  NA 1 1 NA NA NA 1 1 1 1 ...
##  $ MOCARECR_2                    : num  NA 1 1 NA NA NA NA 1 NA NA ...
##  $ MOCARECR_3                    : num  NA 1 1 1 NA 1 NA 1 1 NA ...
##  $ MOCARECR_4                    : num  1 1 1 NA 1 1 NA NA 1 1 ...
##  $ MOCARECR_5                    : num  NA NA 1 NA 1 NA NA NA NA 1 ...
##  $ MOCARECN_REC1                 : num  NA NA NA NA NA 0 NA NA NA NA ...
##  $ MOCARECN_REC2                 : num  NA NA NA NA NA 0 NA NA NA NA ...
##  $ MOCARECN_REC3                 : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ MOCARECN_REC4                 : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ MOCARECN_REC5                 : num  NA NA NA NA NA NA NA 0 NA NA ...
##  $ MOCAORDT_ENTRY                : POSIXct, format: &quot;2023-10-23&quot; &quot;2024-02-13&quot; ...
##  $ MOCAORDT                      : num  0 1 1 1 0 1 1 1 1 1 ...
##  $ MOCAORMO_ENTRY                : chr  NA NA NA NA ...
##  $ MOCAORMO                      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCAORYR_ENTRY                : chr  NA NA NA NA ...
##  $ MOCAORYR                      : num  1 1 1 1 0 1 1 1 1 1 ...
##  $ MOCAORDY_ENTRY                : chr  NA NA NA NA ...
##  $ MOCAORDY                      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCAORPL_ENTRY                : chr  NA NA NA NA ...
##  $ MOCAORPL                      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCAORCT_ENTRY                : chr  NA NA NA NA ...
##  $ MOCAORCT                      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ MOCA_EDU                      : num  1 0 0 0 1 1 0 0 0 0 ...
##  $ NACC_MOCA                     : chr  NA NA NA NA ...
##  $ MOCAVISEXE_SCORE              : num  3 2 5 4 2 3 3 3 4 4 ...
##  $ MOCAVISEXE_SCORE_STATUS       : chr  NA NA NA NA ...
##  $ MOCANAMI_SCORE                : num  3 2 2 3 3 3 3 2 3 3 ...
##  $ MOCANAMI_SCORE_STATUS         : chr  NA NA NA NA ...
##  $ SCORE_REGISTRATION            : num  8 8 8 8 9 8 6 9 8 9 ...
##  $ SCORE_REGISTRATION_STATUS     : logi  NA NA NA NA NA NA ...
##  $ MOCADIGI_SCORE                : num  2 2 2 1 2 1 0 1 2 2 ...
##  $ MOCADIGI_SCORE_STATUS         : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_93_SCORE             : num  1 0 1 1 1 1 1 1 1 1 ...
##  $ MOCASER7_93_SCORE_STATUS      : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_86_SCORE             : num  0 0 1 1 0 1 1 0 1 1 ...
##  $ MOCASER7_86_SCORE_SCORE_STATUS: logi  NA NA NA NA NA NA ...
##  $ MOCASER7_79_SCORE             : num  1 0 1 1 1 1 1 0 0 1 ...
##  $ MOCASER7_79_SCORE_STATUS      : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_72_SCORE             : num  1 0 1 1 1 1 1 0 1 1 ...
##  $ MOCASER7_72_SCORE_STATUS      : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_65_SCORE             : num  0 0 1 1 0 0 1 0 0 1 ...
##  $ MOCASER7_65_SCORE_STATUS      : logi  NA NA NA NA NA NA ...
##  $ MOCASER7_SCORE                : num  3 0 5 5 3 4 5 1 3 5 ...
##  $ MOCASER7_SCORE_STATUS         : chr  NA NA NA NA ...
##  $ MOCASER7_POINTSCORE           : num  2 0 3 3 2 3 3 1 2 3 ...
##  $ MOCASER7_POINTSCORE_STATUS    : chr  NA NA NA NA ...
##  $ MOCAREPE_SCORE                : num  2 1 2 2 1 1 1 2 2 2 ...
##  $ MOCAREPE_SCORE_STATUS         : logi  NA NA NA NA NA NA ...
##  $ MOCAABST_SCORE                : num  2 2 2 2 0 1 1 2 2 2 ...
##  $ MOCAABST_SCORE_STATUS         : logi  NA NA NA NA NA NA ...
##  $ MOCARECN_SCORE                : num  3 0 0 0 2 0 2 0 2 2 ...
##  $ MOCARECN_SCORE_STATUS         : chr  &quot;partial&quot; NA NA NA ...
##  $ MOCARECC_SCORE                : num  1 1 0 4 1 1 2 0 0 0 ...
##  $ MOCARECC_SCORE_STATUS         : chr  &quot;partial&quot; &quot;partial&quot; NA &quot;partial&quot; ...
##  $ MOCARECR_SCORE                : num  1 4 5 1 2 2 1 3 3 3 ...
##  $ MOCARECR_SCORE_STATUS         : chr  &quot;partial&quot; &quot;partial&quot; NA &quot;partial&quot; ...
##  $ MOCAOR_SCORE                  : num  5 6 6 6 4 6 6 6 6 6 ...
##  $ MOCAOR_SCORE_STATUS           : chr  NA NA NA NA ...
##  $ MOCATOTS                      : num  23 16 23 22 18 19 20 19 25 26 ...
##  $ MOCATOTS_STATUS               : chr  &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; ...
##  $ NACCMOCA                      : num  24 16 23 22 19 20 20 19 25 26 ...
##  $ NACCMOCA_STATUS               : chr  &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-36" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;MOCA_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-36" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 18 × 2
##    VarNames                       `Data Type` 
##    &lt;chr&gt;                          &lt;chr&gt;       
##  1 REFCTR                         VARCHAR2(6) 
##  2 REVIEW_DATE                    date        
##  3 REVIEWER                       CHAR        
##  4 MOCALANX                       VARCHAR2(25)
##  5 MOCASER7_93_OTH                VARCHAR2(5) 
##  6 MOCASER7_86_OTH                VARCHAR2(5) 
##  7 MOCASER7_79_OTH                VARCHAR2(5) 
##  8 MOCASER7_72_OTH                VARCHAR2(5) 
##  9 MOCASER7_65_OTH                VARCHAR2(5) 
## 10 SCORE_REGISTRATION_STATUS      CHAR        
## 11 MOCADIGI_SCORE_STATUS          CHAR        
## 12 MOCASER7_93_SCORE_STATUS       CHAR        
## 13 MOCASER7_86_SCORE_SCORE_STATUS CHAR        
## 14 MOCASER7_79_SCORE_STATUS       CHAR        
## 15 MOCASER7_72_SCORE_STATUS       CHAR        
## 16 MOCASER7_65_SCORE_STATUS       CHAR        
## 17 MOCAREPE_SCORE_STATUS          CHAR        
## 18 MOCAABST_SCORE_STATUS          CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## 17 vars

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-36" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;      &quot;DATE_OF_BIRTH&quot;  &quot;MOCAORDT_ENTRY&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;,&quot;Date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH MOCAORDT_ENTRY
## 1 2023-10-24    1954-10-29     2023-10-23
## 2 2024-02-13    1947-05-13     2024-02-13
## 3 2023-10-25    1944-07-28     2023-10-25
## 4 2023-05-15    1949-12-01     2023-05-15
## 5 2024-02-20    1957-08-05     2024-02-20
## 6 2024-02-15    1942-09-30     2024-02-15</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-36" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 46 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0) 
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-48306bdb669c98471f73" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-48306bdb669c98471f73">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="handling-numeric-variables-36" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 90 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA               &quot;1 thru 99999;&quot;  &quot;1 thru 9999;&quot;   &quot;1;\r\n2;\r\n3;&quot;
## [5] &quot;1;\r\n0;&quot;       &quot;1;\r\n0;\r\n&quot;   &quot;1;&quot;             &quot;0;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-556fddde08a6f3812acb" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-556fddde08a6f3812acb">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104540, 104456, 104455, 104556, 104471, 104476, 104519, 104549, 104548, 104459, 104500, 104531, 104521, 104487, 104496, 104525, 104454, 105804, 104515, 104508, 104472, 104490, 104453, 104513, 104499, 104518, 104514, 104554, 104481, 105805, 104460, 104475, 104526, 104539, 104527, 104466, 104532, 104552, 104452, 104463, 104512, 104507, 104536, 104469, 105806, 104457, 104529, 104464, 105802, 104516, 105801, 104530, 104501, 104524, 104449, 104458, 104553, 105807, 105809, 105817, 105800, 105821, 105818, 105827, 105812, 104563, 104564, 104468, 104535, 104560, 104574, 104542, 104461, 104557, 105815, 104498, 105822, 105808, 105803, 105814, 104485, 104465, 104565, 104474, 104586, 104566, 104582, 104486, 104497, 104510, 104489, 104573, 104528, 105824, 104551, 104544, 104547, 104550, 104545, 104546, 104570, 105819, 104583, 105811, 104450, 105813, 104559, 104555, 104590, 104568, 104506, 104473, 104483, 104482, 105820, 104494, 104589, 104511, 104495, 104591, 105826, 104462, 104479, 104523, 104488, 104509, 104505, 104580, 104579, 104448, 104534, 104520, 104578, 104567, 104447, 104502, 104562, 104581, 104584, 104533, 104541, 105810, 104467, 104451, 104470, 104575, 104561, 104484, 105816, 104480, 105823, 105825, 104478, 104594, 104662, 104652, 104666, 104632, 104626, 104656, 104659, 104660, 105830, 104614, 104658, 104588, 104664, 104629, 104657, 104634, 104599, 104616, 104623, 104621, 104617, 104684, 104696, 104697, 104619, 104612, 104503, 105834, 104655, 105833, 104640, 104643, 104654, 104602, 105829, 104645, 104680, 104685, 104681, 104688, 104665, 104597, 104669, 104610, 104618, 105832, 104624, 104595, 104538, 104648, 104558, 104672, 104679, 104638, 104631, 104635, 104604, 104639, 104522, 104517, 104667, 104698, 104701, 104593, 105831, 104689, 104663, 104682, 104686, 104630, 104611, 104644, 104646, 104615, 104605, 104606, 104622, 104683, 104647, 104608, 105828, 104677, 104537, 104661, 104642, 104598, 104600, 104596, 104637, 104543, 104504, 104620, 104668, 104651, 104609, 104607, 104673, 104650, 104592, 104633, 104641, 104636, 104649, 104709, 104714, 104711, 104699, 104613, 105838, 104708, 104704, 104713, 104712, 104710, 104717, 104722, 104724, 104725, 104723, 104720, 104734, 104675, 104676, 104768, 104775, 104718, 104719, 104754, 104743, 104742, 104735, 104761, 104674, 104703, 104738, 104736, 104744, 104769, 104765, 104758, 104762, 104766, 104771, 104627, 104702, 104781, 104628, 104727, 104721, 104728, 104700, 104726, 104715, 104706, 104752, 104746, 104730, 104747, 104690, 104774, 104778, 104695, 104748, 104770, 104731, 104729, 104751, 104776, 104764, 104777, 104763, 104783, 104625, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-36" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>MOCA_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="number_span_rc" class="section level2">
<h2>NUMBER_SPAN_RC</h2>
<pre class="r"><code>df &lt;- NUMBER_SPAN_RC

info(NUMBER_SPAN_RC,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:527, cols:85, inds:522</code></pre>
<pre class="r"><code>## extract all the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;logical&quot;
## 
## [[4]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot;</code></pre>
<pre class="r"><code>str(df, max.level = 99, list.len = 99999)</code></pre>
<details>
<summary>
Click for details
</summary>
<pre><code>## &#39;data.frame&#39;:    527 obs. of  85 variables:
##  $ SYSXM                : num  8276493 8258843 8258873 8260113 8277623 ...
##  $ SYSIND               : num  11369703 11369813 11037673 11620563 11435853 ...
##  $ SYSGP                : num  7951913 7952013 7894423 8005633 7962813 ...
##  $ SYSGPSTUDY           : num  1397023 1397123 1309743 1452343 1407923 ...
##  $ SYSINDGP             : num  8138973 8139083 7793413 8389633 8205123 ...
##  $ CGI_ORDER            : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ GPS_ORDER            : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ STDCGI_ORDER         : num  11 11 11 11 11 11 11 11 11 11 ...
##  $ LSTUDY               : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ DB_OWNER             : chr  &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; &quot;CLINIC_USER&quot; ...
##  $ STUDY                : chr  &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; &quot;ALZ&quot; ...
##  $ SUBSTUDY             : chr  &quot;ADCRLPRADI&quot; &quot;ADCRLPRADI&quot; &quot;ADFAMPRADI&quot; &quot;ADCONTROL&quot; ...
##  $ CENTER               : chr  &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; &quot;IHG&quot; ...
##  $ GP                   : num  88299 88301 87650 104477 88452 ...
##  $ IND                  : num  1 1 9000 1 1 1 105 1 1 1 ...
##  $ REFCTR               : logi  NA NA NA NA NA NA ...
##  $ EXAM_DATE            : POSIXct, format: &quot;2024-02-13&quot; &quot;2024-02-13&quot; ...
##  $ EXAMINER             : chr  &quot;gsv32&quot; &quot;jjs2031&quot; &quot;gsv32&quot; &quot;jjs2031&quot; ...
##  $ DATE_OF_BIRTH        : POSIXct, format: &quot;1944-09-22&quot; &quot;1947-05-13&quot; ...
##  $ AGE_AT_EXAM          : num  79 76 68 73 81 86 71 73 81 79 ...
##  $ REVIEW_DATE          : logi  NA NA NA NA NA NA ...
##  $ REVIEWER             : logi  NA NA NA NA NA NA ...
##  $ SPF3_R1              : chr  &quot;184&quot; NA NA &quot;184&quot; ...
##  $ SPF3_1               : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ SPF3_R2              : chr  &quot;279&quot; NA NA &quot;279&quot; ...
##  $ SPF3_2               : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ SPF4_R1              : chr  &quot;4162&quot; NA NA &quot;4162&quot; ...
##  $ SPF4_1               : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ SPF4_R2              : chr  &quot;8195&quot; NA NA &quot;8195&quot; ...
##  $ SPF4_2               : num  1 1 1 1 0 1 0 1 1 1 ...
##  $ SPF5_R1              : chr  &quot;64928&quot; NA NA &quot;64928&quot; ...
##  $ SPF5_1               : num  1 1 1 1 0 1 0 0 1 0 ...
##  $ SPF5_R2              : chr  &quot;73861&quot; NA NA &quot;73861&quot; ...
##  $ SPF5_2               : num  1 1 1 1 0 1 0 1 0 1 ...
##  $ SPF6_R1              : chr  &quot;392475&quot; &quot;39245&quot; NA &quot;392475&quot; ...
##  $ SPF6_1               : num  1 0 1 1 NA 0 NA 0 0 0 ...
##  $ SPF6_R2              : chr  &quot;628319&quot; &quot;628399&quot; NA &quot;628319&quot; ...
##  $ SPF6_2               : num  1 0 1 1 NA 0 NA 0 0 0 ...
##  $ SPF7_R1              : chr  &quot;9687156&quot; NA NA &quot;9647153&quot; ...
##  $ SPF7_1               : num  0 NA 0 1 NA NA NA NA NA NA ...
##  $ SPF7_R2              : chr  &quot;749281&quot; NA NA &quot;7492681&quot; ...
##  $ SPF7_2               : num  0 NA 0 1 NA NA NA NA NA NA ...
##  $ SPF8_R1              : chr  NA NA NA &quot;47528169&quot; ...
##  $ SPF8_1               : num  NA NA NA 0 NA NA NA NA NA NA ...
##  $ SPF8_R2              : chr  NA NA NA &quot;29753618&quot; ...
##  $ SPF8_2               : num  NA NA NA 0 NA NA NA NA NA NA ...
##  $ SPF9_R1              : chr  NA NA NA NA ...
##  $ SPF9_1               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPF9_R2              : chr  NA NA NA NA ...
##  $ SPF9_2               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPF_LONGEST          : num  6 5 6 10 4 5 4 4 5 4 ...
##  $ SPB2_R1              : chr  &quot;52&quot; NA NA &quot;52&quot; ...
##  $ SPB2_1               : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ SPB2_R2              : chr  &quot;74&quot; NA NA &quot;74&quot; ...
##  $ SPB2_2               : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ SPB3_R1              : chr  &quot;926&quot; NA NA &quot;692&quot; ...
##  $ SPB3_1               : num  0 1 1 1 0 1 0 1 0 0 ...
##  $ SPB3_R2              : chr  &quot;473&quot; NA NA &quot;473&quot; ...
##  $ SPB3_2               : num  1 1 1 1 1 1 0 0 0 0 ...
##  $ SPB4_R1              : chr  &quot;6761&quot; NA NA &quot;68176&quot; ...
##  $ SPB4_1               : num  0 1 0 0 0 0 NA 0 NA NA ...
##  $ SPB4_R2              : chr  &quot;1536&quot; &quot;351&quot; NA &quot;6315&quot; ...
##  $ SPB4_2               : num  0 0 0 0 0 0 NA 0 NA NA ...
##  $ SPB5_R1              : chr  NA &quot;9162&quot; NA NA ...
##  $ SPB5_1               : num  NA 0 NA NA NA NA NA NA NA NA ...
##  $ SPB5_R2              : chr  NA &quot;61927&quot; NA NA ...
##  $ SPB5_2               : num  NA 0 NA NA NA NA NA NA NA NA ...
##  $ SPB6_R1              : chr  NA NA NA NA ...
##  $ SPB6_1               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPB6_R2              : chr  NA NA NA NA ...
##  $ SPB6_2               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPB7_R1              : chr  NA NA NA NA ...
##  $ SPB7_1               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPB7_R2              : chr  NA NA NA NA ...
##  $ SPB7_2               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPB8_R1              : chr  NA NA NA NA ...
##  $ SPB8_1               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPB8_R2              : chr  NA NA NA NA ...
##  $ SPB8_2               : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SPB_LONGEST          : num  3 4 3 4 3 3 2 3 2 2 ...
##  $ COMMENTS_SPF_SPB     : chr  NA NA NA NA ...
##  $ SPF_TOTALSCORE       : num  8 6 8 10 3 6 3 5 5 5 ...
##  $ SPF_TOTALSCORE_STATUS: chr  &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; ...
##  $ SPB_TOTALSCORE       : num  3 5 4 4 3 4 2 3 2 2 ...
##  $ SPB_TOTALSCORE_STATUS: chr  &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; &quot;partial&quot; ...</code></pre>
</details>
<p><br></p>
<div id="pull-the-regenerated-dd-37" class="section level3">
<h3>Pull the regenerated DD</h3>
<pre class="r"><code>dfDD &lt;- read_excel(revisedDDpath, sheet = &quot;NUMBER_SPAN_RC&quot;)</code></pre>
<p><br></p>
</div>
<div id="handling-logical-variables-37" class="section level3">
<h3>Handling Logical Variables</h3>
<pre class="r"><code>## extract all logical variables
logicols &lt;- colnames(df)[sapply(df, is.logical)]

## view those variables in the regeneraed DD
dfDD[dfDD$VarNames %in% logicols,c(&quot;VarNames&quot;,&quot;Data Type&quot;)]</code></pre>
<pre><code>## # A tibble: 3 × 2
##   VarNames    `Data Type`
##   &lt;chr&gt;       &lt;chr&gt;      
## 1 REFCTR      VARCHAR2(6)
## 2 REVIEW_DATE date       
## 3 REVIEWER    CHAR</code></pre>
<pre class="r"><code>## select the vars to be converted to date
convert2date &lt;-  dfDD$VarNames[dfDD$VarNames %in% logicols &amp; grepl(&quot;date&quot;,dfDD$`Data Type`,ignore.case = T)] ## REVIEW_DATE

## the rest should be converted to character
convert2chr &lt;- setdiff(logicols,c(convert2num,convert2date)) ## [1] &quot;REFCTR&quot;   &quot;REVIEWER&quot;

## convert
df[convert2date] &lt;- lapply(df[convert2date], as.Date)
df[convert2chr] &lt;- lapply(df[convert2chr], as.character)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [[1]]
## [1] &quot;numeric&quot;
## 
## [[2]]
## [1] &quot;character&quot;
## 
## [[3]]
## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 
## 
## [[4]]
## [1] &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-date-variables-37" class="section level3">
<h3>Handling Date Variables</h3>
<pre class="r"><code>## extract date variables from sub-dataset
datecols &lt;- colnames(df)[sapply(df, function(x) inherits(x, c(&quot;POSIXct&quot;, &quot;POSIXt&quot;)))]
## [1] &quot;EXAM_DATE&quot;     &quot;DATE_OF_BIRTH&quot;

## extract date variables from regenerated DD
datecolsFromDD &lt;- dfDD$VarNames[dfDD$`Data Type` %in% c(&quot;DATE&quot;,&quot;date&quot;)]

## compare the two to see if we missing any date variables
setdiff(datecols,datecolsFromDD) ## character(0)</code></pre>
<pre><code>## character(0)</code></pre>
<pre class="r"><code>setdiff(datecolsFromDD,datecols) ## [1] &quot;REVIEW_DATE&quot; can ignore REVIEW_DATE, as it has been corrected in previous step</code></pre>
<pre><code>## [1] &quot;REVIEW_DATE&quot;</code></pre>
<pre class="r"><code>head(df[,datecols])</code></pre>
<pre><code>##    EXAM_DATE DATE_OF_BIRTH
## 1 2024-02-13    1944-09-22
## 2 2024-02-13    1947-05-13
## 3 2023-10-24    1954-10-29
## 4 2023-05-15    1949-12-01
## 5 2024-02-15    1942-09-30
## 6 2023-05-09    1936-05-22</code></pre>
<pre class="r"><code>## convert format
df[datecols] &lt;- lapply(df[datecols], as.Date)

## recheck the unique data types
unique(sapply(df, class))</code></pre>
<pre><code>## [1] &quot;numeric&quot;   &quot;character&quot; &quot;Date&quot;</code></pre>
<p><br></p>
</div>
<div id="handling-character-variables-37" class="section level3">
<h3>Handling Character Variables</h3>
<pre class="r"><code>## extract characteristic variables from sub-dataset
chrcols &lt;- colnames(df)[sapply(df, is.character)] ## 39 vars

## check data type inconsistency:
## mismatchChrs_1: present as chr in data but others in the DD
## mismatchChrs_2: present as chr in DD but others in the data
chrColsfromDD &lt;- dfDD[grepl(&quot;^(varchar|char)&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Data Type&quot;)]

mismatchChrs_1 &lt;- setdiff(chrcols,chrColsfromDD$VarNames) ## character(0)
mismatchChrs_2 &lt;- setdiff(chrColsfromDD$VarNames,chrcols) ## character(0)

## extract characteristic variables with value specification
tmp &lt;- dfDD[grepl(&quot;CHAR|VARCHAR&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

## check if the unique values for the chr columns in the dataset matching with the DD
DT::datatable(check_valid_responses(tmp,df))</code></pre>
<pre><code>## All values are within valid ranges.</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-1eda166cf1f157b4f572" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1eda166cf1f157b4f572">{"x":null,"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="handling-numeric-variables-37" class="section level3">
<h3>Handling Numeric Variables</h3>
<pre class="r"><code>## extract numeric variables from sub-dataset
numcols &lt;- colnames(df)[sapply(df, is.numeric)] ## 43 vars

## extract numeric variables from DD

## check data type inconsistency:
## mismatchNums_1: present as numeric in data but others in the DD
## mismatchNums_2: present as numeric in DD but others in the data
numColsfromDD &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

mismatchNums_1 &lt;- setdiff(numcols,numColsfromDD$VarNames) ## character(0)
mismatchNums_2 &lt;- setdiff(numColsfromDD$VarNames,numcols) ## character(0)

unique(numColsfromDD$`Valid Responses`)</code></pre>
<pre><code>## [1] NA              &quot;1 thru 99999;&quot; &quot;1 thru 9999;&quot;  &quot;1;\r\n0;&quot;</code></pre>
<pre class="r"><code>tmp &lt;- dfDD[grepl(&quot;number&quot;, dfDD$`Data Type`, ignore.case = TRUE) &amp; !is.na(dfDD$`Valid Responses`),c(&quot;VarNames&quot;,&quot;Valid Responses&quot;)]

DT::datatable(check_valid_numeric_responses(tmp,df))</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-d1b1e0cb1040e676cc93" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-d1b1e0cb1040e676cc93">{"x":{"filter":"none","vertical":false,"data":[["GP"],["GP"],["104477, 104528, 104456, 104455, 104556, 104471, 104511, 104519, 104549, 104548, 104452, 104459, 104531, 104530, 104497, 104454, 104472, 105806, 104469, 104521, 104496, 104487, 104500, 104525, 105804, 104490, 104515, 104453, 104513, 104499, 104518, 104536, 104514, 104554, 104481, 105805, 104508, 104475, 104526, 104539, 104527, 104532, 104552, 104512, 104516, 104507, 104457, 104529, 104464, 104476, 104466, 105801, 104501, 104489, 104553, 105809, 104551, 104571, 105817, 105800, 105821, 104589, 104565, 104564, 104563, 104535, 104542, 104541, 104557, 104403, 105815, 104473, 105808, 105803, 104540, 104474, 104586, 104566, 104582, 104574, 104447, 104569, 104506, 104573, 105824, 104468, 104570, 105819, 104524, 105807, 104583, 104450, 105813, 104546, 104568, 104585, 104478, 104482, 105818, 105816, 104494, 104560, 104484, 105827, 104572, 104495, 105826, 104462, 104479, 105811, 104523, 104509, 104465, 104488, 104505, 105822, 104485, 104580, 104579, 105814, 104534, 104561, 104578, 104567, 104448, 104502, 104562, 104581, 104584, 104533, 105810, 104467, 104451, 104555, 104498, 104510, 104547, 104449, 104470, 104575, 104480, 104483, 105823, 105825, 104636, 104594, 104662, 104664, 104616, 104599, 104652, 104666, 104632, 104656, 104614, 104588, 104651, 104657, 104658, 104634, 104610, 104623, 104621, 104617, 104684, 104679, 104696, 104697, 105833, 104619, 104612, 105834, 104667, 104655, 104643, 104644, 104654, 104602, 104645, 104680, 104685, 104503, 104688, 104665, 104597, 104681, 104669, 105830, 104618, 105829, 105832, 104504, 104537, 104648, 104624, 104672, 104638, 104635, 104522, 104517, 104558, 104677, 104604, 104699, 104698, 104593, 105831, 104689, 104682, 104686, 104611, 104646, 104605, 104606, 104622, 104647, 104608, 105828, 104631, 104639, 104661, 104629, 104642, 104598, 104600, 104637, 104538, 104620, 104668, 104609, 104607, 104596, 104650, 104592, 104683, 104649, 104714, 104613, 105838, 104705, 104708, 104712, 104710, 104722, 104723, 104676, 104781, 104775, 104754, 104743, 104742, 104735, 104761, 104674, 104709, 104737, 104736, 104744, 104703, 104765, 104752, 104751, 104758, 104766, 104771, 104702, 104727, 104721, 104695, 104783, 104700, 104728, 104706, 104746, 104730, 104747, 104690, 104774, 104778, 104748, 104718, 104719, 104731, 104768, 104764, 104776, 104777, 104675, 104603"],["1 - 99999"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>VarName<\/th>\n      <th>Invalid_Values<\/th>\n      <th>Accepted_values<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"VarName","targets":1},{"name":"Invalid_Values","targets":2},{"name":"Accepted_values","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## ignore GP</code></pre>
<p><br></p>
</div>
<div id="save-cleaned-data-37" class="section level3">
<h3>Save Cleaned Data</h3>
<pre class="r"><code>NUMBER_SPAN_RC &lt;- df</code></pre>
<p><br> <br></p>
</div>
</div>
</div>
<div id="duplicates-check" class="section level1">
<h1>Duplicates Check</h1>
<div id="duplicates-detection" class="section level2">
<h2>Duplicates Detection</h2>
<pre class="r"><code># Get names of all data frames in the environment
longDfwithDuplicates &lt;- c()
otherwithDuplicates &lt;- c()
index = 0

## following function will do:
## 1. filter out the okay cross-sectional datasets
## 2. for the rest: return the longitudinal/cross-sectional dataset names if duplicates got detected
for (df_name in df_names) {
  df &lt;- get(df_name)
  
  ## filter out the okay cross-sectional datasets
  if (length(unique(df[[&quot;SYSIND&quot;]])) == nrow(df)) {
    index = index + 1
    cat(index,
        &quot;No duplicates found in cross-sectional dataset: &quot;,
        df_name,
        &quot;\n&quot;)
  } else{
    ## Check if columns ID and Visit exist (longitduinal data or not)
    if (all(c(&quot;SYSIND&quot;, &quot;EXAM_DATE&quot;) %in% colnames(df))) {
      # Find duplicates using dplyr
      dup_rows &lt;- df %&gt;%
        dplyr::group_by(SYSIND, EXAM_DATE) %&gt;%
        dplyr::filter(n() &gt; 1) %&gt;%
        dplyr::ungroup()
      
      # If any duplicates found, assign to new data frame with _Duplicates
      if (nrow(dup_rows) &gt; 0) {
        longDfwithDuplicates &lt;- c(longDfwithDuplicates, df_name)
      } else {
        index = index + 1
        cat(index,
            &quot;No duplicates found in longitudinal dataset: &quot;,
            df_name,
            &quot;\n&quot;)
      }
    } else {
      otherwithDuplicates &lt;- c(otherwithDuplicates, df_name)
    }
  }
}</code></pre>
<pre><code>## 1 No duplicates found in longitudinal dataset:  AAAD_GERIAT 
## 2 No duplicates found in longitudinal dataset:  AAAD_MEDCON 
## 3 No duplicates found in longitudinal dataset:  AAAD_SOCIO_DEMO 
## 4 No duplicates found in longitudinal dataset:  AAAD_TRAILS 
## 5 No duplicates found in longitudinal dataset:  ALZ_B9_JUDGE_RC 
## 6 No duplicates found in longitudinal dataset:  ALZ_CSDD 
## 7 No duplicates found in cross-sectional dataset:  ALZ_GAI_SP 
## 8 No duplicates found in longitudinal dataset:  ALZ_NEURO_CDR 
## 9 No duplicates found in cross-sectional dataset:  ALZ_RPFQ 
## 10 No duplicates found in longitudinal dataset:  ALZ_SCREENING_RC 
## 11 No duplicates found in longitudinal dataset:  ALZ_STICK_D_RC 
## 12 No duplicates found in longitudinal dataset:  B4_CDR_RC 
## 13 No duplicates found in longitudinal dataset:  B5_NPIQ_RC 
## 14 No duplicates found in longitudinal dataset:  B6_GDS_RC 
## 15 No duplicates found in longitudinal dataset:  B7_FAS_RC 
## 16 No duplicates found in cross-sectional dataset:  BCF_RECOG_RC 
## 17 No duplicates found in cross-sectional dataset:  BCFCD_RC 
## 18 No duplicates found in cross-sectional dataset:  BCFCI_RC 
## 19 No duplicates found in cross-sectional dataset:  BILINGUAL_SCALE_RC 
## 20 No duplicates found in longitudinal dataset:  CAT_FLUENCY_RC 
## 21 No duplicates found in cross-sectional dataset:  CERAD_DEL_RC 
## 22 No duplicates found in cross-sectional dataset:  CERAD_IMM_RC 
## 23 No duplicates found in cross-sectional dataset:  CERAD_RECOG_RC 
## 24 No duplicates found in longitudinal dataset:  CRAFT_21_DEL_RC 
## 25 No duplicates found in longitudinal dataset:  CRAFT_21_IMM_RC 
## 26 No duplicates found in longitudinal dataset:  MEDCON_RC 
## 27 No duplicates found in longitudinal dataset:  MEDICAL_HIST 
## 28 No duplicates found in cross-sectional dataset:  MINT_RC 
## 29 No duplicates found in longitudinal dataset:  MINT_SP_RC 
## 30 No duplicates found in longitudinal dataset:  MOCA_RC 
## 31 No duplicates found in longitudinal dataset:  NUMBER_SPAN_RC</code></pre>
<p><br></p>
<pre class="r"><code>## longidtudinal datatset with duplicate
longDfwithDuplicates</code></pre>
<pre><code>## [1] &quot;ALZ_NPIQ_CBRS&quot;</code></pre>
<pre class="r"><code>## otherwithDuplicates
## the following variables do not have EXAM_DATE but have other time variables
## so I will check duplicates one by one for them based on their unique time variables
otherwithDuplicates</code></pre>
<pre><code>## [1] &quot;ALZ_CLINICALSUM&quot; &quot;ALZ_EXAM&quot;        &quot;ALZ_LOAD_COG&quot;    &quot;ALZ_NCRAD&quot;      
## [5] &quot;ALZ_SCREENING&quot;   &quot;CONSENSUS_DX&quot;</code></pre>
<pre class="r"><code>## check duplicates for ALZ_CLINICALSUM
ALZ_CLINICALSUM %&gt;%
  dplyr::group_by(SYSIND, FORM_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup() %&gt;%
  nrow() %&gt;% print() ## 0 row</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>## check duplicates for ALZ_EXAM
ALZ_EXAM %&gt;%
  dplyr::group_by(SYSIND, FORM_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup() %&gt;%
  nrow() %&gt;% print() ## 0 row</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>## check duplicates for ALZ_LOAD_COG
ALZ_LOAD_COG %&gt;%
  dplyr::group_by(SYSIND, INTERVIEW_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup() %&gt;%
  nrow() %&gt;% print() ## 0 row</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>## check duplicates for ALZ_NCRAD
ALZ_NCRAD %&gt;%
  dplyr::group_by(SYSIND, FORM_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup() %&gt;%
  nrow() %&gt;% print() ## 2 rows</code></pre>
<pre><code>## [1] 2</code></pre>
<pre class="r"><code>## ALZ_SCREENING
ALZ_SCREENING %&gt;%
  dplyr::group_by(SYSIND, FORM_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup() %&gt;%
  nrow() %&gt;% print() ## 0 row</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>## CONSENSUS_DX
CONSENSUS_DX %&gt;%
  dplyr::group_by(SYSIND, DATE_DX) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup() %&gt;%
  nrow() %&gt;% print() ## 211 rows</code></pre>
<pre><code>## [1] 211</code></pre>
<p><br> <br></p>
</div>
<div id="duplicates-handling-per-dataset" class="section level2">
<h2>Duplicates Handling Per Dataset</h2>
<div id="alz_npiq_cbrs-1" class="section level3">
<h3>ALZ_NPIQ_CBRS</h3>
<pre class="r"><code>cat(&quot;Before duplicates handling - SYSIND*EXAM_DATE is: &quot;,dupFixCheck(ALZ_NPIQ_CBRS,&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;),&quot;\n&quot;)</code></pre>
<pre><code>## Before duplicates handling - SYSIND*EXAM_DATE is:  122</code></pre>
<pre class="r"><code>info(ALZ_NPIQ_CBRS,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:123, cols:116, inds:121</code></pre>
<pre class="r"><code>## view the duplicates
ALZ_NPIQ_CBRS %&gt;%
  dplyr::group_by(SYSIND, EXAM_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup()</code></pre>
<pre><code>## # A tibble: 2 × 116
##     SYSXM   SYSIND   SYSGP SYSGPSTUDY SYSINDGP CGI_ORDER GPS_ORDER STDCGI_ORDER
##     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;
## 1 7540713 11048883 7896183    1311503  7804743         1         1           11
## 2 7540723 11048883 7896183    1311503  7804743         1         1           11
## # ℹ 108 more variables: LSTUDY &lt;chr&gt;, DB_OWNER &lt;chr&gt;, STUDY &lt;chr&gt;,
## #   SUBSTUDY &lt;chr&gt;, CENTER &lt;chr&gt;, GP &lt;dbl&gt;, IND &lt;dbl&gt;, REFCTR &lt;chr&gt;,
## #   EXAM_DATE &lt;date&gt;, EXAMINER &lt;chr&gt;, DATE_OF_BIRTH &lt;date&gt;, AGE_AT_EXAM &lt;dbl&gt;,
## #   NPIQINF &lt;chr&gt;, NPIQINF_PRO &lt;chr&gt;, NPIQINF_OTH &lt;chr&gt;, NPIQINFA &lt;dbl&gt;,
## #   NPIQINFB &lt;dbl&gt;, NPIQTYPE &lt;dbl&gt;, AGIT &lt;dbl&gt;, AGITSEV &lt;dbl&gt;,
## #   AGITATION_DIST &lt;dbl&gt;, DEPD &lt;dbl&gt;, DEPDSEV &lt;dbl&gt;, DEPRESS_DIST &lt;dbl&gt;,
## #   ANX &lt;dbl&gt;, ANXSEV &lt;dbl&gt;, ANXIETY_DIST &lt;dbl&gt;, ELAT &lt;dbl&gt;, ELATSEV &lt;dbl&gt;, …</code></pre>
<pre class="r"><code>## after checking the duplicates, I decided to keep the second obs as it has less missingness
ALZ_NPIQ_CBRS &lt;- ALZ_NPIQ_CBRS[ALZ_NPIQ_CBRS$SYSXM != &quot;7540713&quot;, ]</code></pre>
<pre class="r"><code>info(ALZ_NPIQ_CBRS,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:122, cols:116, inds:121</code></pre>
<pre class="r"><code>cat(&quot;After duplicates handling - SYSIND*EXAM_DATE is: &quot;,dupFixCheck(ALZ_NPIQ_CBRS,&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;),&quot;\n&quot;)</code></pre>
<pre><code>## After duplicates handling - SYSIND*EXAM_DATE is:  122</code></pre>
<p><br> <br></p>
</div>
<div id="alz_ncrad-1" class="section level3">
<h3>ALZ_NCRAD</h3>
<pre class="r"><code>cat(&quot;Before duplicates handling - SYSIND*FORM_DATE is: &quot;,dupFixCheck(ALZ_NCRAD,&quot;SYSIND&quot;,&quot;FORM_DATE&quot;),&quot;\n&quot;)</code></pre>
<pre><code>## Before duplicates handling - SYSIND*FORM_DATE is:  742</code></pre>
<pre class="r"><code>info(ALZ_NCRAD,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:743, cols:53, inds:742</code></pre>
<pre class="r"><code>## view the duplicates
ALZ_NCRAD %&gt;%
  dplyr::group_by(SYSIND, FORM_DATE) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup()</code></pre>
<pre><code>## # A tibble: 2 × 53
##     SYSXM   SYSIND   SYSGP SYSGPSTUDY SYSINDGP CGI_ORDER GPS_ORDER STDCGI_ORDER
##     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;
## 1 7906253 11009263 7889133    1304473  7764083         1         1           11
## 2 8388533 11009263 7889133    1304473  7764083         1         1           11
## # ℹ 45 more variables: LSTUDY &lt;chr&gt;, DB_OWNER &lt;chr&gt;, STUDY &lt;chr&gt;,
## #   SUBSTUDY &lt;chr&gt;, CENTER &lt;chr&gt;, GP &lt;dbl&gt;, IND &lt;dbl&gt;, REFCTR &lt;chr&gt;,
## #   QUALIFY &lt;chr&gt;, FORM_DATE &lt;date&gt;, FILLED_OUT_BY &lt;chr&gt;, DATE_OF_BIRTH &lt;date&gt;,
## #   IN_NCRAD &lt;chr&gt;, SAMPLED &lt;dbl&gt;, EDUC &lt;dbl&gt;, VISIT &lt;dbl&gt;, COMREQ &lt;dbl&gt;,
## #   NOTDEMCI &lt;dbl&gt;, EVALMETH &lt;dbl&gt;, EVALYR &lt;dbl&gt;, CLDEMLEW &lt;dbl&gt;,
## #   COMDXAD &lt;chr&gt;, NONADDEM &lt;dbl&gt;, COMDXNAD &lt;chr&gt;, AAOSYMP &lt;dbl&gt;,
## #   STROKETY &lt;dbl&gt;, STROKEAGE &lt;dbl&gt;, HYPERAGE &lt;dbl&gt;, HEARTAGE &lt;dbl&gt;, …</code></pre>
<pre class="r"><code>## the duplicates are exactly same, so we can randomly drop one, I will drop the first observation
ALZ_NCRAD &lt;- ALZ_NCRAD[ALZ_NCRAD$SYSXM != &quot;7906253&quot;, ]</code></pre>
<pre class="r"><code>info(ALZ_NCRAD,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:742, cols:53, inds:742</code></pre>
<pre class="r"><code>cat(&quot;After duplicates handling - SYSIND*FORM_DATE is: &quot;,dupFixCheck(ALZ_NCRAD,&quot;SYSIND&quot;,&quot;FORM_DATE&quot;),&quot;\n&quot;)</code></pre>
<pre><code>## After duplicates handling - SYSIND*FORM_DATE is:  742</code></pre>
<p><br> <br></p>
</div>
<div id="consensus_dx-1" class="section level3">
<h3>CONSENSUS_DX</h3>
<pre class="r"><code>cat(&quot;Before duplicates handling - SYSIND*DATE_DX is: &quot;,dupFixCheck(CONSENSUS_DX,&quot;SYSIND&quot;,&quot;DATE_DX&quot;),&quot;\n&quot;)</code></pre>
<pre><code>## Before duplicates handling - SYSIND*DATE_DX is:  1700</code></pre>
<pre class="r"><code>info(CONSENSUS_DX,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1807, cols:43, inds:1584</code></pre>
<pre class="r"><code>## view the duplicates
dups_CONSENSUS_DX &lt;- CONSENSUS_DX %&gt;%
  dplyr::group_by(SYSIND, DATE_DX) %&gt;%
  dplyr::filter(n() &gt; 1) %&gt;%
  dplyr::ungroup()

info(dups_CONSENSUS_DX,&quot;SYSIND&quot;) </code></pre>
<pre><code>## #obs:211, cols:43, inds:104</code></pre>
<pre class="r"><code>## some individuals have multiple CDX, and the RANK variable records the number of visits
## so I decided to use pivot_wider function to keep all the CDX values
## remove duplicates

IDcols &lt;- c(names(CONSENSUS_DX)[1:16],&quot;DATE_OF_BIRTH&quot;,&quot;DATE_DX&quot;,names(CONSENSUS_DX)[27:43])
IDcols</code></pre>
<pre><code>##  [1] &quot;SYSXM&quot;             &quot;SYSIND&quot;            &quot;SYSGP&quot;            
##  [4] &quot;SYSGPSTUDY&quot;        &quot;SYSINDGP&quot;          &quot;CGI_ORDER&quot;        
##  [7] &quot;GPS_ORDER&quot;         &quot;STDCGI_ORDER&quot;      &quot;LSTUDY&quot;           
## [10] &quot;DB_OWNER&quot;          &quot;STUDY&quot;             &quot;SUBSTUDY&quot;         
## [13] &quot;CENTER&quot;            &quot;GP&quot;                &quot;IND&quot;              
## [16] &quot;REFCTR&quot;            &quot;DATE_OF_BIRTH&quot;     &quot;DATE_DX&quot;          
## [19] &quot;CLINICAL_COMMENTS&quot; &quot;OTHER_TXT1&quot;        &quot;OTHER_TXT2&quot;       
## [22] &quot;OTHER_TXT3&quot;        &quot;CALC_VAL1&quot;         &quot;CALC_VAL2&quot;        
## [25] &quot;CALC_VAL3&quot;         &quot;CALC_VAL4&quot;         &quot;CALC_VAL5&quot;        
## [28] &quot;CALC_VAL6&quot;         &quot;CALC_VAL7&quot;         &quot;CALC_VAL8&quot;        
## [31] &quot;CALC_VAL9&quot;         &quot;CALC_VAL10&quot;        &quot;CALC_VAL11&quot;       
## [34] &quot;LAST_SOURCE&quot;       &quot;OTHER_DATE1&quot;</code></pre>
<pre class="r"><code>CONSENSUS_DX &lt;- CONSENSUS_DX %&gt;%
  pivot_wider(
    id_cols = all_of(IDcols),
    names_from = RANK,
    values_from = c(REVIEW_DATE, REVIEWER, RANK:WHO_DX,COMMENTS),
    names_sep = &quot;_&quot;
  )</code></pre>
<pre class="r"><code>info(CONSENSUS_DX,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1701, cols:59, inds:1584</code></pre>
<pre class="r"><code>cat(&quot;After duplicates handling - SYSIND*DATE_DX is: &quot;,dupFixCheck(CONSENSUS_DX,&quot;SYSIND&quot;,&quot;DATE_DX&quot;),&quot;\n&quot;)</code></pre>
<pre><code>## After duplicates handling - SYSIND*DATE_DX is:  1700</code></pre>
<p><br> <br></p>
</div>
</div>
</div>
<div id="individuals-count" class="section level1">
<h1>Individuals Count</h1>
<div id="total-number-of-individuals" class="section level2">
<h2>Total Number of Individuals</h2>
<pre class="r"><code>## get total number of unique inviduals
all_ids &lt;- unlist(
  lapply(df_names, function(d) get(d)$SYSIND)
)

# Count unique SYSINDs
n_unique &lt;- length(unique(all_ids))

n_unique ## 1994 individuals</code></pre>
<pre><code>## [1] 1994</code></pre>
<p><br></p>
</div>
<div id="individuals-missingness-per-study" class="section level2">
<h2>Individuals Missingness Per Study</h2>
<pre class="r"><code>summary_df &lt;- do.call(rbind, lapply(df_names, function(d) {
  df &lt;- get(d)
  df_individuals &lt;- unique(df$SYSIND)
  
  data.frame(
    dataset   = d,
    n_individuals = length(df_individuals),
    n_obs         = nrow(df),
    n_individials_missing   = length(setdiff(all_ids, df_individuals)),
    stringsAsFactors = FALSE
  )
}))

DT::datatable(summary_df)</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-398c39c97a7b51941f06" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-398c39c97a7b51941f06">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38"],["AAAD_GERIAT","AAAD_MEDCON","AAAD_SOCIO_DEMO","AAAD_TRAILS","ALZ_B9_JUDGE_RC","ALZ_CLINICALSUM","ALZ_CSDD","ALZ_EXAM","ALZ_GAI_SP","ALZ_LOAD_COG","ALZ_NCRAD","ALZ_NEURO_CDR","ALZ_NPIQ_CBRS","ALZ_RPFQ","ALZ_SCREENING","ALZ_SCREENING_RC","ALZ_STICK_D_RC","B4_CDR_RC","B5_NPIQ_RC","B6_GDS_RC","B7_FAS_RC","BCF_RECOG_RC","BCFCD_RC","BCFCI_RC","BILINGUAL_SCALE_RC","CAT_FLUENCY_RC","CERAD_DEL_RC","CERAD_IMM_RC","CERAD_RECOG_RC","CONSENSUS_DX","CRAFT_21_DEL_RC","CRAFT_21_IMM_RC","MEDCON_RC","MEDICAL_HIST","MINT_RC","MINT_SP_RC","MOCA_RC","NUMBER_SPAN_RC"],[939,367,391,428,481,1480,176,522,19,907,742,1102,121,132,272,552,428,592,304,539,431,266,269,270,240,550,177,188,177,1584,519,525,618,871,3,301,580,522],[1051,397,402,439,483,1484,181,526,19,1006,742,1221,122,132,279,556,430,599,305,543,435,266,269,270,240,555,177,188,177,1701,523,530,627,889,3,303,585,527],[1055,1627,1603,1566,1513,514,1818,1472,1975,1087,1252,892,1873,1862,1722,1442,1566,1402,1690,1455,1563,1728,1725,1724,1754,1444,1817,1806,1817,410,1475,1469,1376,1123,1991,1693,1414,1472]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>dataset<\/th>\n      <th>n_individuals<\/th>\n      <th>n_obs<\/th>\n      <th>n_individials_missing<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,4]},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"dataset","targets":1},{"name":"n_individuals","targets":2},{"name":"n_obs","targets":3},{"name":"n_individials_missing","targets":4}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><br> <br></p>
</div>
</div>
<div id="merge-sub-datasets" class="section level1">
<h1>Merge Sub-Datasets</h1>
<div id="grouping-datasets" class="section level2">
<h2>Grouping Datasets</h2>
<pre class="r"><code>cross_dfs&lt;- c()
long_dfs_wEXAM_DATE &lt;- c()
long_dfs_woEXAM_DATE &lt;- c()

for (df_name in df_names) {
  df_obj &lt;- get(df_name)  # get the dataframe
  if (nrow(df_obj) == length(unique(df_obj[[&quot;SYSIND&quot;]]))) {
    cross_dfs &lt;- c(cross_dfs, df_name)
  } else if (&quot;EXAM_DATE&quot; %in% names(df_obj)) {
    long_dfs_wEXAM_DATE &lt;- c(long_dfs_wEXAM_DATE, df_name)
  } else{
    long_dfs_woEXAM_DATE &lt;- c(long_dfs_woEXAM_DATE,df_name)
  }
}

cross_dfs</code></pre>
<pre><code>##  [1] &quot;ALZ_GAI_SP&quot;         &quot;ALZ_NCRAD&quot;          &quot;ALZ_RPFQ&quot;          
##  [4] &quot;BCF_RECOG_RC&quot;       &quot;BCFCD_RC&quot;           &quot;BCFCI_RC&quot;          
##  [7] &quot;BILINGUAL_SCALE_RC&quot; &quot;CERAD_DEL_RC&quot;       &quot;CERAD_IMM_RC&quot;      
## [10] &quot;CERAD_RECOG_RC&quot;     &quot;MINT_RC&quot;</code></pre>
<pre class="r"><code>long_dfs_wEXAM_DATE</code></pre>
<pre><code>##  [1] &quot;AAAD_GERIAT&quot;      &quot;AAAD_MEDCON&quot;      &quot;AAAD_SOCIO_DEMO&quot;  &quot;AAAD_TRAILS&quot;     
##  [5] &quot;ALZ_B9_JUDGE_RC&quot;  &quot;ALZ_CSDD&quot;         &quot;ALZ_NEURO_CDR&quot;    &quot;ALZ_NPIQ_CBRS&quot;   
##  [9] &quot;ALZ_SCREENING_RC&quot; &quot;ALZ_STICK_D_RC&quot;   &quot;B4_CDR_RC&quot;        &quot;B5_NPIQ_RC&quot;      
## [13] &quot;B6_GDS_RC&quot;        &quot;B7_FAS_RC&quot;        &quot;CAT_FLUENCY_RC&quot;   &quot;CRAFT_21_DEL_RC&quot; 
## [17] &quot;CRAFT_21_IMM_RC&quot;  &quot;MEDCON_RC&quot;        &quot;MEDICAL_HIST&quot;     &quot;MINT_SP_RC&quot;      
## [21] &quot;MOCA_RC&quot;          &quot;NUMBER_SPAN_RC&quot;</code></pre>
<pre class="r"><code>long_dfs_woEXAM_DATE</code></pre>
<pre><code>## [1] &quot;ALZ_CLINICALSUM&quot; &quot;ALZ_EXAM&quot;        &quot;ALZ_LOAD_COG&quot;    &quot;ALZ_SCREENING&quot;  
## [5] &quot;CONSENSUS_DX&quot;</code></pre>
<pre class="r"><code>dfwEXAM_DATE &lt;- c()
dfwoEXAM_DATE &lt;- c()

for (df_name in df_names) {
  df_obj &lt;- get(df_name)  # get the dataframe
  
  if (&quot;EXAM_DATE&quot; %in% names(df_obj)) {
    dfwEXAM_DATE &lt;- c(dfwEXAM_DATE, df_name)
  } else{
    dfwoEXAM_DATE &lt;- c(dfwoEXAM_DATE,df_name)
  }
  
}

print(dfwEXAM_DATE)</code></pre>
<pre><code>##  [1] &quot;AAAD_GERIAT&quot;        &quot;AAAD_MEDCON&quot;        &quot;AAAD_SOCIO_DEMO&quot;   
##  [4] &quot;AAAD_TRAILS&quot;        &quot;ALZ_B9_JUDGE_RC&quot;    &quot;ALZ_CSDD&quot;          
##  [7] &quot;ALZ_GAI_SP&quot;         &quot;ALZ_NEURO_CDR&quot;      &quot;ALZ_NPIQ_CBRS&quot;     
## [10] &quot;ALZ_RPFQ&quot;           &quot;ALZ_SCREENING_RC&quot;   &quot;ALZ_STICK_D_RC&quot;    
## [13] &quot;B4_CDR_RC&quot;          &quot;B5_NPIQ_RC&quot;         &quot;B6_GDS_RC&quot;         
## [16] &quot;B7_FAS_RC&quot;          &quot;BCF_RECOG_RC&quot;       &quot;BCFCD_RC&quot;          
## [19] &quot;BCFCI_RC&quot;           &quot;BILINGUAL_SCALE_RC&quot; &quot;CAT_FLUENCY_RC&quot;    
## [22] &quot;CERAD_DEL_RC&quot;       &quot;CERAD_IMM_RC&quot;       &quot;CERAD_RECOG_RC&quot;    
## [25] &quot;CRAFT_21_DEL_RC&quot;    &quot;CRAFT_21_IMM_RC&quot;    &quot;MEDCON_RC&quot;         
## [28] &quot;MEDICAL_HIST&quot;       &quot;MINT_RC&quot;            &quot;MINT_SP_RC&quot;        
## [31] &quot;MOCA_RC&quot;            &quot;NUMBER_SPAN_RC&quot;</code></pre>
<pre class="r"><code>print(dfwoEXAM_DATE)</code></pre>
<pre><code>## [1] &quot;ALZ_CLINICALSUM&quot; &quot;ALZ_EXAM&quot;        &quot;ALZ_LOAD_COG&quot;    &quot;ALZ_NCRAD&quot;      
## [5] &quot;ALZ_SCREENING&quot;   &quot;CONSENSUS_DX&quot;</code></pre>
<p><br> <br></p>
</div>
<div id="age_at_exam-variable-explore" class="section level2">
<h2>AGE_AT_EXAM Variable Explore</h2>
<pre class="r"><code>## detect which dataset has AGE_AT_EXAM variable
index = 1

for (df_name in df_names) {
  df_obj &lt;- get(df_name, inherits = TRUE)
  nms &lt;- names(df_obj)

  has_age  &lt;- &quot;AGE_AT_EXAM&quot; %in% nms
  has_date &lt;- &quot;EXAM_DATE&quot;   %in% nms

  if (has_age &amp;&amp; has_date) {
    cat(index, &quot;:&quot;, df_name, &quot;: both EXAM_DATE and AGE_AT_EXAM present\n&quot;)
  } else if (has_age &amp;&amp; !has_date) {
    cat(index, &quot;:&quot;, df_name, &quot;: only AGE_AT_EXAM present\n&quot;)
  } else if (has_date &amp;&amp; !has_age) {
    cat(index, &quot;:&quot;, df_name, &quot;: only EXAM_DATE present\n&quot;)
  } else {
    cat(index, &quot;:&quot;, df_name, &quot;: ============ none of them present ============\n&quot;)
  }

  index &lt;- index + 1
}</code></pre>
<pre><code>## 1 : AAAD_GERIAT : both EXAM_DATE and AGE_AT_EXAM present
## 2 : AAAD_MEDCON : both EXAM_DATE and AGE_AT_EXAM present
## 3 : AAAD_SOCIO_DEMO : both EXAM_DATE and AGE_AT_EXAM present
## 4 : AAAD_TRAILS : both EXAM_DATE and AGE_AT_EXAM present
## 5 : ALZ_B9_JUDGE_RC : both EXAM_DATE and AGE_AT_EXAM present
## 6 : ALZ_CLINICALSUM : ============ none of them present ============
## 7 : ALZ_CSDD : both EXAM_DATE and AGE_AT_EXAM present
## 8 : ALZ_EXAM : ============ none of them present ============
## 9 : ALZ_GAI_SP : both EXAM_DATE and AGE_AT_EXAM present
## 10 : ALZ_LOAD_COG : ============ none of them present ============
## 11 : ALZ_NCRAD : ============ none of them present ============
## 12 : ALZ_NEURO_CDR : both EXAM_DATE and AGE_AT_EXAM present
## 13 : ALZ_NPIQ_CBRS : both EXAM_DATE and AGE_AT_EXAM present
## 14 : ALZ_RPFQ : both EXAM_DATE and AGE_AT_EXAM present
## 15 : ALZ_SCREENING : ============ none of them present ============
## 16 : ALZ_SCREENING_RC : both EXAM_DATE and AGE_AT_EXAM present
## 17 : ALZ_STICK_D_RC : both EXAM_DATE and AGE_AT_EXAM present
## 18 : B4_CDR_RC : both EXAM_DATE and AGE_AT_EXAM present
## 19 : B5_NPIQ_RC : both EXAM_DATE and AGE_AT_EXAM present
## 20 : B6_GDS_RC : both EXAM_DATE and AGE_AT_EXAM present
## 21 : B7_FAS_RC : both EXAM_DATE and AGE_AT_EXAM present
## 22 : BCF_RECOG_RC : both EXAM_DATE and AGE_AT_EXAM present
## 23 : BCFCD_RC : both EXAM_DATE and AGE_AT_EXAM present
## 24 : BCFCI_RC : both EXAM_DATE and AGE_AT_EXAM present
## 25 : BILINGUAL_SCALE_RC : both EXAM_DATE and AGE_AT_EXAM present
## 26 : CAT_FLUENCY_RC : both EXAM_DATE and AGE_AT_EXAM present
## 27 : CERAD_DEL_RC : both EXAM_DATE and AGE_AT_EXAM present
## 28 : CERAD_IMM_RC : both EXAM_DATE and AGE_AT_EXAM present
## 29 : CERAD_RECOG_RC : both EXAM_DATE and AGE_AT_EXAM present
## 30 : CONSENSUS_DX : ============ none of them present ============
## 31 : CRAFT_21_DEL_RC : both EXAM_DATE and AGE_AT_EXAM present
## 32 : CRAFT_21_IMM_RC : both EXAM_DATE and AGE_AT_EXAM present
## 33 : MEDCON_RC : both EXAM_DATE and AGE_AT_EXAM present
## 34 : MEDICAL_HIST : both EXAM_DATE and AGE_AT_EXAM present
## 35 : MINT_RC : both EXAM_DATE and AGE_AT_EXAM present
## 36 : MINT_SP_RC : both EXAM_DATE and AGE_AT_EXAM present
## 37 : MOCA_RC : both EXAM_DATE and AGE_AT_EXAM present
## 38 : NUMBER_SPAN_RC : both EXAM_DATE and AGE_AT_EXAM present</code></pre>
<pre class="r"><code>## findings: AGE_AT_EXAM and EXAM_DATE variables are paired. If one presents, the other also presents.</code></pre>
<pre class="r"><code>## group by SYSIND and AGE_AT_EXAM then check duplicates
index = 1
for (df_name in df_names) {
  df_obj &lt;- get(df_name)  # get the dataframe
  if (&quot;AGE_AT_EXAM&quot; %in% names(df_obj)) {
    cat(index, &quot; :&quot;, df_name, &quot; : AGE_AT_EXAM present&quot;, &quot;\n&quot;)
    
    dup_rows_AGE_AT_EXAM &lt;- df_obj %&gt;%
      dplyr::group_by(SYSIND, AGE_AT_EXAM) %&gt;%
      dplyr::filter(n() &gt; 1) %&gt;%
      dplyr::ungroup()
    
    dup_rows_EXAM_DATE &lt;- df_obj %&gt;%
      dplyr::group_by(SYSIND, EXAM_DATE) %&gt;%
      dplyr::filter(n() &gt; 1) %&gt;%
      dplyr::ungroup()
    
    if (nrow(dup_rows_AGE_AT_EXAM) &gt; 0) {
      cat(index,
          &quot; :&quot;,
          df_name,
          &quot; : !!!duplicates present (checking by AGE_AT_EXAM )!!!&quot;,
          &quot;\n&quot;)
    } else if (nrow(dup_rows_EXAM_DATE) &gt; 0) {
      cat(index,
          &quot; :&quot;,
          df_name,
          &quot; : !!!duplicates present (checking by EXAM_DATE )!!!&quot;,
          &quot;\n&quot;)
    } else{
      cat(index, &quot; :&quot;, df_name, &quot; : no duplicates found:)&quot;, &quot;\n&quot;)
    }
    
  } else{
    cat(index, &quot; :&quot;, df_name, &quot;===============================================&quot;,&quot;\n&quot;)
  }
  index = index + 1
}</code></pre>
<pre><code>## 1  : AAAD_GERIAT  : AGE_AT_EXAM present 
## 1  : AAAD_GERIAT  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 2  : AAAD_MEDCON  : AGE_AT_EXAM present 
## 2  : AAAD_MEDCON  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 3  : AAAD_SOCIO_DEMO  : AGE_AT_EXAM present 
## 3  : AAAD_SOCIO_DEMO  : no duplicates found:) 
## 4  : AAAD_TRAILS  : AGE_AT_EXAM present 
## 4  : AAAD_TRAILS  : no duplicates found:) 
## 5  : ALZ_B9_JUDGE_RC  : AGE_AT_EXAM present 
## 5  : ALZ_B9_JUDGE_RC  : no duplicates found:) 
## 6  : ALZ_CLINICALSUM =============================================== 
## 7  : ALZ_CSDD  : AGE_AT_EXAM present 
## 7  : ALZ_CSDD  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 8  : ALZ_EXAM =============================================== 
## 9  : ALZ_GAI_SP  : AGE_AT_EXAM present 
## 9  : ALZ_GAI_SP  : no duplicates found:) 
## 10  : ALZ_LOAD_COG =============================================== 
## 11  : ALZ_NCRAD =============================================== 
## 12  : ALZ_NEURO_CDR  : AGE_AT_EXAM present 
## 12  : ALZ_NEURO_CDR  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 13  : ALZ_NPIQ_CBRS  : AGE_AT_EXAM present 
## 13  : ALZ_NPIQ_CBRS  : no duplicates found:) 
## 14  : ALZ_RPFQ  : AGE_AT_EXAM present 
## 14  : ALZ_RPFQ  : no duplicates found:) 
## 15  : ALZ_SCREENING =============================================== 
## 16  : ALZ_SCREENING_RC  : AGE_AT_EXAM present 
## 16  : ALZ_SCREENING_RC  : no duplicates found:) 
## 17  : ALZ_STICK_D_RC  : AGE_AT_EXAM present 
## 17  : ALZ_STICK_D_RC  : no duplicates found:) 
## 18  : B4_CDR_RC  : AGE_AT_EXAM present 
## 18  : B4_CDR_RC  : no duplicates found:) 
## 19  : B5_NPIQ_RC  : AGE_AT_EXAM present 
## 19  : B5_NPIQ_RC  : no duplicates found:) 
## 20  : B6_GDS_RC  : AGE_AT_EXAM present 
## 20  : B6_GDS_RC  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 21  : B7_FAS_RC  : AGE_AT_EXAM present 
## 21  : B7_FAS_RC  : no duplicates found:) 
## 22  : BCF_RECOG_RC  : AGE_AT_EXAM present 
## 22  : BCF_RECOG_RC  : no duplicates found:) 
## 23  : BCFCD_RC  : AGE_AT_EXAM present 
## 23  : BCFCD_RC  : no duplicates found:) 
## 24  : BCFCI_RC  : AGE_AT_EXAM present 
## 24  : BCFCI_RC  : no duplicates found:) 
## 25  : BILINGUAL_SCALE_RC  : AGE_AT_EXAM present 
## 25  : BILINGUAL_SCALE_RC  : no duplicates found:) 
## 26  : CAT_FLUENCY_RC  : AGE_AT_EXAM present 
## 26  : CAT_FLUENCY_RC  : no duplicates found:) 
## 27  : CERAD_DEL_RC  : AGE_AT_EXAM present 
## 27  : CERAD_DEL_RC  : no duplicates found:) 
## 28  : CERAD_IMM_RC  : AGE_AT_EXAM present 
## 28  : CERAD_IMM_RC  : no duplicates found:) 
## 29  : CERAD_RECOG_RC  : AGE_AT_EXAM present 
## 29  : CERAD_RECOG_RC  : no duplicates found:) 
## 30  : CONSENSUS_DX =============================================== 
## 31  : CRAFT_21_DEL_RC  : AGE_AT_EXAM present 
## 31  : CRAFT_21_DEL_RC  : no duplicates found:) 
## 32  : CRAFT_21_IMM_RC  : AGE_AT_EXAM present 
## 32  : CRAFT_21_IMM_RC  : no duplicates found:) 
## 33  : MEDCON_RC  : AGE_AT_EXAM present 
## 33  : MEDCON_RC  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 34  : MEDICAL_HIST  : AGE_AT_EXAM present 
## 34  : MEDICAL_HIST  : !!!duplicates present (checking by AGE_AT_EXAM )!!! 
## 35  : MINT_RC  : AGE_AT_EXAM present 
## 35  : MINT_RC  : no duplicates found:) 
## 36  : MINT_SP_RC  : AGE_AT_EXAM present 
## 36  : MINT_SP_RC  : no duplicates found:) 
## 37  : MOCA_RC  : AGE_AT_EXAM present 
## 37  : MOCA_RC  : no duplicates found:) 
## 38  : NUMBER_SPAN_RC  : AGE_AT_EXAM present 
## 38  : NUMBER_SPAN_RC  : no duplicates found:)</code></pre>
<pre class="r"><code>## findings: when mergeing, AGE_AT_EXAM can not be used as the key column, cause duplicates existed for some people with different AGE_AT_EXAM
## after rounding up, those obs have same AGE_AT_EXAM values</code></pre>
<p><br> <br></p>
</div>
<div id="generate-visit-index-variable" class="section level2">
<h2>Generate Visit Index Variable</h2>
<pre class="r"><code>## for every individual, get all their date data
ppdat &lt;- data.frame(SYSIND = numeric(0), EXAM_DATE = as.Date(character(0)))

## for dataset with EXAM_DATE, we just need to extract the relevant information and appending to the ppdat
for (df_name in dfwEXAM_DATE) {
  df_obj &lt;- get(df_name)  # get the dataframe
  
  df_obj &lt;- df_obj[,c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;)]
  
  ppdat &lt;- rbind(ppdat,df_obj)
}

ppdat &lt;- ppdat[!duplicated(ppdat),]

## for dataset without EXAM_DATE, extract other data variables and appending to the ppdat

## ALZ_CLINICALSUM: has FORM_DATE
## ALZ_EXAM: has FORM_DATE
## ALZ_LOAD_COG: has INTERVIEW_DATE
## ALZ_NCRAD: has FORM_DATE
## ALZ_SCREENING: has FORM_DATE
## CONSENSUS_DX: DATE_DX

dfwFORM_DATE &lt;- c(&quot;ALZ_CLINICALSUM&quot;,&quot;ALZ_EXAM&quot;,&quot;ALZ_NCRAD&quot;,&quot;ALZ_SCREENING&quot;)
for (df_name in dfwFORM_DATE) {
  df_obj &lt;- get(df_name)  # get the dataframe
  
  df_obj &lt;- df_obj[,c(&quot;SYSIND&quot;,&quot;FORM_DATE&quot;)]
  names(df_obj) &lt;- c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;)
  
  ppdat &lt;- rbind(ppdat,df_obj)
}

ppdat &lt;- ppdat[!duplicated(ppdat),]

df_obj &lt;- ALZ_LOAD_COG
df_obj &lt;- df_obj[,c(&quot;SYSIND&quot;,&quot;INTERVIEW_DATE&quot;)]
names(df_obj) &lt;- c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;)
ppdat &lt;- rbind(ppdat,df_obj)
ppdat &lt;- ppdat[!duplicated(ppdat),]

df_obj &lt;- CONSENSUS_DX
df_obj &lt;- df_obj[,c(&quot;SYSIND&quot;,&quot;DATE_DX&quot;)]
names(df_obj) &lt;- c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;)
ppdat &lt;- rbind(ppdat,df_obj)
ppdat &lt;- ppdat[!duplicated(ppdat),]

info(ppdat,&quot;SYSIND&quot;) #obs:5204, cols:2, inds:1994</code></pre>
<pre><code>## #obs:5204, cols:2, inds:1994</code></pre>
<pre class="r"><code>sorted_ppdat &lt;- ppdat %&gt;% arrange(SYSIND, EXAM_DATE)

## creating the Visit Index variable
## If a subject’s next exam is &lt; 3 months after the last one, it stays in the same visit.
## If it’s ≥ 3 months, it becomes the next visit.
## Starts at 1 for each subject.
sorted_ppdat2 &lt;- sorted_ppdat %&gt;%
  group_by(SYSIND) %&gt;%
  mutate(
    new_visit = is.na(lag(EXAM_DATE)) |
      EXAM_DATE &gt;= (lag(EXAM_DATE) %m+% months(6)),
    Visit_Index = cumsum(new_visit) ## start a new visit when the gap from the previous exam is ≥ 3 months
  ) %&gt;%
  select(-new_visit) %&gt;%
  ungroup()

## Visit summary
visit_summary &lt;- sorted_ppdat2 %&gt;%
  group_by(SYSIND) %&gt;%
  summarise(
    total_visits = n_distinct(Visit_Index),
    total_obs    = n(),                 # how many raw rows for this person
    first_date   = min(EXAM_DATE, na.rm = TRUE),
    last_date    = max(EXAM_DATE, na.rm = TRUE),
    span_days    = as.integer(last_date - first_date)
  ) %&gt;%
  arrange(desc(total_visits))

DT::datatable(visit_summary)</code></pre>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2ae1b1bab4e9470885df" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2ae1b1bab4e9470885df">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301","302","303","304","305","306","307","308","309","310","311","312","313","314","315","316","317","318","319","320","321","322","323","324","325","326","327","328","329","330","331","332","333","334","335","336","337","338","339","340","341","342","343","344","345","346","347","348","349","350","351","352","353","354","355","356","357","358","359","360","361","362","363","364","365","366","367","368","369","370","371","372","373","374","375","376","377","378","379","380","381","382","383","384","385","386","387","388","389","390","391","392","393","394","395","396","397","398","399","400","401","402","403","404","405","406","407","408","409","410","411","412","413","414","415","416","417","418","419","420","421","422","423","424","425","426","427","428","429","430","431","432","433","434","435","436","437","438","439","440","441","442","443","444","445","446","447","448","449","450","451","452","453","454","455","456","457","458","459","460","461","462","463","464","465","466","467","468","469","470","471","472","473","474","475","476","477","478","479","480","481","482","483","484","485","486","487","488","489","490","491","492","493","494","495","496","497","498","499","500","501","502","503","504","505","506","507","508","509","510","511","512","513","514","515","516","517","518","519","520","521","522","523","524","525","526","527","528","529","530","531","532","533","534","535","536","537","538","539","540","541","542","543","544","545","546","547","548","549","550","551","552","553","554","555","556","557","558","559","560","561","562","563","564","565","566","567","568","569","570","571","572","573","574","575","576","577","578","579","580","581","582","583","584","585","586","587","588","589","590","591","592","593","594","595","596","597","598","599","600","601","602","603","604","605","606","607","608","609","610","611","612","613","614","615","616","617","618","619","620","621","622","623","624","625","626","627","628","629","630","631","632","633","634","635","636","637","638","639","640","641","642","643","644","645","646","647","648","649","650","651","652","653","654","655","656","657","658","659","660","661","662","663","664","665","666","667","668","669","670","671","672","673","674","675","676","677","678","679","680","681","682","683","684","685","686","687","688","689","690","691","692","693","694","695","696","697","698","699","700","701","702","703","704","705","706","707","708","709","710","711","712","713","714","715","716","717","718","719","720","721","722","723","724","725","726","727","728","729","730","731","732","733","734","735","736","737","738","739","740","741","742","743","744","745","746","747","748","749","750","751","752","753","754","755","756","757","758","759","760","761","762","763","764","765","766","767","768","769","770","771","772","773","774","775","776","777","778","779","780","781","782","783","784","785","786","787","788","789","790","791","792","793","794","795","796","797","798","799","800","801","802","803","804","805","806","807","808","809","810","811","812","813","814","815","816","817","818","819","820","821","822","823","824","825","826","827","828","829","830","831","832","833","834","835","836","837","838","839","840","841","842","843","844","845","846","847","848","849","850","851","852","853","854","855","856","857","858","859","860","861","862","863","864","865","866","867","868","869","870","871","872","873","874","875","876","877","878","879","880","881","882","883","884","885","886","887","888","889","890","891","892","893","894","895","896","897","898","899","900","901","902","903","904","905","906","907","908","909","910","911","912","913","914","915","916","917","918","919","920","921","922","923","924","925","926","927","928","929","930","931","932","933","934","935","936","937","938","939","940","941","942","943","944","945","946","947","948","949","950","951","952","953","954","955","956","957","958","959","960","961","962","963","964","965","966","967","968","969","970","971","972","973","974","975","976","977","978","979","980","981","982","983","984","985","986","987","988","989","990","991","992","993","994","995","996","997","998","999","1000","1001","1002","1003","1004","1005","1006","1007","1008","1009","1010","1011","1012","1013","1014","1015","1016","1017","1018","1019","1020","1021","1022","1023","1024","1025","1026","1027","1028","1029","1030","1031","1032","1033","1034","1035","1036","1037","1038","1039","1040","1041","1042","1043","1044","1045","1046","1047","1048","1049","1050","1051","1052","1053","1054","1055","1056","1057","1058","1059","1060","1061","1062","1063","1064","1065","1066","1067","1068","1069","1070","1071","1072","1073","1074","1075","1076","1077","1078","1079","1080","1081","1082","1083","1084","1085","1086","1087","1088","1089","1090","1091","1092","1093","1094","1095","1096","1097","1098","1099","1100","1101","1102","1103","1104","1105","1106","1107","1108","1109","1110","1111","1112","1113","1114","1115","1116","1117","1118","1119","1120","1121","1122","1123","1124","1125","1126","1127","1128","1129","1130","1131","1132","1133","1134","1135","1136","1137","1138","1139","1140","1141","1142","1143","1144","1145","1146","1147","1148","1149","1150","1151","1152","1153","1154","1155","1156","1157","1158","1159","1160","1161","1162","1163","1164","1165","1166","1167","1168","1169","1170","1171","1172","1173","1174","1175","1176","1177","1178","1179","1180","1181","1182","1183","1184","1185","1186","1187","1188","1189","1190","1191","1192","1193","1194","1195","1196","1197","1198","1199","1200","1201","1202","1203","1204","1205","1206","1207","1208","1209","1210","1211","1212","1213","1214","1215","1216","1217","1218","1219","1220","1221","1222","1223","1224","1225","1226","1227","1228","1229","1230","1231","1232","1233","1234","1235","1236","1237","1238","1239","1240","1241","1242","1243","1244","1245","1246","1247","1248","1249","1250","1251","1252","1253","1254","1255","1256","1257","1258","1259","1260","1261","1262","1263","1264","1265","1266","1267","1268","1269","1270","1271","1272","1273","1274","1275","1276","1277","1278","1279","1280","1281","1282","1283","1284","1285","1286","1287","1288","1289","1290","1291","1292","1293","1294","1295","1296","1297","1298","1299","1300","1301","1302","1303","1304","1305","1306","1307","1308","1309","1310","1311","1312","1313","1314","1315","1316","1317","1318","1319","1320","1321","1322","1323","1324","1325","1326","1327","1328","1329","1330","1331","1332","1333","1334","1335","1336","1337","1338","1339","1340","1341","1342","1343","1344","1345","1346","1347","1348","1349","1350","1351","1352","1353","1354","1355","1356","1357","1358","1359","1360","1361","1362","1363","1364","1365","1366","1367","1368","1369","1370","1371","1372","1373","1374","1375","1376","1377","1378","1379","1380","1381","1382","1383","1384","1385","1386","1387","1388","1389","1390","1391","1392","1393","1394","1395","1396","1397","1398","1399","1400","1401","1402","1403","1404","1405","1406","1407","1408","1409","1410","1411","1412","1413","1414","1415","1416","1417","1418","1419","1420","1421","1422","1423","1424","1425","1426","1427","1428","1429","1430","1431","1432","1433","1434","1435","1436","1437","1438","1439","1440","1441","1442","1443","1444","1445","1446","1447","1448","1449","1450","1451","1452","1453","1454","1455","1456","1457","1458","1459","1460","1461","1462","1463","1464","1465","1466","1467","1468","1469","1470","1471","1472","1473","1474","1475","1476","1477","1478","1479","1480","1481","1482","1483","1484","1485","1486","1487","1488","1489","1490","1491","1492","1493","1494","1495","1496","1497","1498","1499","1500","1501","1502","1503","1504","1505","1506","1507","1508","1509","1510","1511","1512","1513","1514","1515","1516","1517","1518","1519","1520","1521","1522","1523","1524","1525","1526","1527","1528","1529","1530","1531","1532","1533","1534","1535","1536","1537","1538","1539","1540","1541","1542","1543","1544","1545","1546","1547","1548","1549","1550","1551","1552","1553","1554","1555","1556","1557","1558","1559","1560","1561","1562","1563","1564","1565","1566","1567","1568","1569","1570","1571","1572","1573","1574","1575","1576","1577","1578","1579","1580","1581","1582","1583","1584","1585","1586","1587","1588","1589","1590","1591","1592","1593","1594","1595","1596","1597","1598","1599","1600","1601","1602","1603","1604","1605","1606","1607","1608","1609","1610","1611","1612","1613","1614","1615","1616","1617","1618","1619","1620","1621","1622","1623","1624","1625","1626","1627","1628","1629","1630","1631","1632","1633","1634","1635","1636","1637","1638","1639","1640","1641","1642","1643","1644","1645","1646","1647","1648","1649","1650","1651","1652","1653","1654","1655","1656","1657","1658","1659","1660","1661","1662","1663","1664","1665","1666","1667","1668","1669","1670","1671","1672","1673","1674","1675","1676","1677","1678","1679","1680","1681","1682","1683","1684","1685","1686","1687","1688","1689","1690","1691","1692","1693","1694","1695","1696","1697","1698","1699","1700","1701","1702","1703","1704","1705","1706","1707","1708","1709","1710","1711","1712","1713","1714","1715","1716","1717","1718","1719","1720","1721","1722","1723","1724","1725","1726","1727","1728","1729","1730","1731","1732","1733","1734","1735","1736","1737","1738","1739","1740","1741","1742","1743","1744","1745","1746","1747","1748","1749","1750","1751","1752","1753","1754","1755","1756","1757","1758","1759","1760","1761","1762","1763","1764","1765","1766","1767","1768","1769","1770","1771","1772","1773","1774","1775","1776","1777","1778","1779","1780","1781","1782","1783","1784","1785","1786","1787","1788","1789","1790","1791","1792","1793","1794","1795","1796","1797","1798","1799","1800","1801","1802","1803","1804","1805","1806","1807","1808","1809","1810","1811","1812","1813","1814","1815","1816","1817","1818","1819","1820","1821","1822","1823","1824","1825","1826","1827","1828","1829","1830","1831","1832","1833","1834","1835","1836","1837","1838","1839","1840","1841","1842","1843","1844","1845","1846","1847","1848","1849","1850","1851","1852","1853","1854","1855","1856","1857","1858","1859","1860","1861","1862","1863","1864","1865","1866","1867","1868","1869","1870","1871","1872","1873","1874","1875","1876","1877","1878","1879","1880","1881","1882","1883","1884","1885","1886","1887","1888","1889","1890","1891","1892","1893","1894","1895","1896","1897","1898","1899","1900","1901","1902","1903","1904","1905","1906","1907","1908","1909","1910","1911","1912","1913","1914","1915","1916","1917","1918","1919","1920","1921","1922","1923","1924","1925","1926","1927","1928","1929","1930","1931","1932","1933","1934","1935","1936","1937","1938","1939","1940","1941","1942","1943","1944","1945","1946","1947","1948","1949","1950","1951","1952","1953","1954","1955","1956","1957","1958","1959","1960","1961","1962","1963","1964","1965","1966","1967","1968","1969","1970","1971","1972","1973","1974","1975","1976","1977","1978","1979","1980","1981","1982","1983","1984","1985","1986","1987","1988","1989","1990","1991","1992","1993","1994"],[11041163,11024153,11039653,11039663,11040003,11041153,11109523,11109543,11005553,11005833,11005893,11006193,11007343,11007783,11009163,11034113,11037673,11039823,11039903,11040013,11040333,11041043,11041173,11063743,11064113,11109513,11109643,11160333,11160513,11160523,11163433,11248103,11341663,11005283,11005403,11005413,11005423,11005663,11005683,11005693,11005783,11005813,11005883,11006263,11006293,11006303,11006693,11006733,11007063,11007543,11007623,11007693,11007763,11007773,11007793,11009393,11009423,11009483,11010673,11011063,11012393,11024003,11034073,11034403,11034493,11036733,11036823,11036863,11037103,11037323,11037393,11037613,11039433,11039453,11039513,11039633,11039803,11039913,11040173,11040323,11040363,11040573,11051603,11051663,11051913,11052183,11052753,11053213,11058883,11059213,11063753,11063923,11109533,11109853,11109953,11110073,11110113,11110213,11110253,11110403,11111383,11111443,11161523,11161883,11161933,11163443,11165493,11216923,11219553,11221423,11221503,11222153,11222953,11223013,11248653,11340143,11341643,11358523,11360553,11369223,11369583,11369703,11369753,11369773,11414943,11435803,11435813,11005393,11005633,11005713,11005733,11005743,11005803,11005823,11005843,11006083,11006093,11006393,11006583,11006603,11006763,11006853,11006883,11006893,11006973,11007173,11007213,11007633,11007653,11007723,11007843,11007893,11007973,11008023,11008073,11008133,11008293,11008313,11008573,11008753,11008763,11008773,11008833,11008863,11008953,11009143,11009213,11009263,11009363,11009573,11009583,11011023,11011053,11011223,11011273,11011433,11011563,11011773,11012073,11018563,11024123,11034143,11034593,11034603,11035023,11036713,11036743,11036753,11036783,11036793,11036803,11036853,11036883,11037063,11037213,11037223,11037313,11037373,11037413,11037453,11037513,11037543,11037593,11037623,11037653,11039463,11039493,11039523,11039543,11039553,11039563,11039583,11039593,11039693,11039713,11039723,11039783,11039833,11039843,11039883,11039953,11039963,11039993,11040023,11040153,11040183,11040223,11040243,11040263,11040273,11040293,11040303,11040343,11041143,11044303,11044313,11048013,11048033,11048883,11051513,11051533,11051573,11051633,11051643,11051673,11051733,11051753,11051773,11051783,11051993,11052013,11052023,11052053,11052173,11052223,11052313,11052323,11052813,11053223,11053293,11057853,11059233,11063633,11063713,11063943,11063963,11064443,11108783,11108793,11108803,11108813,11108823,11108833,11109183,11109483,11109493,11109553,11109593,11109633,11109653,11109673,11109693,11109753,11109763,11109783,11109793,11109833,11109873,11109933,11109963,11110003,11110013,11110093,11110133,11110173,11110223,11110283,11110303,11110383,11111363,11111373,11111453,11135243,11157933,11157983,11160583,11161743,11161793,11161823,11161843,11162543,11162663,11162853,11162863,11163213,11163373,11163453,11163473,11163493,11163533,11163663,11163783,11163793,11167333,11212163,11212363,11215343,11215383,11215403,11216893,11216903,11218563,11218583,11218593,11218603,11218643,11218923,11219593,11219843,11219893,11219923,11219943,11220163,11220183,11220223,11220393,11221433,11221813,11221933,11221943,11222143,11248683,11249823,11313733,11323413,11323433,11329533,11341583,11341593,11341653,11345183,11346023,11346713,11346723,11347443,11359933,11360633,11362953,11368203,11368263,11368363,11368423,11368433,11368923,11368953,11368983,11369063,11369093,11369113,11369193,11369213,11369233,11369473,11369573,11369713,11369783,11369813,11369823,11420163,11420173,11435773,11435853,11443133,11455133,11590193,11620493,11621183,11638383,11645743,11667133,11005233,11005433,11005723,11005773,11006353,11006473,11006743,11006903,11006913,11007073,11007123,11007683,11007853,11007933,11007943,11008103,11008183,11008643,11008723,11008733,11008893,11008923,11008973,11009023,11009103,11009303,11009593,11009603,11010563,11010653,11010963,11010973,11011093,11011163,11011583,11011853,11011893,11012263,11012313,11012633,11024163,11024253,11024263,11034293,11034313,11034463,11034503,11034523,11034563,11034573,11034613,11034623,11034633,11034703,11034723,11035013,11036763,11036813,11036833,11036843,11036873,11036893,11037113,11037143,11037153,11037163,11037183,11037203,11037283,11037303,11037333,11037343,11037353,11037363,11037383,11037403,11037423,11037433,11037443,11037493,11037503,11037523,11037533,11037553,11037583,11037633,11037643,11037663,11037683,11037703,11037713,11039473,11039533,11039603,11039613,11039623,11039643,11039683,11039703,11039733,11039773,11039813,11039853,11039873,11039893,11039923,11039973,11040203,11040213,11040233,11040253,11040373,11040613,11042263,11042273,11044033,11044813,11045923,11048163,11048263,11048273,11048283,11048693,11048913,11049163,11049493,11051543,11051583,11051623,11051653,11051683,11051693,11051703,11051723,11051803,11051823,11051903,11051943,11052003,11052033,11052043,11052063,11052073,11052083,11052093,11052103,11052113,11052123,11052133,11052143,11052153,11052193,11052203,11052213,11052233,11052243,11052253,11052263,11052273,11052283,11052293,11052303,11052353,11052683,11052693,11052703,11052713,11052723,11052733,11052743,11052763,11052773,11052803,11052833,11052863,11052873,11052883,11052893,11052903,11052913,11052923,11052933,11052983,11053123,11053133,11053153,11053173,11053233,11053253,11053273,11053283,11053313,11053333,11053343,11053353,11053373,11053383,11053393,11053403,11053413,11053423,11057753,11057863,11057893,11059263,11059623,11062473,11063703,11063723,11063933,11063953,11063993,11064413,11064423,11064433,11064873,11108733,11108743,11108753,11108763,11108773,11108843,11108853,11108863,11108873,11108883,11109173,11109193,11109203,11109213,11109223,11109233,11109503,11109563,11109573,11109583,11109603,11109623,11109663,11109703,11109713,11109723,11109733,11109743,11109773,11109813,11109823,11109843,11109863,11109883,11109893,11109903,11109913,11109923,11109943,11109973,11109983,11109993,11110023,11110033,11110043,11110053,11110063,11110083,11110123,11110163,11110183,11110193,11110203,11110233,11110263,11110273,11110293,11110313,11110323,11110333,11110343,11110353,11110363,11110373,11110393,11110413,11110423,11110433,11110443,11110483,11110493,11111183,11111193,11111293,11111393,11111403,11111423,11111433,11111463,11134623,11134663,11134713,11134723,11134753,11134763,11134843,11134953,11135213,11138293,11139983,11143823,11157903,11157913,11157943,11157973,11157993,11158003,11158013,11158023,11158033,11158043,11158053,11158063,11158073,11158123,11158133,11158153,11158933,11158943,11159093,11160343,11160363,11160533,11160683,11161383,11161393,11161413,11161533,11161543,11161553,11161563,11161573,11161683,11161703,11161713,11161723,11161733,11161753,11161763,11161783,11161803,11161813,11161833,11161853,11161863,11161873,11161893,11161903,11161913,11161923,11161943,11161953,11161963,11162553,11162603,11162613,11162633,11162653,11162963,11162973,11162983,11162993,11163003,11163133,11163173,11163183,11163293,11163313,11163323,11163333,11163343,11163363,11163383,11163463,11163483,11163553,11163563,11163573,11163583,11163593,11163683,11163693,11163773,11164743,11164763,11164773,11164783,11165133,11165143,11165153,11165413,11167313,11167323,11167343,11167353,11167363,11167373,11167393,11211903,11212263,11212373,11215323,11215353,11215363,11215373,11215393,11216913,11216933,11216943,11217103,11218493,11218513,11218533,11218613,11218963,11219013,11219543,11219563,11219763,11219773,11219803,11219813,11219823,11219833,11219853,11219863,11219873,11219883,11219913,11219933,11219953,11219963,11219973,11219983,11219993,11220143,11220153,11220173,11220193,11220203,11220213,11220243,11220253,11220263,11220323,11220343,11220373,11220403,11220413,11220423,11220483,11220503,11220543,11220653,11220683,11220703,11220713,11220743,11221123,11221133,11221143,11221223,11221233,11221253,11221263,11221273,11221303,11221323,11221343,11221353,11221363,11221383,11221403,11221413,11221473,11221483,11221493,11221543,11221553,11221563,11221743,11221753,11221763,11221773,11221783,11221803,11221823,11221833,11221843,11221863,11221873,11221893,11221903,11221913,11222043,11222053,11222063,11222073,11222083,11222093,11222943,11222993,11245643,11245653,11247843,11247853,11247883,11247893,11247943,11247963,11248003,11248013,11248023,11248033,11248043,11248053,11248063,11248073,11248083,11248093,11248153,11248413,11248623,11248663,11248673,11248693,11248723,11248943,11249163,11249793,11249833,11249943,11249963,11249973,11249993,11250153,11250383,11250413,11250553,11250563,11264853,11264863,11264873,11264883,11264893,11265333,11265343,11286153,11293253,11302133,11302533,11302543,11305133,11307463,11307473,11307483,11313743,11322343,11323443,11323903,11324633,11324663,11329543,11329553,11329563,11329573,11329583,11329733,11339743,11340153,11340163,11341603,11341613,11341623,11341673,11341733,11341743,11341753,11341763,11341773,11341783,11341793,11341813,11341823,11341833,11341843,11341853,11341863,11345483,11345513,11345523,11345543,11345593,11345913,11345923,11345933,11345943,11345953,11345963,11345973,11345993,11346013,11346043,11346073,11346083,11346093,11346103,11346113,11346123,11346133,11346693,11346703,11346733,11346753,11346763,11347073,11347323,11347393,11347413,11347423,11347433,11347453,11348533,11348543,11348553,11348573,11348603,11348613,11351413,11351423,11351433,11351453,11351473,11351503,11351523,11351543,11351553,11351603,11351733,11351783,11351803,11358423,11358433,11358483,11358493,11358503,11358513,11358533,11358733,11358743,11358753,11358763,11358773,11360543,11360563,11360593,11363483,11363503,11366573,11368183,11368243,11368273,11368493,11368753,11368783,11368793,11368873,11369203,11369293,11369313,11369543,11369553,11369623,11369643,11369693,11369913,11369933,11378333,11399673,11399783,11414133,11414533,11420143,11420713,11421653,11427703,11433133,11435743,11435753,11435763,11435823,11435833,11435843,11435863,11435873,11440943,11441133,11441143,11441153,11443143,11443153,11443163,11443533,11447143,11449733,11456553,11458103,11458123,11458143,11458753,11465543,11475933,11476133,11476163,11476173,11476183,11476193,11493243,11493413,11493533,11493563,11493603,11493613,11493623,11493643,11493663,11493683,11493703,11493753,11493763,11493773,11507333,11507353,11538733,11544953,11559733,11573733,11573743,11573753,11573973,11575133,11575143,11589743,11589943,11589953,11589983,11589993,11590003,11590013,11590023,11590133,11590143,11590153,11590203,11590213,11590223,11590243,11606333,11607133,11607333,11607533,11607733,11607743,11607753,11617533,11617543,11617553,11617563,11617573,11617733,11617743,11617933,11617943,11617953,11617963,11617973,11617983,11618013,11618033,11618043,11618133,11618143,11618153,11618163,11618173,11618183,11618193,11618203,11618213,11618223,11618233,11620393,11620403,11620413,11620423,11620443,11620453,11620463,11620473,11620483,11620503,11620513,11620523,11620533,11620543,11620553,11620563,11620573,11620583,11620733,11620743,11620763,11620773,11620783,11620793,11620803,11620813,11620823,11620843,11620853,11620863,11620873,11620893,11620903,11620913,11620923,11620933,11620943,11620953,11620963,11621133,11621153,11621163,11621173,11621193,11621203,11621213,11621223,11621233,11621243,11621253,11621263,11621273,11621283,11621293,11621303,11621333,11621363,11621373,11638333,11638353,11638363,11638373,11638393,11638403,11638413,11638423,11638433,11638443,11638453,11638463,11638473,11638733,11638743,11638753,11638763,11638773,11638783,11638793,11638803,11638813,11645753,11645933,11662733,11662743,11666533,11666543,11666553,11666573,11666593,11666603,11666613,11666623,11666633,11666643,11666653,11666663,11666673,11674933,11676733,11676753,11676863,11689603,11717393,11717733,11717753,11718353,11718373,11718423,11718433,11719363,11719383,11005073,11005103,11006333,11006543,11006573,11006773,11007463,11007643,11007823,11007863,11008263,11008303,11008433,11008793,11009333,11010713,11011243,11011873,11011903,11011913,11012053,11012203,11012303,11012423,11012523,11024203,11024303,11034083,11034473,11034513,11034543,11034553,11035063,11036723,11036773,11037093,11037123,11037173,11037573,11037603,11039443,11039483,11039503,11039743,11039753,11039763,11039793,11039863,11039983,11040163,11040353,11040383,11042283,11044283,11044293,11046873,11046963,11046973,11048153,11048643,11048713,11049113,11049123,11049143,11049153,11049173,11049783,11051523,11051553,11051563,11052163,11052333,11052343,11052823,11052853,11053243,11053263,11053303,11053323,11053363,11057883,11058413,11059693,11062663,11062683,11063733,11064393,11064573,11088253,11109403,11109413,11109613,11109683,11109803,11110143,11110153,11110243,11111413,11111473,11134633,11134643,11134703,11134773,11134853,11134913,11139993,11140003,11145803,11147013,11147113,11147173,11161583,11161693,11161773,11162623,11162643,11162843,11163143,11163163,11163203,11163223,11163303,11163353,11163393,11163673,11164753,11167403,11215333,11218433,11218523,11218623,11218633,11218653,11218663,11218693,11219583,11219743,11219753,11219783,11219903,11220233,11220523,11220663,11220693,11220733,11221153,11221283,11221393,11221853,11221883,11221923,11222103,11223003,11247833,11247873,11247953,11247973,11247983,11247993,11248703,11249743,11249753,11249763,11249773,11249803,11249983,11286023,11286033,11286353,11293373,11297343,11317303,11322333,11323453,11323463,11323893,11324623,11324643,11324653,11326143,11329153,11329393,11340133,11341803,11345413,11345423,11346053,11346743,11348003,11348033,11351443,11351463,11351743,11359733,11360573,11360583,11360603,11360613,11360623,11360643,11360653,11360663,11360673,11360893,11360983,11361003,11361013,11361023,11361033,11362933,11362943,11362963,11362973,11363133,11363513,11363523,11363753,11363763,11363773,11366563,11366733,11366753,11368193,11368213,11368223,11368233,11368303,11368313,11368333,11368343,11368353,11368373,11368383,11368393,11368403,11368413,11368443,11368453,11368463,11368473,11368483,11368503,11368763,11368773,11368803,11368813,11368823,11368833,11368843,11368853,11368863,11368883,11368893,11368903,11368913,11368933,11368943,11368963,11368973,11369013,11369023,11369033,11369043,11369053,11369073,11369083,11369123,11369133,11369143,11369153,11369163,11369173,11369183,11369243,11369253,11369263,11369273,11369283,11369303,11369323,11369333,11369343,11369353,11369363,11369373,11369403,11369423,11369443,11369453,11369523,11369533,11369563,11369593,11369603,11369613,11369633,11369653,11369663,11369673,11369683,11369723,11369733,11369743,11369763,11369793,11369803,11369853,11369863,11369873,11369883,11370353,11370393,11374013,11374033,11404233,11414933,11419533,11420133,11420153,11420333,11421663,11427693,11435783,11445933,11447133,11449933,11451943,11454303,11458133,11458733,11458743,11476143,11476153,11476533,11490133,11492153,11492163,11492733,11493193,11493293,11493353,11493363,11493573,11493593,11493633,11493693,11493803,11493813,11493833,11494133,11500983,11544933,11544943,11559743,11574453,11589933,11589963,11589973,11590163,11590173,11590183,11590233,11599333,11615333,11615343,11615353,11615363,11615373,11615533,11618053,11618063,11620433,11620753,11620833,11620883,11621143,11621343,11621353,11659133,11660143,11660163,11660183,11660193,11660233,11660243,11660373,11660423,11660463,11662933,11662943,11662953,11663133,11663143,11663153,11663173,11663183,11676743,11676813,11676853,11676913,11676933,11676963,11678733,11689543,11689553,11689563,11689573,11689583,11689593,11689613,11689623,11689633,11689643,11689653,11705333,11705733,11705753,11705763,11706333,11706413,11706733,11706753,11707133,11707353,11707373,11707423,11707473,11707493,11707533,11707593,11707603,11707613,11707803,11707993,11717333,11717743,11718363,11718383,11718393,11718403,11718413,11718533,11718543,11718733,11719133,11719373,11719393,11720133,11720143,11723133,11723363,11723373,11723733,11724543,11724593,11725533,11725553,11725743,11725753,11728733,11732533,11732563,11732633,11732653,11732933,11732943,11732963,11733003,11733013,11733023,11733033,11733063,11733073,11733083,11733093,11733133,11733163,11733183,11733193,11733203,11733213,11733233,11733253,11733263,11733293,11733783,11733803,11734133,11734143,11734173,11734533,11738933,11738943,11739133,11739153,11739163,11739193,11739203,11739333,11742733,11742763,11742793,11742933,11742963,11742973,11743003,11743013,11743053,11743103,11743113,11743183,11743243,11743253,11743283,11743313,11743343,11743353,11743403,11743413,11743443,11743473,11743503,11743533,11743543,11743593,11743623,11743653,11743663,11743713,11743763,11743793,11743803,11743813,11743843,11743873,11743903,11743933,11743963,11744023,11744053,11744083,11744113,11744143,11744173,11744183,11744223,11744273,11744283,11744313,11744343,11744373,11744733,11744743,11744973,11745133,11745333,11745343,11745543,11745553,11745753,11745943,11745973,11746003,11746033,11746063,11746093,11751153,11751183,11754133,11754173,11754203,11754213,11754243,11754283,11754293,11754553,11755153,11755183,11755223,11755303,11755533,11755543,11755573,11755603,11755733,11756533,11756743,11757333,11757933,11758133,11758343,11758533,11758543,11758553,11758563,11761983,11763293,11786593,11786603,11786613,11786623,11786633,11786643,11787103,11787433,11787443,11789073,11789113,11789263,11789383,11789393,11789433,11789443,11789453,11789463,11789993,11790123,11790163,11790303,11790343,11790393,11790583,11791023,11791203,11793193,11793203,11793213,11793223,11793233,11793243,11793273,11793283,11793293,11793303,11793793,11793803,11793813,11793823,11793833,11793843,11793883,11794393,11794403,11794413,11794423,11794433,11794443,11794613,11795393,11795403,11795793,11795973,11796323,11796603,11796633,11796663,11796693,11796723,11796753,11796793,11797003,11797193,11797223,11797253,11798193,11798203,11798643,11798653,11798663,11798713,11799203,11799353,11799733,11799743,11799753,11799793,11800613,11800623,11800633,11800943,11801973,11802213,11802233,11802243,11802253,11802543],[7,6,6,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[8,7,8,10,7,6,10,7,5,7,7,5,5,6,8,8,9,6,7,5,7,9,7,6,7,6,6,8,6,5,10,5,7,4,5,5,5,6,6,4,6,7,4,4,4,6,4,5,4,4,6,4,5,4,5,4,6,4,4,5,5,5,5,5,4,4,4,4,4,4,4,4,6,4,4,4,5,4,5,4,4,5,6,5,5,4,6,4,4,4,6,6,5,5,6,8,5,5,6,5,6,7,7,5,5,6,6,4,5,6,5,6,5,5,4,4,4,5,7,4,7,7,6,5,5,6,5,4,3,4,4,4,3,4,4,3,5,3,4,3,4,3,4,4,5,3,5,3,5,3,3,3,6,3,3,3,3,3,3,5,3,3,4,4,3,3,3,4,3,3,3,4,5,3,4,4,5,3,3,4,6,4,5,5,4,3,4,4,3,3,3,3,4,3,5,3,4,4,3,3,5,3,6,4,5,5,6,3,4,7,5,8,5,4,3,4,3,6,4,3,4,5,3,4,5,5,5,5,3,3,3,3,4,6,3,3,3,3,4,3,3,6,3,3,3,4,3,4,4,3,3,3,4,3,6,4,3,3,3,4,5,3,6,5,3,4,3,4,4,4,4,6,6,3,4,5,5,4,4,3,4,5,3,5,3,5,3,4,4,5,4,4,5,4,4,4,6,4,3,5,6,6,4,6,4,3,3,4,3,4,3,4,3,4,5,4,5,3,4,5,3,4,3,3,3,5,4,3,5,3,4,3,3,3,5,3,5,4,3,3,4,3,4,3,4,3,5,4,3,3,3,3,3,3,5,4,4,3,3,5,5,3,4,5,4,3,5,5,6,4,5,5,4,6,4,5,4,4,4,5,4,4,5,5,4,6,7,4,3,5,4,3,3,4,3,3,4,3,3,3,2,2,2,2,4,2,5,2,2,2,2,3,2,2,3,2,2,2,3,6,2,2,2,4,6,3,2,2,5,3,2,2,2,2,2,3,2,3,3,2,2,2,5,4,2,2,2,2,2,2,2,2,4,3,3,2,2,2,2,5,2,2,2,2,2,2,5,2,2,3,2,2,2,3,3,4,3,2,3,3,2,3,2,7,3,2,2,3,2,3,2,3,2,2,3,2,4,3,2,2,3,3,2,3,2,2,2,4,5,2,3,2,2,2,4,2,2,3,2,2,5,4,3,2,2,2,3,2,2,2,2,2,2,2,2,2,4,4,2,2,2,3,2,2,2,2,2,2,3,2,2,2,2,3,3,2,2,2,2,3,3,2,2,2,3,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,4,2,2,2,3,2,2,2,2,2,2,2,2,2,2,4,3,3,2,3,2,2,3,2,3,2,2,2,2,2,2,2,3,3,3,5,3,2,2,2,2,3,2,2,2,2,3,2,3,3,2,2,2,2,3,3,4,5,2,2,4,2,3,3,3,4,3,3,3,4,4,4,3,3,5,3,3,4,2,2,3,3,2,4,2,3,3,3,3,3,3,4,3,3,3,3,3,3,2,2,3,2,3,4,2,4,6,6,4,2,3,3,4,3,4,2,4,2,3,2,3,2,2,3,3,2,2,2,2,2,3,3,3,3,2,4,2,2,3,2,2,2,3,2,4,2,3,2,3,2,2,3,2,2,2,3,2,4,5,3,3,3,3,4,3,4,3,2,2,3,2,4,3,2,2,2,4,3,3,3,2,2,2,2,2,3,2,2,3,2,3,2,3,4,3,3,5,2,4,3,4,2,2,3,2,2,2,3,3,2,2,2,3,2,2,2,2,2,3,2,3,2,3,3,2,3,2,2,3,2,2,2,2,4,3,2,3,3,2,3,2,5,2,2,2,2,2,2,2,2,4,4,3,2,2,2,3,3,4,2,3,3,3,3,2,2,2,3,2,2,2,3,4,2,2,2,3,3,3,2,2,2,2,2,2,3,2,2,3,2,2,2,2,2,2,3,4,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,3,2,2,2,2,3,2,2,3,2,2,2,2,2,3,3,2,2,3,2,2,2,2,2,2,2,2,3,2,2,4,2,3,2,2,2,4,2,3,2,3,2,2,2,3,2,2,3,4,3,2,2,2,2,2,4,2,2,4,3,2,2,2,3,3,3,3,3,2,3,3,2,3,3,3,2,2,2,2,3,3,2,4,2,2,4,4,5,3,3,3,3,4,3,3,2,2,3,3,3,2,3,3,2,3,4,2,2,2,3,2,2,2,2,3,3,3,2,3,4,3,2,3,3,3,3,2,2,2,2,2,3,5,3,5,3,2,3,3,3,3,2,3,3,3,2,2,2,3,2,3,2,3,2,2,2,3,2,3,5,2,2,4,3,3,4,3,5,3,5,6,3,5,3,3,4,5,4,4,6,6,3,3,2,3,3,3,2,3,2,2,2,4,2,2,2,2,3,2,3,2,2,2,2,2,2,2,3,3,3,2,2,3,3,2,3,2,2,2,3,2,4,3,3,3,3,3,3,3,5,6,3,4,2,3,2,2,2,2,2,2,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,1,1,2,2,1,1,1,1,1,1,3,2,4,1,1,3,1,1,1,1,1,1,2,1,1,1,3,1,2,1,2,1,1,2,1,5,1,1,1,1,1,1,1,1,1,2,5,1,1,1,1,1,2,4,4,3,3,2,1,3,1,3,3,3,3,3,2,2,1,2,1,1,3,1,1,1,1,1,1,1,2,3,4,1,1,1,3,3,1,2,2,1,1,1,1,1,1,3,3,3,4,3,1,2,1,1,1,2,1,1,3,1,2,2,3,1,2,2,1,2,3,2,2,3,1,1,1,4,2,2,2,2,2,2,2,2,2,2,3,2,3,3,2,2,2,2,1,1,3,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,1,2,1,1,1,2,3,3,3,3,3,3,3,3,2,2,1,3,1,1,1,3,1,1,3,3,4,3,3,2,2,2,2,2,3,3,2,2,2,2,2,2,3,2,3,2,2,2,3,2,2,2,3,2,3,2,2,2,3,3,2,2,3,2,3,2,2,3,2,3,2,3,3,3,2,3,3,3,3,2,2,2,3,2,2,2,2,4,1,3,3,2,2,1,2,2,2,3,3,4,2,3,3,2,2,3,3,2,2,2,3,3,3,2,3,2,3,3,2,5,3,3,3,3,2,4,2,3,1,2,2,3,3,2,2,3,3,2,3,2,3,2,2,3,3,2,3,2,2,2,2,3,1,3,2,1,2,2,3,1,3,2,2,2,2,1,1,1,2,2,2,2,1,2,2,2,2,3,2,3,2,2,2,2,1,1,1,1,2,2,2,2,2,2,2,2,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,1,2,3,1,2,2,2,1,1,2,2,1,2,2,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,2,2,1,1,2,2,2,2,1,1,2,1,1,1,1,2,2,1,2,1,2,1,1,2,2,1,1,2,2,2,2,1,2,1,1,1,1,1,1,1,2,1,1,2,2,1,1,2,1,1,1,1,1,1,1,1,1,2,1,1,2,2,1,2,2,3,1,1,2,1,1,1,2,1,1,2,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],["2017-11-27","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-11-27","2018-03-05","2018-03-19","2017-05-03","2018-01-30","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-02-01","2017-05-03","2018-07-29","2017-05-03","2017-05-03","2017-11-27","2018-03-27","2017-11-28","2018-03-05","2018-03-05","2018-08-08","2018-08-28","2018-08-20","2018-10-16","2019-04-04","2019-09-26","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-04-30","2017-05-03","2016-09-14","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2016-01-21","2017-05-03","2017-05-03","2017-05-03","2018-03-08","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-07-18","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-04-14","2017-11-28","2018-03-27","2017-11-28","2018-03-05","2018-03-07","2018-03-07","2018-03-07","2018-03-09","2018-03-08","2018-03-08","2018-03-08","2018-03-28","2018-03-28","2018-12-18","2018-12-11","2018-09-18","2018-10-16","2018-11-17","2019-02-14","2017-05-03","2019-03-07","2019-03-07","2019-03-04","2019-04-04","2019-04-11","2019-05-15","2018-09-23","2019-09-27","2019-11-20","2019-12-05","2020-03-03","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-09-02","2021-04-16","2021-04-19","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-03-27","2017-05-03","2017-05-03","2019-06-27","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-06-28","2016-02-02","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2016-09-14","2017-05-03","2017-05-03","2017-11-27","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-06-19","2017-06-19","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-02-01","2017-05-03","2017-05-03","2020-05-20","2017-05-03","2017-05-03","2017-05-03","2016-11-17","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-02-01","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2022-03-29","2019-09-27","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-11-27","2017-11-27","2017-11-27","2017-05-03","2017-05-03","2017-02-19","2017-05-03","2017-05-03","2018-03-20","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-04-14","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2018-04-03","2017-05-22","2017-11-28","2017-11-28","2017-11-28","2017-11-28","2017-11-27","2018-01-11","2018-01-11","2018-01-11","2018-01-11","2018-01-11","2018-01-11","2018-01-25","2018-03-05","2018-03-05","2018-03-05","2018-03-05","2018-03-05","2018-03-05","2018-03-06","2018-03-06","2018-03-06","2018-03-06","2018-03-06","2018-03-06","2018-03-07","2018-03-07","2018-03-07","2018-03-08","2018-03-07","2018-03-07","2018-03-07","2018-04-20","2018-03-08","2018-03-08","2018-03-08","2018-03-14","2018-03-08","2018-03-28","2018-03-28","2018-03-28","2018-05-17","2018-06-05","2018-06-05","2018-08-22","2018-10-18","2018-09-19","2018-09-19","2018-09-17","2018-10-03","2018-10-03","2018-10-09","2018-10-09","2018-10-18","2018-10-16","2018-10-16","2018-10-25","2017-11-16","2018-10-25","2018-10-25","2018-10-25","2018-11-08","2018-12-05","2019-01-24","2019-01-24","2019-02-14","2019-02-14","2019-02-13","2019-02-14","2019-02-13","2019-03-06","2019-03-06","2019-03-06","2019-03-04","2019-03-04","2019-03-06","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-06","2019-03-06","2019-03-04","2018-03-06","2019-03-07","2019-03-07","2019-03-05","2019-03-05","2019-04-04","2019-05-15","2018-08-13","2019-07-11","2019-07-19","2019-07-24","2019-08-26","2019-09-25","2019-09-25","2019-09-26","2020-03-02","2017-09-23","2019-09-26","2019-09-26","2019-10-02","2019-12-05","2019-12-11","2020-01-20","2020-03-04","2020-03-04","2020-03-06","2020-03-06","2020-03-06","2020-03-03","2020-03-05","2020-03-05","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-03","2020-03-03","2020-03-03","2020-03-05","2020-03-02","2020-03-02","2020-03-03","2020-03-02","2020-10-24","2020-11-06","2021-04-19","2022-03-30","2021-06-17","2021-11-02","2022-04-06","2023-06-08","2023-02-23","2015-09-12","2023-09-27","2023-01-18","2019-05-22","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-03-05","2018-04-19","2019-05-20","2017-05-03","2019-06-26","2017-05-03","2019-02-08","2017-05-03","2018-06-07","2017-05-03","2019-05-20","2019-06-28","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-06-26","2017-05-03","2017-05-03","2016-09-07","2017-05-03","2017-05-03","2019-06-28","2017-05-03","2019-11-13","2018-09-28","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2023-10-25","2017-11-27","2017-11-27","2021-11-15","2017-05-03","2017-05-03","2017-05-03","2017-11-30","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-01","2017-11-27","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-11-12","2016-11-18","2017-05-03","2017-05-03","2019-03-05","2017-05-03","2017-05-03","2017-11-27","2017-11-27","2016-11-17","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-06-27","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-02-12","2017-05-03","2017-05-03","2017-05-03","2017-11-27","2017-05-03","2017-05-03","2017-11-30","2017-11-28","2018-08-21","2017-03-15","2017-11-28","2018-03-06","2018-02-19","2017-11-28","2017-11-28","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-09-23","2017-05-03","2017-05-03","2017-11-29","2017-05-03","2017-05-03","2017-11-29","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-11-28","2017-11-29","2017-11-28","2017-11-28","2018-02-18","2019-09-26","2017-11-28","2017-11-28","2017-11-28","2017-05-24","2017-11-28","2017-11-29","2017-11-29","2017-11-29","2017-08-29","2018-01-10","2018-01-10","2018-01-10","2018-01-10","2018-01-10","2018-01-11","2018-01-11","2018-01-12","2018-01-12","2018-01-12","2018-01-26","2018-01-24","2018-01-24","2018-01-24","2018-01-24","2018-01-24","2018-03-05","2018-04-20","2018-03-05","2018-03-05","2018-03-21","2018-03-21","2018-03-05","2018-03-06","2018-03-06","2018-03-06","2020-05-28","2018-03-06","2018-03-06","2018-03-07","2018-03-07","2018-03-07","2018-03-07","2018-03-07","2018-03-07","2018-03-07","2018-03-07","2018-03-08","2018-03-07","2018-03-15","2020-03-07","2018-03-06","2018-03-08","2018-03-07","2018-03-07","2018-03-15","2018-03-07","2018-03-03","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-08","2018-03-06","2023-06-19","2018-03-21","2018-03-08","2018-03-09","2018-03-28","2018-03-26","2018-03-26","2018-03-29","2018-03-28","2018-03-29","2018-05-08","2017-04-10","2018-04-12","2018-03-26","2018-04-13","2018-03-26","2018-05-02","2018-05-10","2018-05-16","2018-09-27","2023-06-19","2018-10-17","2018-06-04","2018-06-04","2018-06-06","2018-06-05","2018-06-05","2018-06-05","2018-06-06","2018-06-06","2018-06-06","2018-06-08","2018-06-06","2018-06-05","2018-06-05","2018-06-11","2018-06-11","2018-06-13","2018-06-13","2018-06-04","2018-06-27","2018-08-08","2018-08-13","2018-08-21","2018-08-22","2018-08-26","2018-08-30","2018-09-04","2018-09-10","2018-09-12","2018-12-07","2018-09-12","2018-09-15","2018-09-17","2018-09-17","2018-10-23","2018-09-17","2018-09-19","2018-10-23","2018-09-19","2018-09-17","2018-09-19","2018-09-19","2018-10-26","2018-09-19","2018-09-19","2018-09-19","2018-09-20","2018-11-09","2018-11-09","2018-09-20","2018-09-20","2018-09-20","2018-09-20","2018-10-03","2018-10-02","2018-10-02","2019-03-06","2019-03-06","2018-09-05","2018-10-15","2018-10-15","2018-10-15","2018-10-15","2018-10-17","2018-10-19","2018-10-18","2018-10-22","2018-10-22","2018-10-08","2018-10-18","2018-10-17","2018-10-17","2018-10-16","2018-10-25","2018-10-25","2018-10-25","2018-10-25","2018-10-25","2018-10-25","2018-10-25","2018-10-25","2018-10-25","2018-11-08","2018-10-25","2019-03-01","2018-10-25","2018-10-25","2018-11-15","2018-11-15","2018-11-15","2018-11-15","2018-12-05","2018-12-05","2018-12-05","2018-12-06","2018-12-06","2018-12-06","2018-12-06","2019-01-24","2019-01-24","2019-01-24","2019-02-14","2019-02-14","2019-02-13","2019-02-13","2019-02-14","2019-02-13","2019-02-13","2019-02-03","2019-02-19","2019-03-05","2019-03-05","2019-03-04","2019-03-01","2019-03-08","2019-03-28","2019-03-07","2019-03-07","2019-03-04","2019-03-06","2019-03-04","2019-03-06","2019-03-06","2019-03-04","2019-03-04","2019-03-06","2019-03-06","2019-03-04","2019-03-04","2019-03-04","2019-03-07","2019-03-07","2019-03-04","2019-03-06","2019-03-06","2019-03-06","2019-03-06","2019-03-06","2019-03-06","2019-03-06","2019-03-04","2019-03-05","2019-03-05","2019-03-05","2019-03-06","2019-03-06","2019-03-06","2019-03-04","2019-03-07","2019-03-07","2019-04-03","2019-04-03","2019-04-03","2019-03-08","2019-03-08","2019-03-08","2019-03-08","2019-03-05","2019-03-05","2019-03-07","2019-03-07","2019-03-07","2019-04-03","2019-03-07","2019-03-07","2019-03-04","2019-03-07","2019-03-07","2019-03-07","2019-03-07","2019-03-07","2019-03-07","2019-03-07","2019-03-07","2019-03-07","2019-03-03","2019-03-07","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-08","2019-03-05","2019-04-01","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-03-05","2019-04-04","2019-03-18","2019-04-02","2019-04-02","2019-04-24","2019-04-24","2019-04-24","2019-04-24","2019-04-25","2019-04-25","2019-03-04","2019-05-06","2019-05-06","2019-04-02","2019-04-02","2019-04-02","2019-04-02","2019-04-02","2019-04-01","2019-04-01","2019-04-01","2019-05-09","2019-05-07","2019-05-09","2019-05-15","2019-05-15","2019-05-05","2019-05-15","2019-05-08","2019-04-02","2019-04-02","2019-05-20","2019-05-20","2019-05-20","2019-05-15","2019-05-21","2019-03-07","2019-06-05","2019-03-07","2019-03-07","2019-06-12","2019-06-12","2019-06-12","2019-06-12","2019-06-12","2019-06-12","2019-06-12","2022-07-12","2023-02-14","2019-06-20","2019-06-24","2019-06-24","2019-07-02","2019-06-26","2019-06-06","2019-06-26","2019-07-11","2019-07-19","2019-07-24","2019-07-24","2019-07-26","2019-07-29","2019-08-26","2019-08-26","2019-08-28","2019-08-26","2019-08-26","2019-08-29","2019-09-18","2019-09-23","2019-09-23","2019-09-25","2019-09-25","2019-09-25","2019-09-25","2019-09-25","2019-09-23","2019-09-25","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-25","2019-09-25","2019-09-25","2019-09-25","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-25","2019-09-25","2019-09-23","2019-09-25","2019-09-25","2019-09-25","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-23","2019-09-26","2019-09-26","2019-09-23","2019-09-23","2019-09-27","2019-09-26","2019-09-26","2019-09-26","2019-09-26","2019-10-01","2019-10-02","2019-10-02","2019-10-02","2019-09-30","2019-09-30","2019-10-02","2019-10-01","2019-10-01","2019-10-01","2019-10-01","2019-10-01","2019-10-01","2019-09-26","2019-09-30","2019-11-11","2019-11-11","2019-11-11","2019-09-30","2019-09-30","2019-09-30","2019-09-30","2019-11-14","2019-11-04","2019-10-21","2019-10-10","2019-11-21","2019-11-21","2019-11-22","2019-11-02","2019-11-22","2019-11-21","2019-11-20","2019-11-21","2019-11-21","2019-11-21","2019-11-22","2019-11-22","2019-12-11","2019-12-05","2019-12-11","2020-01-29","2020-01-29","2020-02-02","2020-03-05","2020-03-04","2020-03-04","2020-03-04","2020-03-02","2020-03-02","2020-03-02","2020-03-04","2020-03-02","2020-03-03","2020-03-03","2020-03-05","2020-03-05","2020-03-05","2020-03-05","2020-03-05","2020-03-02","2020-03-02","2020-02-13","2023-04-28","2023-09-22","2020-09-02","2020-09-02","2020-10-24","2020-11-03","2020-11-13","2021-02-20","2021-02-25","2022-03-30","2022-03-30","2022-03-30","2022-03-30","2022-03-30","2022-03-30","2022-03-30","2022-03-30","2021-05-27","2021-05-27","2021-05-27","2021-05-27","2021-06-17","2021-06-21","2021-06-21","2021-06-25","2021-08-17","2019-11-02","2021-11-16","2021-12-06","2021-12-06","2021-12-06","2021-12-06","2021-02-16","2022-02-17","2022-02-22","2022-02-16","2022-02-15","2022-02-15","2022-02-15","2022-03-28","2022-03-28","2022-03-30","2022-03-30","2022-03-29","2022-03-28","2022-03-29","2022-03-29","2022-03-30","2022-03-30","2022-03-30","2022-03-29","2023-02-09","2022-03-29","2022-06-22","2022-06-22","2022-08-16","2022-09-29","2022-11-01","2022-11-01","2022-11-01","2022-11-01","2022-11-01","2022-11-22","2022-11-22","2022-12-09","2022-12-08","2022-12-08","2022-12-07","2022-12-09","2022-12-09","2022-12-06","2022-12-09","2022-12-13","2022-12-13","2022-12-07","2022-12-09","2022-12-09","2022-12-08","2022-12-13","2022-12-12","2022-12-07","2022-12-09","2022-12-08","2022-12-08","2022-12-07","2022-12-08","2023-08-17","2023-08-17","2023-08-17","2023-08-17","2023-08-18","2023-08-18","2023-08-18","2023-08-16","2023-08-16","2023-08-16","2023-08-16","2023-08-15","2023-08-15","2023-08-14","2023-08-11","2023-08-11","2023-08-11","2023-02-06","2023-07-07","2023-02-14","2023-08-07","2023-08-07","2023-08-07","2023-08-08","2023-08-08","2023-08-08","2023-08-08","2023-08-14","2023-08-07","2023-08-09","2023-08-16","2023-08-09","2023-05-15","2023-05-13","2023-05-16","2023-05-16","2023-06-08","2023-06-08","2023-06-08","2023-05-15","2023-05-15","2023-05-15","2023-05-15","2023-05-16","2023-05-16","2023-05-16","2023-05-16","2023-04-17","2023-02-17","2023-04-17","2023-05-17","2023-04-17","2023-04-17","2023-04-18","2023-04-19","2023-04-17","2023-04-18","2022-11-22","2022-12-08","2022-12-13","2022-12-13","2022-12-13","2022-12-07","2022-12-06","2022-12-06","2022-12-06","2022-12-06","2023-02-23","2023-02-23","2023-02-23","2023-02-23","2023-02-24","2023-02-24","2023-02-24","2023-02-24","2023-02-27","2023-05-04","2023-05-04","2023-05-04","2023-05-08","2023-05-08","2023-05-08","2023-05-09","2023-05-09","2023-05-09","2023-09-12","2023-09-12","2023-09-11","2023-09-11","2023-09-12","2023-09-12","2023-09-12","2023-09-12","2023-09-12","2023-09-12","2023-09-11","2023-09-11","2023-09-11","2023-09-13","2023-09-11","2023-09-13","2023-09-13","2023-09-13","2023-09-13","2023-09-11","2023-09-11","2023-09-11","2023-06-21","2023-09-25","2023-10-31","2023-10-31","2023-06-20","2023-06-20","2023-06-20","2023-06-20","2023-06-20","2023-06-20","2023-06-22","2023-06-23","2023-06-23","2023-06-23","2023-06-23","2023-06-22","2023-06-23","2024-02-29","2024-03-08","2024-03-08","2023-03-20","2023-05-15","2023-03-28","2024-07-16","2024-07-16","2024-07-22","2024-07-22","2024-07-24","2024-07-18","2024-07-16","2024-07-22","2017-05-03","2017-05-03","2018-04-13","2019-03-05","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2023-02-15","2017-05-03","2019-02-19","2017-05-03","2019-01-23","2017-05-03","2017-05-03","2019-11-13","2017-05-03","2017-05-03","2017-05-03","2017-11-27","2017-05-03","2017-05-03","2018-06-12","2017-05-03","2017-05-03","2024-10-08","2017-11-27","2022-07-13","2022-07-12","2022-07-12","2018-04-19","2022-07-12","2022-07-12","2019-10-25","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-05-22","2017-05-03","2017-05-03","2020-02-21","2017-11-28","2017-05-03","2017-05-03","2017-11-27","2017-11-27","2017-11-27","2018-02-26","2018-02-06","2018-02-06","2017-11-28","2018-03-06","2023-10-23","2017-11-28","2018-03-28","2017-11-28","2018-04-04","2017-11-28","2024-02-12","2019-04-25","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-11-28","2017-05-03","2017-05-03","2017-05-03","2018-04-20","2017-11-29","2018-04-03","2019-04-25","2018-02-19","2017-05-03","2017-05-03","2017-11-27","2017-11-27","2017-11-28","2017-11-27","2018-07-05","2018-03-21","2018-04-20","2018-04-20","2018-03-06","2018-04-20","2018-04-20","2018-04-20","2018-03-29","2018-03-27","2018-03-29","2017-12-04","2018-04-14","2018-04-23","2018-05-03","2022-07-12","2025-02-04","2025-02-04","2019-09-26","2024-10-09","2022-07-14","2025-02-06","2018-09-17","2018-09-18","2018-09-17","2019-01-18","2018-10-03","2018-10-09","2018-10-18","2018-10-19","2018-10-18","2018-10-16","2018-10-17","2018-10-17","2018-10-10","2018-10-25","2018-10-25","2018-12-06","2019-02-13","2019-03-06","2019-03-04","2019-03-04","2019-03-04","2019-03-04","2019-03-06","2019-03-06","2019-03-04","2019-03-06","2019-03-06","2019-03-04","2019-03-04","2019-03-05","2019-04-03","2019-03-08","2019-03-08","2019-03-05","2019-03-07","2019-03-07","2019-03-07","2019-03-04","2019-03-05","2019-03-05","2019-04-04","2019-04-11","2019-04-24","2019-04-25","2019-04-25","2019-04-25","2019-04-02","2019-04-02","2019-05-16","2019-05-22","2019-05-22","2019-05-22","2019-05-22","2019-04-02","2019-05-21","2024-10-07","2024-10-07","2025-02-05","2023-02-14","2023-02-15","2019-07-18","2019-07-19","2019-07-24","2019-07-24","2019-07-24","2019-07-26","2019-07-26","2019-07-29","2019-05-20","2019-08-26","2019-08-26","2019-09-23","2019-09-23","2023-02-16","2023-02-16","2019-09-23","2019-09-26","2023-02-15","2023-02-16","2019-09-30","2019-09-30","2019-10-01","2019-11-20","2019-12-11","2019-12-11","2019-12-11","2019-12-11","2019-12-11","2019-12-12","2019-12-11","2019-12-11","2019-12-11","2019-12-11","2019-12-18","2019-12-18","2019-12-18","2019-12-18","2019-12-18","2020-01-22","2020-01-22","2020-01-22","2020-01-23","2020-01-27","2020-01-19","2020-01-29","2020-01-17","2020-01-31","2020-01-29","2020-02-05","2020-06-03","2020-02-11","2020-03-04","2020-03-04","2020-03-04","2020-03-04","2020-03-04","2020-03-04","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-06","2020-03-04","2020-03-04","2020-03-04","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-04","2020-03-04","2020-03-05","2020-03-04","2020-03-04","2020-03-04","2020-03-05","2020-03-05","2020-03-05","2020-03-05","2020-03-04","2020-03-05","2020-03-05","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-03","2020-03-03","2020-03-03","2020-03-03","2020-03-03","2020-03-02","2020-03-03","2020-03-03","2020-03-03","2020-03-03","2020-03-03","2020-03-03","2020-03-03","2020-03-02","2020-03-03","2020-03-03","2020-03-02","2020-03-03","2020-03-02","2019-09-27","2020-03-03","2020-03-03","2020-03-05","2020-03-05","2020-03-05","2020-03-05","2020-03-05","2020-03-03","2020-03-02","2020-03-05","2020-03-05","2020-03-02","2020-03-05","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-02","2020-03-05","2020-03-03","2020-02-13","2020-02-12","2019-12-11","2020-11-06","2020-10-26","2020-10-24","2020-10-24","2020-11-02","2020-11-13","2021-02-19","2021-04-15","2021-08-02","2021-08-17","2024-02-15","2021-10-05","2021-10-28","2021-12-06","2021-12-06","2021-12-06","2022-02-17","2022-02-16","2022-03-01","2022-03-17","2022-03-29","2022-03-29","2022-03-30","2025-02-06","2022-03-28","2022-03-28","2022-03-28","2022-03-29","2022-03-28","2022-03-29","2022-03-30","2022-03-30","2022-03-30","2022-03-30","2022-03-31","2023-10-23","2022-09-20","2022-09-20","2022-10-26","2022-11-01","2022-12-08","2022-12-07","2022-12-07","2022-12-08","2022-12-06","2022-12-06","2022-12-13","2022-12-07","2023-06-21","2023-06-19","2023-06-19","2023-06-19","2023-06-13","2023-06-22","2023-08-11","2023-08-09","2023-08-09","2023-05-09","2023-04-19","2022-11-22","2022-12-13","2023-03-27","2023-05-09","2023-03-15","2023-03-13","2023-03-16","2023-03-13","2023-03-13","2023-03-16","2023-03-17","2023-03-15","2023-03-15","2023-03-15","2023-10-23","2023-10-23","2023-11-30","2023-10-23","2023-10-23","2023-10-24","2023-10-23","2023-10-23","2024-03-21","2024-03-20","2024-03-18","2024-03-18","2024-03-18","2024-03-18","2024-03-22","2024-04-17","2024-04-17","2024-04-16","2024-04-17","2024-04-16","2024-04-16","2024-04-16","2024-04-16","2024-04-16","2024-04-14","2024-04-16","2023-02-15","2024-03-11","2023-02-15","2023-02-15","2024-06-10","2024-06-10","2024-06-11","2024-06-11","2024-06-12","2024-06-12","2024-06-13","2024-06-12","2024-06-12","2024-06-12","2024-06-27","2024-06-10","2024-06-14","2024-06-11","2023-09-29","2023-08-01","2023-07-31","2024-07-16","2024-07-22","2024-08-21","2024-07-23","2024-07-23","2024-07-23","2024-07-23","2024-07-23","2024-07-24","2024-06-10","2024-07-23","2024-07-23","2024-08-21","2024-09-17","2023-10-24","2024-09-04","2024-09-04","2024-09-04","2024-08-21","2024-08-21","2024-09-04","2024-06-14","2023-02-16","2023-02-15","2023-10-24","2024-10-14","2024-10-07","2024-10-07","2024-10-07","2024-10-07","2024-10-07","2024-10-08","2024-10-08","2024-10-08","2024-10-08","2024-10-09","2024-10-09","2024-10-09","2024-10-07","2024-10-09","2024-10-09","2024-10-10","2024-10-10","2024-10-10","2024-10-10","2024-10-07","2024-10-10","2024-10-10","2024-10-11","2024-10-11","2024-10-01","2024-10-11","2024-10-23","2024-10-23","2024-10-23","2024-10-24","2024-10-22","2024-10-22","2024-10-22","2024-10-22","2024-11-11","2024-10-22","2024-10-22","2024-11-05","2024-11-07","2024-11-06","2024-11-06","2024-11-02","2024-11-02","2024-10-22","2024-11-03","2024-10-25","2024-11-02","2024-11-13","2024-10-23","2024-11-14","2024-11-18","2024-11-18","2024-11-12","2024-10-23","2024-11-13","2024-11-20","2024-11-13","2024-11-20","2024-11-20","2024-11-20","2024-11-14","2024-11-20","2024-11-20","2024-11-19","2024-11-19","2024-11-02","2024-11-02","2024-11-19","2024-11-19","2024-11-14","2024-11-20","2024-11-19","2024-11-18","2024-11-18","2024-11-20","2024-11-19","2024-11-13","2024-11-22","2024-11-13","2024-10-23","2024-10-23","2024-10-23","2024-10-24","2024-10-24","2024-10-24","2024-10-23","2024-10-24","2024-10-10","2024-10-22","2024-10-22","2024-11-18","2024-11-18","2024-11-18","2024-11-19","2024-11-19","2024-11-19","2024-11-19","2024-11-20","2024-11-20","2024-11-18","2024-11-18","2024-11-18","2024-11-18","2024-11-18","2024-11-18","2022-11-22","2022-11-22","2025-01-15","2025-01-14","2025-01-13","2025-01-13","2025-01-14","2025-01-15","2025-01-13","2025-01-16","2025-01-16","2025-01-16","2025-01-16","2025-01-16","2025-01-16","2025-01-22","2025-01-16","2025-01-16","2025-01-23","2025-01-23","2025-01-16","2025-02-03","2025-02-03","2025-02-05","2025-02-12","2025-02-13","2025-02-13","2025-02-13","2025-02-13","2025-02-24","2024-07-19","2025-03-10","2025-03-10","2024-08-07","2024-08-16","2024-08-18","2024-08-18","2025-03-11","2025-03-11","2025-03-11","2025-03-12","2024-08-19","2025-03-12","2025-03-12","2025-03-12","2024-10-26","2024-08-10","2024-08-15","2024-08-16","2025-03-13","2025-02-14","2024-10-04","2025-03-01","2024-11-12","2024-09-26","2024-10-02","2025-02-22","2025-03-13","2025-03-26","2025-03-06","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-28","2025-03-28","2025-03-28","2025-03-28","2025-03-26","2025-03-28","2025-04-01","2025-04-01","2025-04-01","2025-04-01","2025-04-01","2025-04-01","2025-04-07","2025-04-07","2025-04-07","2025-04-07","2025-03-12","2025-03-11","2025-03-13","2025-03-13","2025-03-13","2025-03-11","2025-02-11","2025-02-11","2025-02-18","2025-03-13","2025-03-12","2025-03-12","2025-03-11","2025-04-21","2025-04-21","2025-04-22","2025-04-22","2025-04-22","2025-03-13","2025-03-12","2025-04-24","2025-04-25","2025-04-25","2025-04-25","2025-04-25","2025-04-29","2025-04-29","2025-04-29","2025-04-30","2025-05-06","2025-05-08","2025-05-08","2025-05-08","2025-05-08","2025-01-30"],["2023-10-24","2024-10-08","2022-01-05","2025-02-24","2025-02-05","2023-01-31","2023-02-28","2024-02-13","2020-09-17","2025-02-03","2022-09-08","2020-09-17","2021-03-12","2023-02-15","2024-10-08","2022-07-13","2023-10-24","2023-04-19","2024-09-19","2025-02-05","2024-10-23","2024-10-07","2023-01-20","2023-01-20","2025-02-05","2024-02-13","2023-01-05","2025-02-04","2024-02-14","2024-02-14","2025-02-04","2025-02-04","2023-10-24","2021-02-18","2025-02-05","2025-02-05","2025-02-05","2025-03-21","2024-03-20","2021-02-18","2022-07-13","2022-07-13","2021-01-14","2021-01-20","2020-09-15","2025-04-08","2021-03-12","2021-01-20","2021-03-12","2021-03-12","2020-09-18","2023-02-15","2023-02-15","2023-02-15","2023-02-15","2025-02-26","2020-05-26","2020-02-21","2021-03-12","2021-03-12","2024-08-26","2023-10-25","2022-07-13","2023-06-23","2024-10-09","2021-03-12","2021-03-12","2020-05-19","2023-10-24","2021-03-12","2021-03-12","2021-03-05","2021-01-14","2020-05-19","2021-02-18","2021-03-12","2023-10-24","2021-03-12","2024-02-14","2020-05-22","2021-03-15","2024-11-11","2023-06-20","2021-03-15","2024-11-11","2021-03-15","2021-03-09","2020-05-18","2021-03-15","2021-03-15","2023-04-27","2023-10-25","2022-06-13","2023-10-14","2023-10-14","2023-12-07","2024-04-18","2021-03-15","2024-02-13","2021-03-15","2025-02-03","2024-10-09","2023-01-19","2023-01-19","2023-02-16","2024-02-13","2022-04-26","2023-10-23","2021-03-11","2025-02-05","2023-02-15","2023-06-19","2025-02-04","2022-03-03","2022-03-24","2021-03-09","2023-04-20","2023-04-28","2024-08-14","2024-02-15","2024-02-13","2024-03-13","2023-01-19","2024-02-13","2024-02-15","2024-02-15","2024-02-15","2020-05-07","2020-02-21","2020-06-30","2021-02-18","2019-10-29","2021-01-14","2021-01-14","2021-02-18","2020-07-17","2024-05-20","2021-01-20","2021-01-20","2024-02-12","2021-01-20","2020-06-17","2020-09-15","2020-09-15","2020-09-18","2021-03-12","2020-05-20","2021-02-09","2020-09-18","2023-02-15","2023-02-15","2020-06-01","2019-03-08","2020-06-17","2020-06-04","2020-06-18","2020-02-21","2020-07-28","2020-02-21","2022-07-12","2022-07-12","2020-06-17","2020-09-16","2020-09-16","2020-06-30","2020-04-27","2021-01-20","2020-05-21","2021-02-09","2020-06-29","2020-06-08","2020-05-04","2019-10-06","2020-06-05","2020-07-21","2020-07-16","2020-07-14","2020-05-18","2020-06-11","2020-07-28","2022-01-11","2020-07-24","2024-10-09","2019-04-04","2019-04-04","2020-07-16","2024-10-09","2020-01-22","2020-06-11","2020-06-30","2020-05-21","2020-05-22","2020-05-26","2020-05-26","2020-05-20","2021-03-12","2019-09-24","2021-03-12","2023-05-04","2020-05-12","2021-03-12","2020-05-20","2021-02-18","2020-02-21","2020-06-01","2021-01-14","2021-01-14","2021-02-18","2021-01-14","2021-02-18","2021-02-18","2021-02-18","2020-07-14","2020-09-11","2020-04-30","2025-02-03","2021-01-14","2022-11-03","2021-03-12","2020-01-21","2020-07-14","2023-10-23","2025-02-05","2022-09-07","2020-07-14","2023-11-16","2020-05-18","2020-01-13","2020-06-02","2024-02-12","2019-08-27","2023-10-25","2020-05-21","2024-10-07","2022-03-24","2019-06-28","2020-05-20","2020-05-12","2020-04-30","2020-05-22","2020-09-15","2022-06-02","2020-06-05","2024-05-20","2020-05-26","2021-03-15","2020-05-26","2020-06-15","2021-03-15","2024-09-19","2024-08-27","2024-08-27","2021-03-15","2020-09-15","2025-02-04","2021-03-15","2022-02-21","2020-06-15","2020-05-29","2020-05-20","2023-01-05","2020-06-11","2025-02-19","2020-02-27","2023-10-23","2020-02-27","2020-02-21","2023-04-25","2023-04-25","2023-04-25","2023-04-25","2021-03-12","2023-04-25","2023-04-24","2020-05-25","2022-03-24","2022-10-13","2021-03-15","2020-07-16","2020-05-18","2021-11-15","2022-04-21","2021-11-16","2022-03-24","2021-11-15","2022-01-09","2022-02-23","2024-11-14","2024-11-14","2022-02-07","2020-10-09","2022-02-23","2021-11-16","2021-03-15","2020-01-21","2020-06-09","2022-05-27","2020-01-13","2024-02-15","2022-07-14","2025-02-06","2024-10-09","2023-06-21","2021-10-20","2020-12-08","2024-02-12","2023-02-14","2020-06-26","2024-02-12","2023-04-13","2020-06-01","2023-02-14","2023-06-22","2023-06-21","2024-04-18","2022-01-13","2023-10-25","2024-04-15","2019-08-16","2024-04-15","2024-04-15","2024-04-15","2024-04-15","2023-10-24","2021-03-15","2024-04-17","2021-03-15","2024-04-18","2024-04-27","2023-10-23","2021-03-15","2023-02-14","2021-03-15","2021-03-15","2021-03-11","2021-03-11","2021-03-11","2021-03-11","2021-03-11","2021-02-08","2020-05-19","2020-09-11","2021-03-11","2021-03-11","2021-03-11","2020-05-18","2025-02-05","2021-03-11","2020-06-11","2020-09-15","2023-06-19","2022-02-11","2020-06-15","2023-05-08","2021-10-11","2021-12-15","2022-02-10","2023-02-16","2023-02-16","2022-03-29","2023-10-24","2020-06-05","2023-02-16","2023-02-16","2022-11-02","2022-02-17","2023-01-19","2024-02-20","2023-12-07","2023-12-07","2023-04-28","2023-01-19","2022-11-03","2023-05-01","2023-02-16","2023-01-20","2025-01-09","2023-04-20","2023-12-01","2024-02-12","2023-02-28","2023-03-19","2023-04-28","2023-05-01","2023-01-19","2023-05-17","2024-02-13","2023-01-31","2023-04-20","2023-01-19","2023-01-20","2024-02-15","2023-04-27","2024-08-14","2025-01-22","2025-01-08","2025-01-08","2025-01-06","2025-01-07","2024-08-14","2020-07-17","2020-05-26","2018-09-14","2022-02-02","2020-09-18","2020-05-20","2020-09-18","2020-09-15","2021-01-20","2020-06-15","2020-05-07","2020-01-22","2019-06-28","2020-05-26","2018-06-21","2020-06-01","2020-05-29","2018-06-28","2018-06-07","2018-07-18","2021-01-14","2020-05-26","2018-09-14","2021-01-14","2020-09-17","2020-09-18","2018-05-24","2020-09-15","2018-07-19","2020-07-16","2022-02-02","2020-05-01","2020-04-06","2020-05-18","2019-07-30","2025-02-05","2020-05-20","2018-06-13","2018-06-14","2020-05-12","2024-10-08","2018-07-11","2021-03-12","2025-02-03","2022-02-02","2022-02-02","2022-02-02","2020-09-11","2022-02-02","2022-02-02","2022-02-02","2022-02-02","2019-04-04","2018-06-14","2018-06-29","2022-02-02","2020-05-20","2019-02-04","2019-02-06","2020-07-14","2020-05-26","2020-05-21","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-19","2020-05-12","2020-05-29","2020-05-15","2018-04-04","2020-05-12","2020-05-18","2019-04-05","2019-05-07","2019-04-02","2018-07-19","2022-02-02","2018-07-12","2020-04-06","2019-10-29","2020-01-21","2021-03-12","2018-11-28","2019-05-08","2020-05-20","2020-06-30","2018-07-11","2020-09-15","2019-12-17","2018-07-27","2020-06-01","2020-05-20","2020-05-26","2020-07-16","2019-08-27","2018-07-11","2020-01-14","2020-05-20","2019-08-15","2019-08-29","2022-02-02","2022-02-02","2019-04-02","2020-05-20","2020-06-30","2023-10-23","2019-06-26","2019-08-23","2020-05-12","2020-09-11","2020-05-12","2020-02-27","2022-02-02","2021-01-14","2020-05-12","2020-05-12","2020-06-11","2022-02-02","2019-09-24","2018-07-12","2023-06-21","2023-12-08","2020-05-05","2018-07-11","2020-01-13","2019-10-31","2020-05-22","2020-05-20","2020-06-05","2020-05-12","2020-05-12","2020-09-12","2020-09-16","2020-05-21","2020-05-20","2020-01-21","2018-04-04","2020-06-05","2020-09-15","2020-09-15","2019-09-26","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-20","2020-05-12","2020-05-12","2020-05-12","2020-05-28","2018-07-12","2018-07-12","2020-05-20","2020-05-18","2020-09-15","2020-05-12","2020-06-15","2020-05-20","2020-05-12","2020-09-15","2020-09-11","2020-05-18","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-20","2020-05-28","2020-05-12","2020-05-12","2020-05-20","2020-05-12","2020-05-16","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-09-11","2020-05-20","2020-05-12","2020-05-12","2020-05-12","2020-05-05","2022-02-02","2020-05-12","2020-05-12","2020-05-22","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-05-20","2020-05-12","2020-05-12","2020-05-12","2020-05-24","2020-09-11","2021-03-15","2018-07-30","2018-07-30","2020-05-12","2021-03-15","2020-05-12","2018-07-11","2018-07-11","2020-05-12","2020-02-28","2020-09-15","2020-09-15","2020-05-12","2020-09-15","2018-04-20","2020-05-05","2020-05-12","2020-05-05","2020-05-20","2020-05-12","2020-07-20","2020-05-12","2020-05-12","2020-05-12","2020-05-12","2020-09-11","2020-05-12","2020-05-12","2020-09-15","2020-06-02","2020-09-15","2020-06-04","2020-05-28","2020-05-22","2020-06-15","2020-05-12","2020-05-12","2020-06-02","2020-05-06","2020-06-02","2020-05-20","2022-06-28","2020-07-13","2020-05-29","2020-05-12","2020-05-16","2020-05-16","2020-10-02","2020-05-16","2020-05-18","2020-06-29","2020-06-11","2020-07-06","2020-06-01","2020-07-14","2022-02-10","2020-05-20","2020-06-29","2020-05-20","2020-07-14","2020-06-10","2020-05-07","2020-04-27","2020-05-19","2020-05-29","2020-06-02","2020-05-24","2020-05-20","2020-07-13","2020-02-21","2020-07-13","2020-05-16","2020-05-29","2020-05-18","2020-05-19","2020-05-29","2020-07-13","2020-05-18","2020-05-20","2020-07-13","2020-02-21","2020-05-01","2020-09-15","2020-05-16","2025-02-04","2023-06-19","2020-09-15","2020-02-21","2021-03-15","2020-09-15","2022-05-26","2022-03-31","2022-06-28","2024-10-09","2020-05-12","2018-06-28","2021-03-15","2019-03-26","2021-03-15","2020-05-20","2020-09-15","2020-07-14","2020-05-07","2019-08-16","2025-02-04","2020-06-02","2019-08-29","2019-09-03","2020-06-02","2020-05-21","2020-05-18","2020-05-27","2020-07-21","2020-05-18","2020-05-16","2021-02-18","2020-05-29","2020-05-20","2020-06-01","2020-06-11","2020-07-13","2020-05-22","2020-07-15","2020-07-16","2020-05-22","2020-01-14","2019-08-27","2023-06-21","2019-08-16","2019-08-15","2019-08-13","2020-05-20","2019-08-28","2019-09-06","2019-08-27","2019-09-11","2019-08-29","2020-05-05","2020-04-30","2019-08-16","2020-06-11","2019-06-10","2023-02-14","2023-02-15","2020-06-15","2019-09-27","2019-09-27","2019-08-27","2020-06-01","2019-08-27","2019-09-03","2019-09-05","2019-09-05","2019-09-09","2019-08-16","2019-09-09","2019-08-15","2019-09-11","2020-04-28","2019-09-18","2019-09-05","2023-02-14","2023-02-14","2019-08-28","2019-08-08","2019-09-11","2019-08-15","2020-06-18","2023-06-20","2019-09-18","2019-09-06","2019-09-18","2019-09-24","2019-09-18","2019-10-23","2019-08-27","2020-01-22","2021-03-15","2019-09-03","2020-05-12","2019-07-23","2019-09-09","2024-04-15","2020-05-22","2019-09-09","2019-09-18","2020-05-19","2020-07-16","2020-05-12","2020-05-25","2019-09-17","2020-09-15","2020-05-22","2019-09-03","2019-08-15","2020-06-11","2020-06-11","2019-09-24","2019-09-17","2019-09-11","2019-08-27","2019-09-24","2019-09-18","2019-09-24","2019-08-23","2019-08-29","2020-01-13","2020-05-01","2020-06-17","2020-07-15","2024-04-18","2019-09-09","2020-05-22","2020-06-11","2020-05-05","2020-07-28","2020-05-01","2020-05-01","2021-02-01","2021-03-11","2020-02-21","2021-03-11","2025-02-03","2020-05-22","2020-05-25","2020-05-22","2020-05-19","2020-05-21","2020-05-21","2020-01-13","2020-05-05","2020-06-11","2020-01-13","2020-05-22","2020-05-22","2020-07-28","2020-06-17","2020-05-27","2020-02-21","2020-06-07","2020-05-21","2020-05-26","2020-05-21","2020-05-05","2020-05-20","2020-05-21","2020-05-21","2020-05-21","2020-06-18","2020-01-14","2020-06-06","2020-06-01","2020-05-05","2020-06-05","2020-05-05","2020-06-11","2020-05-19","2021-02-25","2020-05-06","2020-05-20","2020-05-05","2020-07-20","2020-07-20","2020-05-19","2020-05-21","2020-05-21","2020-06-11","2020-06-11","2020-05-05","2020-04-29","2020-05-19","2020-05-18","2020-06-15","2020-05-18","2020-05-18","2020-05-21","2020-05-21","2020-05-21","2020-07-15","2019-10-23","2020-05-26","2023-02-15","2020-05-01","2020-05-19","2020-06-30","2020-05-05","2020-05-21","2020-05-05","2020-05-21","2020-05-18","2020-05-21","2020-05-22","2020-05-21","2020-05-21","2020-06-30","2020-05-21","2020-06-11","2020-05-12","2020-05-24","2020-05-25","2020-05-25","2020-06-17","2020-02-21","2020-05-26","2020-05-01","2020-05-21","2020-05-05","2020-05-05","2020-02-21","2020-05-19","2020-04-28","2020-05-26","2020-09-15","2019-10-30","2019-12-17","2020-01-13","2020-06-05","2020-05-22","2020-05-05","2020-04-28","2020-05-21","2020-05-22","2020-05-20","2020-06-30","2020-01-13","2020-07-28","2020-06-05","2020-06-05","2020-05-05","2020-05-05","2020-01-21","2020-06-05","2020-05-18","2020-07-15","2020-05-05","2020-05-03","2020-06-15","2020-07-14","2020-07-15","2020-06-11","2020-05-22","2020-05-18","2020-05-18","2020-01-13","2020-01-13","2020-05-18","2020-01-21","2020-02-21","2020-02-21","2020-05-18","2020-05-18","2020-04-28","2023-01-20","2024-02-14","2020-05-29","2020-05-22","2020-07-14","2020-05-18","2020-06-30","2020-05-22","2020-05-25","2020-05-08","2020-05-19","2020-06-15","2020-07-15","2020-07-15","2020-09-15","2020-06-15","2020-06-09","2020-06-06","2020-07-16","2020-07-28","2020-07-20","2020-06-29","2020-06-05","2020-06-09","2020-04-28","2020-04-29","2020-04-29","2020-06-15","2020-05-22","2020-05-21","2020-06-15","2020-07-14","2020-07-17","2020-05-20","2020-07-14","2020-07-14","2020-07-14","2020-04-30","2020-05-08","2020-05-19","2020-07-15","2020-05-26","2020-05-22","2020-05-07","2020-05-20","2020-05-20","2020-06-04","2020-07-17","2020-07-14","2020-07-20","2020-06-29","2020-07-28","2020-05-22","2020-07-28","2020-07-14","2020-05-06","2020-06-06","2020-05-25","2020-06-02","2020-06-04","2020-06-11","2020-07-15","2020-06-15","2020-06-01","2020-07-27","2020-06-15","2020-07-27","2020-06-07","2020-07-16","2020-05-20","2020-04-28","2020-05-20","2020-06-30","2020-07-16","2020-06-18","2020-05-18","2020-07-20","2020-07-15","2020-06-30","2020-06-18","2020-07-20","2021-03-09","2020-05-22","2022-01-10","2020-05-22","2020-06-29","2020-04-28","2020-05-22","2020-07-15","2020-07-16","2020-05-19","2020-06-15","2020-06-11","2020-07-16","2020-05-25","2020-05-25","2020-05-22","2020-05-25","2020-05-25","2020-06-15","2020-07-15","2020-07-16","2020-05-21","2020-05-21","2020-05-29","2020-06-17","2020-06-15","2021-03-09","2024-02-20","2020-10-09","2020-10-09","2021-03-09","2021-03-12","2021-12-20","2021-12-20","2021-12-20","2022-03-29","2022-03-31","2022-09-07","2021-11-17","2022-03-02","2024-02-20","2021-03-03","2021-11-16","2022-09-09","2022-01-03","2022-01-28","2022-03-28","2023-01-05","2023-01-05","2020-09-18","2024-08-14","2024-08-14","2022-02-23","2022-02-10","2022-03-24","2022-03-24","2022-03-24","2021-12-18","2023-08-10","2023-02-16","2024-02-15","2023-08-24","2023-05-18","2023-04-24","2023-08-24","2023-04-20","2023-08-24","2021-12-18","2022-01-18","2021-12-18","2021-12-17","2021-12-17","2022-02-10","2022-02-10","2022-01-17","2022-04-21","2021-12-15","2024-10-08","2023-05-05","2023-05-06","2022-09-06","2022-09-06","2023-05-05","2023-05-05","2023-05-05","2023-05-05","2023-05-06","2023-05-06","2023-04-04","2025-02-06","2025-02-06","2025-02-06","2025-02-06","2025-02-06","2025-02-06","2025-02-06","2025-02-06","2025-03-21","2025-02-06","2025-02-06","2023-11-13","2023-10-23","2023-10-23","2025-01-21","2025-01-21","2025-01-22","2025-01-22","2023-05-18","2023-05-07","2025-01-09","2023-05-18","2023-05-07","2025-01-22","2025-01-21","2025-01-22","2023-12-01","2024-01-06","2025-01-06","2025-01-21","2025-01-06","2025-01-08","2025-01-21","2023-12-01","2025-01-09","2023-12-07","2023-12-07","2025-01-06","2025-01-06","2023-12-01","2025-01-09","2025-01-09","2025-01-09","2025-01-09","2025-01-06","2025-01-06","2025-01-08","2025-01-06","2025-01-21","2025-01-06","2025-01-07","2025-01-22","2025-01-06","2025-01-06","2025-01-08","2025-01-09","2025-01-09","2025-01-22","2025-01-06","2025-01-08","2025-01-06","2025-01-08","2025-01-08","2025-01-08","2025-01-07","2025-01-08","2025-01-07","2025-01-07","2025-01-22","2025-01-06","2025-01-22","2025-01-21","2025-01-22","2025-01-06","2025-01-06","2025-01-07","2025-01-07","2025-01-09","2025-01-06","2025-01-08","2025-01-06","2025-01-07","2025-01-09","2025-01-06","2025-01-07","2025-01-22","2025-01-06","2025-01-06","2025-01-07","2025-01-06","2025-01-07","2025-01-22","2025-01-21","2025-01-07","2025-01-22","2025-01-08","2025-01-21","2025-01-07","2025-01-06","2025-01-08","2025-01-08","2025-01-09","2025-01-09","2025-01-22","2025-01-21","2025-01-21","2025-01-22","2025-01-22","2025-01-21","2025-01-22","2025-01-09","2025-01-09","2025-01-21","2025-01-21","2025-01-08","2025-01-08","2025-01-08","2025-01-21","2025-01-22","2025-01-07","2025-01-09","2025-01-07","2025-01-06","2025-01-08","2025-01-22","2025-01-08","2025-01-07","2025-01-08","2025-01-06","2025-01-08","2025-01-08","2025-01-07","2025-01-09","2025-01-09","2025-01-09","2025-01-07","2025-01-07","2025-01-09","2025-01-06","2025-01-06","2025-01-06","2025-01-21","2025-01-08","2025-01-06","2025-01-09","2025-01-21","2025-01-21","2025-01-09","2025-01-06","2025-01-09","2024-09-13","2025-01-08","2025-01-07","2025-01-09","2024-08-14","2025-01-08","2025-01-08","2025-01-09","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2024-08-14","2025-01-22","2025-01-07","2025-01-09","2024-03-20","2024-04-16","2025-01-22","2025-01-22","2025-01-22","2025-01-22","2025-01-22","2025-05-01","2025-01-22","2025-01-22","2025-01-22","2017-05-03","2017-05-03","2018-06-14","2019-06-13","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2023-02-15","2017-05-03","2019-07-30","2017-09-27","2019-07-30","2017-05-03","2017-05-03","2020-02-04","2017-05-03","2017-05-03","2017-05-03","2017-11-27","2017-05-03","2017-05-03","2018-06-14","2017-05-03","2017-05-03","2024-10-08","2018-06-21","2022-07-13","2022-07-13","2022-07-12","2018-05-31","2022-07-12","2022-07-12","2020-02-21","2017-05-03","2018-06-20","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2017-05-03","2019-08-01","2018-10-02","2017-05-03","2020-02-21","2017-11-28","2017-05-03","2017-05-03","2018-05-23","2018-10-02","2018-07-18","2018-07-30","2018-07-30","2018-07-12","2017-11-28","2018-07-18","2023-10-23","2018-07-18","2018-07-18","2018-07-18","2018-07-18","2018-07-30","2024-02-14","2019-09-05","2017-05-03","2017-08-23","2017-05-03","2017-05-03","2017-09-15","2017-05-03","2017-11-28","2017-05-03","2017-05-03","2017-05-03","2018-04-20","2017-11-29","2018-07-11","2019-09-06","2018-04-04","2017-05-03","2017-05-03","2017-11-27","2018-06-20","2018-07-11","2017-11-27","2018-07-30","2018-06-01","2018-04-20","2018-04-20","2018-03-06","2018-04-20","2018-04-20","2018-04-20","2018-07-30","2018-05-30","2018-05-30","2018-07-05","2018-06-14","2018-04-23","2018-07-11","2022-07-12","2025-02-04","2025-02-04","2020-01-13","2024-10-09","2022-07-14","2025-03-06","2018-09-17","2018-09-26","2019-01-13","2019-08-14","2018-10-03","2018-11-07","2018-10-24","2018-10-19","2018-10-24","2018-10-24","2018-11-13","2018-11-13","2018-11-28","2018-10-25","2018-10-25","2018-12-06","2019-06-03","2019-07-30","2019-08-27","2019-07-29","2019-05-17","2019-07-29","2019-07-30","2019-08-23","2019-07-31","2019-06-28","2019-07-23","2019-06-28","2019-07-09","2019-06-26","2019-06-28","2019-07-11","2019-07-11","2019-03-08","2019-08-19","2019-03-07","2019-03-07","2019-06-26","2019-03-05","2019-03-05","2019-08-23","2019-09-11","2019-09-03","2019-09-06","2019-07-11","2019-09-06","2019-08-29","2019-07-11","2019-08-29","2019-05-30","2019-05-30","2019-05-30","2019-05-30","2019-04-02","2019-08-14","2024-10-07","2024-11-07","2025-02-05","2023-02-14","2023-02-15","2020-01-14","2019-08-28","2019-09-05","2020-01-21","2019-08-29","2019-09-03","2019-09-05","2020-01-21","2020-01-22","2020-01-22","2019-09-06","2019-09-23","2020-04-01","2023-02-16","2023-02-16","2019-09-23","2020-01-13","2023-02-15","2023-02-16","2020-04-28","2020-01-14","2020-04-28","2020-05-21","2020-06-06","2020-05-22","2020-05-22","2020-05-21","2020-06-09","2020-06-06","2020-05-21","2020-05-21","2020-05-25","2020-05-20","2020-06-11","2020-05-26","2020-05-26","2020-06-17","2020-05-26","2020-06-11","2020-04-28","2020-04-28","2020-04-28","2020-04-28","2020-05-08","2020-05-18","2020-05-05","2020-05-19","2020-05-19","2020-04-28","2020-07-17","2020-05-07","2020-05-27","2020-05-29","2020-09-17","2020-05-14","2020-05-29","2020-05-27","2020-09-17","2020-05-27","2020-07-16","2020-05-23","2020-06-02","2020-09-17","2020-05-23","2020-07-16","2020-05-15","2020-09-16","2020-06-06","2020-09-17","2020-05-24","2020-09-17","2020-07-16","2020-05-26","2020-09-18","2020-05-26","2020-06-04","2020-05-27","2020-09-17","2020-05-27","2020-06-01","2020-05-27","2020-05-16","2020-07-17","2020-03-05","2020-09-17","2020-05-29","2020-05-24","2020-05-20","2020-03-02","2020-05-20","2020-06-04","2020-05-18","2020-09-17","2020-09-18","2020-09-17","2020-05-19","2020-05-18","2020-09-17","2020-06-02","2020-05-18","2020-09-17","2020-09-18","2020-05-20","2020-05-18","2020-05-20","2020-05-19","2020-09-17","2020-09-17","2020-05-18","2020-05-27","2020-05-24","2020-09-17","2020-09-17","2020-05-29","2020-05-18","2020-05-26","2020-09-17","2020-09-17","2020-09-17","2020-05-16","2020-09-17","2020-05-29","2020-07-16","2020-03-03","2020-05-26","2020-05-15","2020-07-17","2020-09-18","2020-07-24","2020-06-08","2020-09-18","2020-07-16","2020-06-05","2020-09-18","2020-06-08","2020-09-18","2020-05-27","2020-06-05","2020-06-01","2020-09-17","2020-05-18","2020-04-28","2020-05-05","2020-05-20","2021-02-24","2021-02-24","2021-02-24","2020-10-24","2021-02-24","2021-02-24","2021-02-19","2021-08-18","2022-01-13","2022-02-10","2024-02-15","2021-12-15","2022-01-11","2022-01-09","2022-05-09","2022-05-04","2022-02-17","2022-02-16","2022-03-01","2022-06-15","2022-05-25","2022-05-27","2022-05-27","2025-02-06","2022-05-27","2022-05-27","2022-05-27","2022-05-27","2022-05-20","2022-05-27","2022-05-25","2022-06-02","2022-05-20","2022-05-23","2022-05-27","2023-10-23","2022-09-20","2022-09-20","2022-10-26","2023-03-03","2023-05-09","2023-05-09","2023-05-07","2023-05-07","2023-05-07","2023-05-07","2023-05-07","2023-05-07","2023-06-21","2023-06-19","2023-06-19","2023-06-19","2023-06-20","2023-06-22","2023-08-11","2023-08-09","2023-08-09","2023-05-09","2023-04-19","2022-11-22","2022-12-13","2023-03-27","2023-05-09","2023-03-15","2023-03-13","2023-03-16","2023-03-13","2023-03-13","2023-03-16","2023-03-17","2023-03-15","2023-03-15","2023-03-15","2023-10-23","2023-10-23","2023-11-30","2023-10-23","2023-10-23","2023-10-24","2023-10-23","2023-10-25","2024-03-21","2024-03-20","2024-03-18","2024-03-18","2024-03-18","2024-03-18","2024-03-22","2024-04-17","2024-04-17","2024-04-16","2024-04-17","2024-04-16","2024-04-16","2024-04-16","2024-04-16","2024-04-16","2024-04-16","2024-04-16","2023-02-15","2024-03-22","2023-02-15","2023-02-15","2024-06-10","2024-06-10","2024-06-11","2024-06-11","2024-06-12","2024-06-12","2024-06-13","2024-06-12","2024-06-12","2024-06-12","2024-06-27","2024-06-10","2024-06-14","2024-06-11","2023-09-29","2023-08-01","2023-07-31","2024-07-16","2024-07-22","2024-08-21","2025-01-22","2025-01-22","2025-01-22","2024-07-23","2025-01-22","2025-01-22","2024-06-10","2025-01-22","2025-01-22","2025-01-22","2024-09-17","2023-10-24","2025-01-22","2025-01-22","2024-09-04","2025-01-22","2025-01-22","2024-09-04","2024-06-14","2023-02-16","2023-02-15","2023-10-24","2025-01-22","2024-10-07","2024-10-07","2024-10-07","2024-10-07","2024-10-07","2024-10-08","2024-10-08","2024-10-08","2024-10-08","2024-10-09","2024-10-09","2024-10-09","2024-10-07","2024-10-09","2024-10-09","2024-10-10","2024-10-10","2024-10-10","2024-10-10","2024-10-10","2024-10-10","2024-10-10","2025-01-22","2025-01-22","2024-10-01","2024-10-11","2025-01-22","2025-01-22","2025-01-22","2025-01-22","2024-10-22","2024-10-22","2025-01-22","2024-10-22","2024-11-11","2024-10-22","2024-10-22","2025-01-22","2025-01-22","2024-11-06","2025-01-22","2024-11-02","2025-01-22","2024-10-22","2024-11-03","2025-01-22","2025-01-22","2024-11-13","2024-10-23","2025-01-22","2025-01-22","2025-01-22","2025-01-22","2024-10-23","2025-01-21","2024-11-20","2024-11-13","2024-11-20","2024-11-20","2024-11-20","2024-11-14","2024-11-20","2025-01-21","2024-11-19","2024-11-19","2025-01-22","2025-01-22","2024-11-19","2024-11-19","2025-01-22","2024-11-20","2024-11-19","2024-11-18","2024-11-18","2024-11-20","2024-11-19","2024-11-13","2024-11-22","2024-11-13","2025-01-22","2024-10-23","2024-10-23","2025-01-22","2025-01-22","2024-10-24","2025-01-22","2025-01-22","2025-01-22","2024-10-22","2024-10-22","2025-01-22","2024-11-18","2024-11-18","2024-11-19","2025-01-21","2024-11-19","2024-11-19","2025-01-21","2024-11-20","2024-11-18","2024-11-18","2024-11-18","2024-11-18","2024-11-18","2025-01-22","2022-11-22","2022-11-22","2025-01-15","2025-01-14","2025-01-13","2025-01-13","2025-01-14","2025-01-15","2025-01-13","2025-01-16","2025-01-16","2025-01-16","2025-01-16","2025-01-16","2025-01-16","2025-01-22","2025-01-16","2025-01-16","2025-01-23","2025-01-23","2025-01-30","2025-02-03","2025-02-03","2025-02-05","2025-02-12","2025-02-13","2025-02-13","2025-02-13","2025-02-13","2025-02-24","2024-07-19","2025-03-10","2025-03-10","2024-08-07","2024-08-16","2024-08-18","2024-08-18","2025-03-11","2025-03-11","2025-03-11","2025-03-12","2024-08-19","2025-03-12","2025-03-12","2025-03-12","2024-10-26","2024-08-10","2024-08-15","2024-08-16","2025-03-13","2025-02-14","2024-10-04","2025-03-01","2024-11-12","2024-09-26","2024-10-02","2025-02-22","2025-03-13","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-26","2025-03-28","2025-03-28","2025-03-28","2025-03-28","2025-03-28","2025-03-28","2025-03-28","2025-04-01","2025-04-01","2025-04-01","2025-04-01","2025-04-01","2025-04-01","2025-04-07","2025-04-07","2025-04-07","2025-04-07","2025-03-12","2025-03-11","2025-03-13","2025-03-13","2025-03-13","2025-03-11","2025-04-11","2025-02-11","2025-02-18","2025-03-13","2025-03-12","2025-03-12","2025-03-11","2025-04-21","2025-04-21","2025-04-22","2025-04-22","2025-04-22","2025-03-13","2025-03-12","2025-04-24","2025-04-25","2025-04-25","2025-04-25","2025-04-25","2025-04-29","2025-04-29","2025-04-29","2025-04-30","2025-05-06","2025-05-08","2025-05-08","2025-05-08","2025-05-08","2025-01-30"],[2157,2715,1708,2854,2835,1891,1821,2157,1233,2561,1954,1233,1409,2114,2715,1897,2365,1903,2696,2383,2730,2714,1880,1760,2626,2171,1767,2372,1996,2004,2303,2133,1489,1387,2835,2835,2835,2879,2513,1387,1897,1897,1352,1358,1231,2897,1409,1361,1409,1640,1234,2114,2114,2114,2114,2856,1119,1492,1409,1409,2672,2057,1897,2242,2716,1409,1409,1112,2365,1333,1409,1402,1352,1112,1387,1409,2365,1409,2478,1115,1412,2749,2239,1412,2749,1412,1406,1111,1066,1203,1857,2157,1561,2047,2047,2101,2232,1103,2168,1103,2504,2387,1493,1500,1612,1946,1256,1712,1408,2162,1441,1568,2133,1057,1044,898,1301,1255,1714,1444,1443,1472,1053,1443,1261,1035,1032,1100,1024,1154,1387,909,1352,1352,1387,1171,2246,1358,1358,1691,1358,1141,1231,1231,1234,1409,1113,592,1690,2114,2114,1125,674,1141,1128,1142,1024,1182,1024,1896,1896,1141,1232,1232,1154,1090,1358,1114,1609,1153,1132,889,886,1129,1175,1170,1168,1111,1135,1182,1714,1178,2669,654,701,1170,2716,994,1135,1154,1114,1115,1119,1119,1113,1135,874,1409,1079,1105,1409,1113,1554,1024,1125,1352,1352,1387,1352,1387,1387,1387,1168,1227,1093,2833,1352,1736,1409,993,1168,2364,1044,1076,1168,2388,1111,985,1126,2476,846,2366,1114,2506,1578,578,1113,1105,1166,1115,1231,1535,1129,2574,1119,1412,1119,1139,1066,2696,2673,2673,1412,1231,2834,1412,1755,1139,1122,1113,1738,1116,2640,821,2155,821,816,1930,1930,1930,1930,1156,1930,1915,812,1480,1683,1106,864,805,1350,1507,1351,1479,1350,1405,1449,2444,2444,1432,947,1449,1350,1060,684,824,1541,670,2170,1569,2507,2387,1861,1233,917,2000,1580,646,1972,1669,607,1595,1717,1716,2009,1185,1835,1999,638,1999,1999,1999,1985,1784,781,1910,760,1890,1900,1712,761,1441,740,740,738,738,736,738,738,707,442,557,736,736,738,804,2162,735,464,560,1537,1003,672,1397,815,875,899,1240,1240,915,1331,986,1239,1239,1127,805,1135,1492,1373,1373,1148,1049,972,1154,1078,1051,1774,1144,1369,1442,1092,1111,1151,1152,1053,1171,1442,1065,908,804,641,687,679,1016,1022,580,685,3404,468,574,422,1119,499,1736,1234,442,883,484,1358,355,1100,348,786,719,414,378,336,421,400,441,1352,1119,499,1352,1233,450,386,1231,680,1170,1736,308,1069,187,305,2835,1113,406,407,1105,349,226,1201,1176,1736,1736,1736,1016,1736,1736,1736,1736,701,409,214,1736,1113,642,644,1168,1119,1114,1105,1105,1105,1105,1112,1105,1122,1108,336,1105,1111,702,734,699,442,1736,435,1069,909,993,486,740,735,1113,483,434,1231,750,242,1292,1113,1119,1170,846,434,986,1113,834,848,1736,1736,699,1113,369,2364,784,842,1105,577,1105,1030,1736,1144,1105,1105,924,1527,399,484,2031,2103,806,225,776,911,1115,1113,1129,1105,1105,1228,1232,1114,1113,993,336,1129,1231,1231,876,1105,1105,1105,1105,1105,1105,1113,1105,1105,1105,1121,435,435,1113,1111,1231,1105,1139,1113,1105,1231,1227,1111,1105,1105,1105,1105,1105,1113,1121,1105,1105,1113,1105,1109,1105,1105,1105,1105,1227,1113,1105,1105,1105,1098,1736,1105,1105,242,1105,1105,895,1105,1113,895,1105,1105,1117,1227,1203,243,244,896,1121,229,225,225,896,1010,1022,1021,895,1021,234,846,853,846,861,853,921,852,851,851,851,959,839,839,965,860,965,822,769,809,833,783,783,820,792,819,806,761,860,815,797,801,801,940,801,803,845,827,851,817,852,705,806,844,805,860,818,792,786,803,813,817,808,804,858,715,858,800,813,802,803,813,858,802,804,858,715,785,922,802,596,1916,922,714,1083,904,1522,1463,1553,2386,735,444,1068,365,1067,786,867,796,722,323,596,594,451,456,727,716,713,722,776,712,710,986,723,715,727,731,763,709,763,773,695,524,379,1765,359,354,348,624,352,359,263,364,348,596,591,297,633,264,1575,1610,637,373,373,305,621,342,349,350,300,304,330,354,329,356,573,351,338,1441,1441,357,297,331,304,612,1707,334,323,331,337,345,370,314,462,881,313,565,271,319,1999,575,319,328,572,616,565,451,327,691,554,292,273,574,554,293,286,279,264,292,286,243,211,217,333,442,490,518,1890,208,464,494,441,511,423,424,703,734,330,735,2160,445,446,445,440,442,444,315,426,463,315,445,445,509,468,450,352,459,442,447,442,426,441,444,443,443,471,314,458,453,428,456,425,435,412,694,425,439,424,500,503,441,441,441,462,435,425,419,442,438,466,438,438,441,441,441,496,230,450,1441,424,442,484,428,444,428,444,437,443,417,443,443,483,443,464,434,446,447,447,470,353,448,423,413,414,399,325,391,370,398,510,188,236,315,396,382,399,392,415,416,414,456,287,484,393,395,362,356,251,397,369,434,399,397,392,421,422,393,367,438,348,312,312,341,223,254,254,341,341,321,192,365,344,333,386,321,370,351,334,302,305,327,357,355,414,294,288,283,325,337,326,285,256,260,216,217,217,264,240,241,264,295,298,240,295,295,295,220,228,239,294,244,240,225,240,240,255,298,293,299,280,307,240,307,295,226,257,245,253,252,259,296,266,248,305,263,305,255,289,231,209,231,274,290,260,230,293,288,273,261,293,530,235,791,193,231,211,235,289,290,187,224,234,280,186,186,182,205,185,207,238,238,182,182,189,208,187,460,1532,254,254,401,372,656,656,656,757,759,919,623,730,1449,365,621,918,669,694,753,1039,1039,218,474,327,539,526,516,506,496,301,896,323,687,512,414,390,512,386,512,205,236,205,204,183,234,234,206,247,774,1057,515,516,274,274,808,442,437,443,445,445,413,1046,1046,1044,1044,1045,1046,1045,1045,1087,1044,1044,594,256,573,944,944,890,846,198,187,800,198,187,792,791,775,358,394,761,774,759,764,774,353,758,365,363,759,760,353,759,764,762,763,760,761,762,508,523,508,509,523,507,507,511,512,512,525,510,512,511,516,516,516,701,551,693,519,534,518,533,532,533,517,511,519,517,512,516,604,604,602,604,578,579,594,602,602,603,602,602,617,616,602,646,691,645,601,630,632,631,631,633,645,791,775,771,771,770,777,765,765,777,777,685,685,685,698,698,683,685,683,679,615,629,615,610,611,609,610,610,609,485,485,486,484,483,485,482,482,482,497,485,483,486,496,498,484,481,484,366,485,484,486,420,471,435,436,421,421,421,421,421,421,419,418,418,418,418,419,418,328,305,307,366,337,666,190,190,184,184,281,188,190,184,0,0,62,100,0,0,0,0,0,0,161,147,188,0,0,83,0,0,0,0,0,0,2,0,0,0,206,0,1,0,42,0,0,119,0,413,0,0,0,0,0,0,0,0,0,71,517,0,0,0,0,0,177,309,233,154,174,156,0,134,0,232,112,232,105,244,2,133,0,112,0,0,135,0,0,0,0,0,0,0,99,134,44,0,0,0,205,225,0,25,72,0,0,0,0,0,0,123,64,62,213,61,0,69,0,0,0,109,0,0,28,0,8,118,208,0,29,6,0,6,8,27,27,49,0,0,0,110,146,176,147,74,147,146,170,149,114,139,116,127,113,86,125,125,3,165,0,0,114,0,0,141,153,132,134,77,134,149,100,105,8,8,8,8,0,85,0,31,0,0,0,180,40,43,181,36,39,41,176,247,149,11,0,191,0,0,0,109,0,0,211,106,210,183,178,163,163,162,181,177,162,162,166,161,176,160,160,182,160,141,97,97,96,92,110,110,109,109,111,83,44,86,84,86,197,71,86,84,195,82,132,78,88,195,78,132,70,194,92,197,81,197,136,85,200,85,92,84,196,84,89,84,72,134,0,196,86,80,76,0,79,94,77,199,200,199,78,76,198,91,76,198,200,78,76,78,77,198,198,76,86,82,198,199,87,77,242,198,198,196,72,196,85,133,0,85,71,134,200,141,98,200,136,95,200,98,200,86,95,91,196,76,75,83,161,110,121,123,0,114,103,0,125,164,177,0,71,75,34,154,149,0,0,0,90,57,59,58,0,60,60,60,59,53,59,56,64,51,54,57,0,0,0,0,122,152,153,151,150,152,152,145,151,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,183,183,183,0,183,182,0,183,183,154,0,0,140,140,0,154,154,0,0,0,0,0,100,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,103,103,0,0,91,91,91,90,0,0,92,0,0,0,0,78,76,0,77,0,81,0,0,89,81,0,0,69,65,65,71,0,69,0,0,0,0,0,0,0,62,0,0,81,81,0,0,69,0,0,0,0,0,0,0,0,0,91,0,0,90,90,0,91,90,104,0,0,65,0,0,0,63,0,0,62,0,0,0,0,0,0,65,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,0,0,0,0,0,0,0,0,2,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,59,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>SYSIND<\/th>\n      <th>total_visits<\/th>\n      <th>total_obs<\/th>\n      <th>first_date<\/th>\n      <th>last_date<\/th>\n      <th>span_days<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,6]},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"SYSIND","targets":1},{"name":"total_visits","targets":2},{"name":"total_obs","targets":3},{"name":"first_date","targets":4},{"name":"last_date","targets":5},{"name":"span_days","targets":6}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>## add Visit index back to each dataset

## for dataset with EXAM_DATE variable:
index = 1
for (df_name in dfwEXAM_DATE) {
  
  cat(&quot;======================================================================&quot;,&quot;\n&quot;)
  df_obj &lt;- get(df_name)  # get the dataframe
  
  cat(index,&quot;: Currently processing dataset: &quot;,df_name,&quot;\n&quot;)
  cat(&quot;Dataset dimension: &quot;,&quot;\n&quot;)
  info(df_obj,&quot;SYSIND&quot;)
  
  df_obj &lt;- merge(df_obj,sorted_ppdat2,by=c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;))
  
  cat(&quot;After adding visit index, dataset dimension: &quot;,&quot;\n&quot;)
  info(df_obj,&quot;SYSIND&quot;)
  
  ## change dataset name
  newdfname &lt;- paste0(&quot;wVisitIndex_&quot;,df_name)
  assign(newdfname, df_obj)
  
  index = index + 1
}</code></pre>
<pre><code>## ====================================================================== 
## 1 : Currently processing dataset:  AAAD_GERIAT 
## Dataset dimension:  
## #obs:1051, cols:62, inds:939 
## After adding visit index, dataset dimension:  
## #obs:1051, cols:63, inds:939 
## ====================================================================== 
## 2 : Currently processing dataset:  AAAD_MEDCON 
## Dataset dimension:  
## #obs:397, cols:256, inds:367 
## After adding visit index, dataset dimension:  
## #obs:397, cols:257, inds:367 
## ====================================================================== 
## 3 : Currently processing dataset:  AAAD_SOCIO_DEMO 
## Dataset dimension:  
## #obs:402, cols:161, inds:391 
## After adding visit index, dataset dimension:  
## #obs:402, cols:162, inds:391 
## ====================================================================== 
## 4 : Currently processing dataset:  AAAD_TRAILS 
## Dataset dimension:  
## #obs:439, cols:34, inds:428 
## After adding visit index, dataset dimension:  
## #obs:439, cols:35, inds:428 
## ====================================================================== 
## 5 : Currently processing dataset:  ALZ_B9_JUDGE_RC 
## Dataset dimension:  
## #obs:483, cols:82, inds:481 
## After adding visit index, dataset dimension:  
## #obs:483, cols:83, inds:481 
## ====================================================================== 
## 6 : Currently processing dataset:  ALZ_CSDD 
## Dataset dimension:  
## #obs:181, cols:42, inds:176 
## After adding visit index, dataset dimension:  
## #obs:181, cols:43, inds:176 
## ====================================================================== 
## 7 : Currently processing dataset:  ALZ_GAI_SP 
## Dataset dimension:  
## #obs:19, cols:42, inds:19 
## After adding visit index, dataset dimension:  
## #obs:19, cols:43, inds:19 
## ====================================================================== 
## 8 : Currently processing dataset:  ALZ_NEURO_CDR 
## Dataset dimension:  
## #obs:1221, cols:30, inds:1102 
## After adding visit index, dataset dimension:  
## #obs:1221, cols:31, inds:1102 
## ====================================================================== 
## 9 : Currently processing dataset:  ALZ_NPIQ_CBRS 
## Dataset dimension:  
## #obs:122, cols:116, inds:121 
## After adding visit index, dataset dimension:  
## #obs:122, cols:117, inds:121 
## ====================================================================== 
## 10 : Currently processing dataset:  ALZ_RPFQ 
## Dataset dimension:  
## #obs:132, cols:67, inds:132 
## After adding visit index, dataset dimension:  
## #obs:132, cols:68, inds:132 
## ====================================================================== 
## 11 : Currently processing dataset:  ALZ_SCREENING_RC 
## Dataset dimension:  
## #obs:556, cols:61, inds:552 
## After adding visit index, dataset dimension:  
## #obs:556, cols:62, inds:552 
## ====================================================================== 
## 12 : Currently processing dataset:  ALZ_STICK_D_RC 
## Dataset dimension:  
## #obs:430, cols:46, inds:428 
## After adding visit index, dataset dimension:  
## #obs:430, cols:47, inds:428 
## ====================================================================== 
## 13 : Currently processing dataset:  B4_CDR_RC 
## Dataset dimension:  
## #obs:599, cols:38, inds:592 
## After adding visit index, dataset dimension:  
## #obs:599, cols:39, inds:592 
## ====================================================================== 
## 14 : Currently processing dataset:  B5_NPIQ_RC 
## Dataset dimension:  
## #obs:305, cols:38, inds:304 
## After adding visit index, dataset dimension:  
## #obs:305, cols:39, inds:304 
## ====================================================================== 
## 15 : Currently processing dataset:  B6_GDS_RC 
## Dataset dimension:  
## #obs:543, cols:39, inds:539 
## After adding visit index, dataset dimension:  
## #obs:543, cols:40, inds:539 
## ====================================================================== 
## 16 : Currently processing dataset:  B7_FAS_RC 
## Dataset dimension:  
## #obs:435, cols:33, inds:431 
## After adding visit index, dataset dimension:  
## #obs:435, cols:34, inds:431 
## ====================================================================== 
## 17 : Currently processing dataset:  BCF_RECOG_RC 
## Dataset dimension:  
## #obs:266, cols:24, inds:266 
## After adding visit index, dataset dimension:  
## #obs:266, cols:25, inds:266 
## ====================================================================== 
## 18 : Currently processing dataset:  BCFCD_RC 
## Dataset dimension:  
## #obs:269, cols:38, inds:269 
## After adding visit index, dataset dimension:  
## #obs:269, cols:39, inds:269 
## ====================================================================== 
## 19 : Currently processing dataset:  BCFCI_RC 
## Dataset dimension:  
## #obs:270, cols:38, inds:270 
## After adding visit index, dataset dimension:  
## #obs:270, cols:39, inds:270 
## ====================================================================== 
## 20 : Currently processing dataset:  BILINGUAL_SCALE_RC 
## Dataset dimension:  
## #obs:240, cols:90, inds:240 
## After adding visit index, dataset dimension:  
## #obs:240, cols:91, inds:240 
## ====================================================================== 
## 21 : Currently processing dataset:  CAT_FLUENCY_RC 
## Dataset dimension:  
## #obs:555, cols:29, inds:550 
## After adding visit index, dataset dimension:  
## #obs:555, cols:30, inds:550 
## ====================================================================== 
## 22 : Currently processing dataset:  CERAD_DEL_RC 
## Dataset dimension:  
## #obs:177, cols:44, inds:177 
## After adding visit index, dataset dimension:  
## #obs:177, cols:45, inds:177 
## ====================================================================== 
## 23 : Currently processing dataset:  CERAD_IMM_RC 
## Dataset dimension:  
## #obs:188, cols:88, inds:188 
## After adding visit index, dataset dimension:  
## #obs:188, cols:89, inds:188 
## ====================================================================== 
## 24 : Currently processing dataset:  CERAD_RECOG_RC 
## Dataset dimension:  
## #obs:177, cols:48, inds:177 
## After adding visit index, dataset dimension:  
## #obs:177, cols:49, inds:177 
## ====================================================================== 
## 25 : Currently processing dataset:  CRAFT_21_DEL_RC 
## Dataset dimension:  
## #obs:523, cols:95, inds:519 
## After adding visit index, dataset dimension:  
## #obs:523, cols:96, inds:519 
## ====================================================================== 
## 26 : Currently processing dataset:  CRAFT_21_IMM_RC 
## Dataset dimension:  
## #obs:530, cols:98, inds:525 
## After adding visit index, dataset dimension:  
## #obs:530, cols:99, inds:525 
## ====================================================================== 
## 27 : Currently processing dataset:  MEDCON_RC 
## Dataset dimension:  
## #obs:627, cols:237, inds:618 
## After adding visit index, dataset dimension:  
## #obs:627, cols:238, inds:618 
## ====================================================================== 
## 28 : Currently processing dataset:  MEDICAL_HIST 
## Dataset dimension:  
## #obs:889, cols:53, inds:871 
## After adding visit index, dataset dimension:  
## #obs:889, cols:54, inds:871 
## ====================================================================== 
## 29 : Currently processing dataset:  MINT_RC 
## Dataset dimension:  
## #obs:3, cols:221, inds:3 
## After adding visit index, dataset dimension:  
## #obs:3, cols:222, inds:3 
## ====================================================================== 
## 30 : Currently processing dataset:  MINT_SP_RC 
## Dataset dimension:  
## #obs:303, cols:221, inds:301 
## After adding visit index, dataset dimension:  
## #obs:303, cols:222, inds:301 
## ====================================================================== 
## 31 : Currently processing dataset:  MOCA_RC 
## Dataset dimension:  
## #obs:585, cols:140, inds:580 
## After adding visit index, dataset dimension:  
## #obs:585, cols:141, inds:580 
## ====================================================================== 
## 32 : Currently processing dataset:  NUMBER_SPAN_RC 
## Dataset dimension:  
## #obs:527, cols:85, inds:522 
## After adding visit index, dataset dimension:  
## #obs:527, cols:86, inds:522</code></pre>
<pre class="r"><code>## Now add visit index to dataset with FORM_DATE
sorted_ppdat3 &lt;- sorted_ppdat2
names(sorted_ppdat3)[names(sorted_ppdat3)==&quot;EXAM_DATE&quot;] &lt;- &quot;FORM_DATE&quot;

for (df_name in dfwFORM_DATE) {
  cat(&quot;======================================================================&quot;,&quot;\n&quot;)
  df_obj &lt;- get(df_name)  # get the dataframe
  
  cat(index,&quot;: Currently processing dataset: &quot;,df_name,&quot;\n&quot;)
  cat(&quot;Dataset dimension: &quot;,&quot;\n&quot;)
  info(df_obj,&quot;SYSIND&quot;)
  
  df_obj &lt;- merge(df_obj,sorted_ppdat3,by=c(&quot;SYSIND&quot;,&quot;FORM_DATE&quot;))
  
  cat(&quot;After adding visit index, dataset dimension: &quot;,&quot;\n&quot;)
  info(df_obj,&quot;SYSIND&quot;)
  
  ## change dataset name
  newdfname &lt;- paste0(&quot;wVisitIndex_&quot;,df_name)
  assign(newdfname, df_obj)
  
  index = index + 1
}</code></pre>
<pre><code>## ====================================================================== 
## 33 : Currently processing dataset:  ALZ_CLINICALSUM 
## Dataset dimension:  
## #obs:1484, cols:39, inds:1480 
## After adding visit index, dataset dimension:  
## #obs:1484, cols:40, inds:1480 
## ====================================================================== 
## 34 : Currently processing dataset:  ALZ_EXAM 
## Dataset dimension:  
## #obs:526, cols:80, inds:522 
## After adding visit index, dataset dimension:  
## #obs:526, cols:81, inds:522 
## ====================================================================== 
## 35 : Currently processing dataset:  ALZ_NCRAD 
## Dataset dimension:  
## #obs:742, cols:53, inds:742 
## After adding visit index, dataset dimension:  
## #obs:742, cols:54, inds:742 
## ====================================================================== 
## 36 : Currently processing dataset:  ALZ_SCREENING 
## Dataset dimension:  
## #obs:279, cols:49, inds:272 
## After adding visit index, dataset dimension:  
## #obs:279, cols:50, inds:272</code></pre>
<pre class="r"><code>## Finally, we add visit index to the last two datasets: ALZ_LOAD_COG and CONSENSUS_DX

cat(&quot;======================================================================&quot;,&quot;\n&quot;)</code></pre>
<pre><code>## ======================================================================</code></pre>
<pre class="r"><code>df_obj &lt;- ALZ_LOAD_COG  # get the dataframe
df_name &lt;- &quot;ALZ_LOAD_COG&quot;
cat(index,&quot;: Currently processing dataset: &quot;,df_name,&quot;\n&quot;)</code></pre>
<pre><code>## 37 : Currently processing dataset:  ALZ_LOAD_COG</code></pre>
<pre class="r"><code>cat(&quot;Dataset dimension: &quot;,&quot;\n&quot;)</code></pre>
<pre><code>## Dataset dimension:</code></pre>
<pre class="r"><code>info(df_obj,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1006, cols:41, inds:907</code></pre>
<pre class="r"><code>df_obj &lt;- merge(df_obj,sorted_ppdat2,by.x=c(&quot;SYSIND&quot;,&quot;INTERVIEW_DATE&quot;),by.y = c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;))
cat(&quot;After adding visit index, dataset dimension: &quot;,&quot;\n&quot;)</code></pre>
<pre><code>## After adding visit index, dataset dimension:</code></pre>
<pre class="r"><code>info(df_obj,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1006, cols:42, inds:907</code></pre>
<pre class="r"><code>## change dataset name
newdfname &lt;- paste0(&quot;wVisitIndex_&quot;,df_name)
assign(newdfname, df_obj)
index = index + 1

cat(&quot;======================================================================&quot;,&quot;\n&quot;)</code></pre>
<pre><code>## ======================================================================</code></pre>
<pre class="r"><code>df_obj &lt;- CONSENSUS_DX  # get the dataframe
df_name &lt;- &quot;CONSENSUS_DX&quot;
cat(index,&quot;: Currently processing dataset: &quot;,df_name,&quot;\n&quot;)</code></pre>
<pre><code>## 38 : Currently processing dataset:  CONSENSUS_DX</code></pre>
<pre class="r"><code>cat(&quot;Dataset dimension: &quot;,&quot;\n&quot;)</code></pre>
<pre><code>## Dataset dimension:</code></pre>
<pre class="r"><code>info(df_obj,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1701, cols:59, inds:1584</code></pre>
<pre class="r"><code>df_obj &lt;- merge(df_obj,sorted_ppdat2,by.x=c(&quot;SYSIND&quot;,&quot;DATE_DX&quot;),by.y = c(&quot;SYSIND&quot;,&quot;EXAM_DATE&quot;))
cat(&quot;After adding visit index, dataset dimension: &quot;,&quot;\n&quot;)</code></pre>
<pre><code>## After adding visit index, dataset dimension:</code></pre>
<pre class="r"><code>info(df_obj,&quot;SYSIND&quot;)</code></pre>
<pre><code>## #obs:1701, cols:60, inds:1584</code></pre>
<pre class="r"><code>## change dataset name
newdfname &lt;- paste0(&quot;wVisitIndex_&quot;,df_name)
assign(newdfname, df_obj)</code></pre>
</div>
<div id="merge-all-datasets" class="section level2">
<h2>Merge All Datasets</h2>
<pre class="r"><code>## since there are a lot of columns for individuals identifiers, instead of merging the dataset by all of these, I decided to taking them out and merge it back to the very end

colsWfixedValues &lt;- c(&quot;SYSGP&quot;,&quot;SYSGPSTUDY&quot;,&quot;SYSINDGP&quot;,&quot;CGI_ORDER&quot;,&quot;GPS_ORDER&quot;,&quot;STDCGI_ORDER&quot;,&quot;LSTUDY&quot;,&quot;DB_OWNER&quot;,&quot;STUDY&quot;,&quot;SUBSTUDY&quot;,&quot;CENTER&quot;,&quot;GP&quot;,&quot;IND&quot;,&quot;REFCTR&quot;,&quot;DATE_OF_BIRTH&quot;) ## 15 vars

df_names &lt;- ls(pattern = &quot;^wVisitIndex_&quot;)
length(df_names)</code></pre>
<pre><code>## [1] 38</code></pre>
<pre class="r"><code>## this dataset will stored all those identifer values which will be merged to the final dataset at the very end
colsWfixedValuesDF &lt;- wVisitIndex_AAAD_GERIAT[,colsWfixedValues]

index = 1
for (df_name in df_names) {
  cat(&quot;======================================================================&quot;,&quot;\n&quot;)
  df_obj &lt;- get(df_name)
  cat(index,&quot;: Currently processing dataset: &quot;,df_name,&quot;\n&quot;)
  cat(&quot;Dataset dimension: &quot;,&quot;\n&quot;)
  info(df_obj,&quot;SYSIND&quot;)
  
  colsWfixedValuesDF &lt;- rbind(colsWfixedValuesDF,df_obj[,colsWfixedValues])
  
  ## drop columns of colsWfixedValues
  df_obj &lt;- df_obj[, setdiff(names(df_obj), colsWfixedValues), drop = FALSE]
  
  cat(&quot;After removing indetifer columns, dataset dimension: &quot;,&quot;\n&quot;)
  info(df_obj,&quot;SYSIND&quot;)
  
  assign(df_name, df_obj)
  index = index + 1
}</code></pre>
<pre><code>## ====================================================================== 
## 1 : Currently processing dataset:  wVisitIndex_AAAD_GERIAT 
## Dataset dimension:  
## #obs:1051, cols:63, inds:939 
## After removing indetifer columns, dataset dimension:  
## #obs:1051, cols:48, inds:939 
## ====================================================================== 
## 2 : Currently processing dataset:  wVisitIndex_AAAD_MEDCON 
## Dataset dimension:  
## #obs:397, cols:257, inds:367 
## After removing indetifer columns, dataset dimension:  
## #obs:397, cols:242, inds:367 
## ====================================================================== 
## 3 : Currently processing dataset:  wVisitIndex_AAAD_SOCIO_DEMO 
## Dataset dimension:  
## #obs:402, cols:162, inds:391 
## After removing indetifer columns, dataset dimension:  
## #obs:402, cols:147, inds:391 
## ====================================================================== 
## 4 : Currently processing dataset:  wVisitIndex_AAAD_TRAILS 
## Dataset dimension:  
## #obs:439, cols:35, inds:428 
## After removing indetifer columns, dataset dimension:  
## #obs:439, cols:20, inds:428 
## ====================================================================== 
## 5 : Currently processing dataset:  wVisitIndex_ALZ_B9_JUDGE_RC 
## Dataset dimension:  
## #obs:483, cols:83, inds:481 
## After removing indetifer columns, dataset dimension:  
## #obs:483, cols:68, inds:481 
## ====================================================================== 
## 6 : Currently processing dataset:  wVisitIndex_ALZ_CLINICALSUM 
## Dataset dimension:  
## #obs:1484, cols:40, inds:1480 
## After removing indetifer columns, dataset dimension:  
## #obs:1484, cols:25, inds:1480 
## ====================================================================== 
## 7 : Currently processing dataset:  wVisitIndex_ALZ_CSDD 
## Dataset dimension:  
## #obs:181, cols:43, inds:176 
## After removing indetifer columns, dataset dimension:  
## #obs:181, cols:28, inds:176 
## ====================================================================== 
## 8 : Currently processing dataset:  wVisitIndex_ALZ_EXAM 
## Dataset dimension:  
## #obs:526, cols:81, inds:522 
## After removing indetifer columns, dataset dimension:  
## #obs:526, cols:66, inds:522 
## ====================================================================== 
## 9 : Currently processing dataset:  wVisitIndex_ALZ_GAI_SP 
## Dataset dimension:  
## #obs:19, cols:43, inds:19 
## After removing indetifer columns, dataset dimension:  
## #obs:19, cols:28, inds:19 
## ====================================================================== 
## 10 : Currently processing dataset:  wVisitIndex_ALZ_LOAD_COG 
## Dataset dimension:  
## #obs:1006, cols:42, inds:907 
## After removing indetifer columns, dataset dimension:  
## #obs:1006, cols:27, inds:907 
## ====================================================================== 
## 11 : Currently processing dataset:  wVisitIndex_ALZ_NCRAD 
## Dataset dimension:  
## #obs:742, cols:54, inds:742 
## After removing indetifer columns, dataset dimension:  
## #obs:742, cols:39, inds:742 
## ====================================================================== 
## 12 : Currently processing dataset:  wVisitIndex_ALZ_NEURO_CDR 
## Dataset dimension:  
## #obs:1221, cols:31, inds:1102 
## After removing indetifer columns, dataset dimension:  
## #obs:1221, cols:16, inds:1102 
## ====================================================================== 
## 13 : Currently processing dataset:  wVisitIndex_ALZ_NPIQ_CBRS 
## Dataset dimension:  
## #obs:122, cols:117, inds:121 
## After removing indetifer columns, dataset dimension:  
## #obs:122, cols:102, inds:121 
## ====================================================================== 
## 14 : Currently processing dataset:  wVisitIndex_ALZ_RPFQ 
## Dataset dimension:  
## #obs:132, cols:68, inds:132 
## After removing indetifer columns, dataset dimension:  
## #obs:132, cols:53, inds:132 
## ====================================================================== 
## 15 : Currently processing dataset:  wVisitIndex_ALZ_SCREENING 
## Dataset dimension:  
## #obs:279, cols:50, inds:272 
## After removing indetifer columns, dataset dimension:  
## #obs:279, cols:35, inds:272 
## ====================================================================== 
## 16 : Currently processing dataset:  wVisitIndex_ALZ_SCREENING_RC 
## Dataset dimension:  
## #obs:556, cols:62, inds:552 
## After removing indetifer columns, dataset dimension:  
## #obs:556, cols:47, inds:552 
## ====================================================================== 
## 17 : Currently processing dataset:  wVisitIndex_ALZ_STICK_D_RC 
## Dataset dimension:  
## #obs:430, cols:47, inds:428 
## After removing indetifer columns, dataset dimension:  
## #obs:430, cols:32, inds:428 
## ====================================================================== 
## 18 : Currently processing dataset:  wVisitIndex_B4_CDR_RC 
## Dataset dimension:  
## #obs:599, cols:39, inds:592 
## After removing indetifer columns, dataset dimension:  
## #obs:599, cols:24, inds:592 
## ====================================================================== 
## 19 : Currently processing dataset:  wVisitIndex_B5_NPIQ_RC 
## Dataset dimension:  
## #obs:305, cols:39, inds:304 
## After removing indetifer columns, dataset dimension:  
## #obs:305, cols:24, inds:304 
## ====================================================================== 
## 20 : Currently processing dataset:  wVisitIndex_B6_GDS_RC 
## Dataset dimension:  
## #obs:543, cols:40, inds:539 
## After removing indetifer columns, dataset dimension:  
## #obs:543, cols:25, inds:539 
## ====================================================================== 
## 21 : Currently processing dataset:  wVisitIndex_B7_FAS_RC 
## Dataset dimension:  
## #obs:435, cols:34, inds:431 
## After removing indetifer columns, dataset dimension:  
## #obs:435, cols:19, inds:431 
## ====================================================================== 
## 22 : Currently processing dataset:  wVisitIndex_BCF_RECOG_RC 
## Dataset dimension:  
## #obs:266, cols:25, inds:266 
## After removing indetifer columns, dataset dimension:  
## #obs:266, cols:10, inds:266 
## ====================================================================== 
## 23 : Currently processing dataset:  wVisitIndex_BCFCD_RC 
## Dataset dimension:  
## #obs:269, cols:39, inds:269 
## After removing indetifer columns, dataset dimension:  
## #obs:269, cols:24, inds:269 
## ====================================================================== 
## 24 : Currently processing dataset:  wVisitIndex_BCFCI_RC 
## Dataset dimension:  
## #obs:270, cols:39, inds:270 
## After removing indetifer columns, dataset dimension:  
## #obs:270, cols:24, inds:270 
## ====================================================================== 
## 25 : Currently processing dataset:  wVisitIndex_BILINGUAL_SCALE_RC 
## Dataset dimension:  
## #obs:240, cols:91, inds:240 
## After removing indetifer columns, dataset dimension:  
## #obs:240, cols:76, inds:240 
## ====================================================================== 
## 26 : Currently processing dataset:  wVisitIndex_CAT_FLUENCY_RC 
## Dataset dimension:  
## #obs:555, cols:30, inds:550 
## After removing indetifer columns, dataset dimension:  
## #obs:555, cols:15, inds:550 
## ====================================================================== 
## 27 : Currently processing dataset:  wVisitIndex_CERAD_DEL_RC 
## Dataset dimension:  
## #obs:177, cols:45, inds:177 
## After removing indetifer columns, dataset dimension:  
## #obs:177, cols:30, inds:177 
## ====================================================================== 
## 28 : Currently processing dataset:  wVisitIndex_CERAD_IMM_RC 
## Dataset dimension:  
## #obs:188, cols:89, inds:188 
## After removing indetifer columns, dataset dimension:  
## #obs:188, cols:74, inds:188 
## ====================================================================== 
## 29 : Currently processing dataset:  wVisitIndex_CERAD_RECOG_RC 
## Dataset dimension:  
## #obs:177, cols:49, inds:177 
## After removing indetifer columns, dataset dimension:  
## #obs:177, cols:34, inds:177 
## ====================================================================== 
## 30 : Currently processing dataset:  wVisitIndex_CONSENSUS_DX 
## Dataset dimension:  
## #obs:1701, cols:60, inds:1584 
## After removing indetifer columns, dataset dimension:  
## #obs:1701, cols:45, inds:1584 
## ====================================================================== 
## 31 : Currently processing dataset:  wVisitIndex_CRAFT_21_DEL_RC 
## Dataset dimension:  
## #obs:523, cols:96, inds:519 
## After removing indetifer columns, dataset dimension:  
## #obs:523, cols:81, inds:519 
## ====================================================================== 
## 32 : Currently processing dataset:  wVisitIndex_CRAFT_21_IMM_RC 
## Dataset dimension:  
## #obs:530, cols:99, inds:525 
## After removing indetifer columns, dataset dimension:  
## #obs:530, cols:84, inds:525 
## ====================================================================== 
## 33 : Currently processing dataset:  wVisitIndex_MEDCON_RC 
## Dataset dimension:  
## #obs:627, cols:238, inds:618 
## After removing indetifer columns, dataset dimension:  
## #obs:627, cols:223, inds:618 
## ====================================================================== 
## 34 : Currently processing dataset:  wVisitIndex_MEDICAL_HIST 
## Dataset dimension:  
## #obs:889, cols:54, inds:871 
## After removing indetifer columns, dataset dimension:  
## #obs:889, cols:39, inds:871 
## ====================================================================== 
## 35 : Currently processing dataset:  wVisitIndex_MINT_RC 
## Dataset dimension:  
## #obs:3, cols:222, inds:3 
## After removing indetifer columns, dataset dimension:  
## #obs:3, cols:207, inds:3 
## ====================================================================== 
## 36 : Currently processing dataset:  wVisitIndex_MINT_SP_RC 
## Dataset dimension:  
## #obs:303, cols:222, inds:301 
## After removing indetifer columns, dataset dimension:  
## #obs:303, cols:207, inds:301 
## ====================================================================== 
## 37 : Currently processing dataset:  wVisitIndex_MOCA_RC 
## Dataset dimension:  
## #obs:585, cols:141, inds:580 
## After removing indetifer columns, dataset dimension:  
## #obs:585, cols:126, inds:580 
## ====================================================================== 
## 38 : Currently processing dataset:  wVisitIndex_NUMBER_SPAN_RC 
## Dataset dimension:  
## #obs:527, cols:86, inds:522 
## After removing indetifer columns, dataset dimension:  
## #obs:527, cols:71, inds:522</code></pre>
<pre class="r"><code>colsWfixedValuesDF &lt;- colsWfixedValuesDF[!duplicated(colsWfixedValuesDF),]
info(colsWfixedValuesDF,&quot;SYSINDGP&quot;) #obs:1994, cols:15, inds:1994 </code></pre>
<pre><code>## #obs:1994, cols:15, inds:1994</code></pre>
<pre class="r"><code>## Now we can merge all datasets!!
mergedDF &lt;- get(df_names[1])

for (i in 2:length(df_names)) { 
  mergedDF &lt;- merge_with_info(&quot;mergedDF&quot;, df_names[i], merge_cols = c(&quot;SYSIND&quot;,&quot;Visit_Index&quot;), info_col = &quot;SYSIND&quot;) 
}</code></pre>
<pre><code>## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_AAAD_MEDCON 
## Before merging: Info of  wVisitIndex_AAAD_MEDCON : 
## #obs:397, cols:242, inds:367 
## 
## Number of individuals that only present in  mergedDF  :  654 
## Number of individuals that only present in  wVisitIndex_AAAD_MEDCON  :  82 
## Number of individuals present in both datasets :  285 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM 
## 
## Info for merged dataset:
## #obs:1163, cols:288, inds:1021 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_AAAD_SOCIO_DEMO 
## Before merging: Info of  wVisitIndex_AAAD_SOCIO_DEMO : 
## #obs:402, cols:147, inds:391 
## 
## Number of individuals that only present in  mergedDF  :  678 
## Number of individuals that only present in  wVisitIndex_AAAD_SOCIO_DEMO  :  48 
## Number of individuals present in both datasets :  343 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:1293, cols:433, inds:1069 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_AAAD_TRAILS 
## Before merging: Info of  wVisitIndex_AAAD_TRAILS : 
## #obs:439, cols:20, inds:428 
## 
## Number of individuals that only present in  mergedDF  :  674 
## Number of individuals that only present in  wVisitIndex_AAAD_TRAILS  :  33 
## Number of individuals present in both datasets :  395 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:1331, cols:451, inds:1102 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_B9_JUDGE_RC 
## Before merging: Info of  wVisitIndex_ALZ_B9_JUDGE_RC : 
## #obs:483, cols:68, inds:481 
## 
## Number of individuals that only present in  mergedDF  :  996 
## Number of individuals that only present in  wVisitIndex_ALZ_B9_JUDGE_RC  :  375 
## Number of individuals present in both datasets :  106 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:1799, cols:517, inds:1477 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_CLINICALSUM 
## Before merging: Info of  wVisitIndex_ALZ_CLINICALSUM : 
## #obs:1484, cols:25, inds:1480 
## 
## Number of individuals that only present in  mergedDF  :  410 
## Number of individuals that only present in  wVisitIndex_ALZ_CLINICALSUM  :  413 
## Number of individuals present in both datasets :  1067 
## 
## Common columns between the two datatsets are:  SYSXM COMMENTS 
## 
## Info for merged dataset:
## #obs:2470, cols:540, inds:1890 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_CSDD 
## Before merging: Info of  wVisitIndex_ALZ_CSDD : 
## #obs:181, cols:28, inds:176 
## 
## Number of individuals that only present in  mergedDF  :  1714 
## Number of individuals that only present in  wVisitIndex_ALZ_CSDD  :  0 
## Number of individuals present in both datasets :  176 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM 
## 
## Info for merged dataset:
## #obs:2513, cols:566, inds:1890 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_EXAM 
## Before merging: Info of  wVisitIndex_ALZ_EXAM : 
## #obs:526, cols:66, inds:522 
## 
## Number of individuals that only present in  mergedDF  :  1368 
## Number of individuals that only present in  wVisitIndex_ALZ_EXAM  :  0 
## Number of individuals present in both datasets :  522 
## 
## Common columns between the two datatsets are:  SYSXM DOPAMINE FORM_DATE FILLED_OUT_BY 
## 
## Info for merged dataset:
## #obs:2522, cols:630, inds:1890 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_GAI_SP 
## Before merging: Info of  wVisitIndex_ALZ_GAI_SP : 
## #obs:19, cols:28, inds:19 
## 
## Number of individuals that only present in  mergedDF  :  1871 
## Number of individuals that only present in  wVisitIndex_ALZ_GAI_SP  :  0 
## Number of individuals present in both datasets :  19 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2523, cols:656, inds:1890 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_LOAD_COG 
## Before merging: Info of  wVisitIndex_ALZ_LOAD_COG : 
## #obs:1006, cols:27, inds:907 
## 
## Number of individuals that only present in  mergedDF  :  985 
## Number of individuals that only present in  wVisitIndex_ALZ_LOAD_COG  :  2 
## Number of individuals present in both datasets :  905 
## 
## Common columns between the two datatsets are:  SYSXM 
## 
## Info for merged dataset:
## #obs:2540, cols:681, inds:1892 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_NCRAD 
## Before merging: Info of  wVisitIndex_ALZ_NCRAD : 
## #obs:742, cols:39, inds:742 
## 
## Number of individuals that only present in  mergedDF  :  1150 
## Number of individuals that only present in  wVisitIndex_ALZ_NCRAD  :  0 
## Number of individuals present in both datasets :  742 
## 
## Common columns between the two datatsets are:  SYSXM FORM_DATE FILLED_OUT_BY 
## 
## Info for merged dataset:
## #obs:2645, cols:718, inds:1892 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_NEURO_CDR 
## Before merging: Info of  wVisitIndex_ALZ_NEURO_CDR : 
## #obs:1221, cols:16, inds:1102 
## 
## Number of individuals that only present in  mergedDF  :  790 
## Number of individuals that only present in  wVisitIndex_ALZ_NEURO_CDR  :  0 
## Number of individuals present in both datasets :  1102 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM 
## 
## Info for merged dataset:
## #obs:2707, cols:732, inds:1892 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_NPIQ_CBRS 
## Before merging: Info of  wVisitIndex_ALZ_NPIQ_CBRS : 
## #obs:122, cols:102, inds:121 
## 
## Number of individuals that only present in  mergedDF  :  1771 
## Number of individuals that only present in  wVisitIndex_ALZ_NPIQ_CBRS  :  0 
## Number of individuals present in both datasets :  121 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM NOTES 
## 
## Info for merged dataset:
## #obs:2709, cols:832, inds:1892 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_RPFQ 
## Before merging: Info of  wVisitIndex_ALZ_RPFQ : 
## #obs:132, cols:53, inds:132 
## 
## Number of individuals that only present in  mergedDF  :  1760 
## Number of individuals that only present in  wVisitIndex_ALZ_RPFQ  :  0 
## Number of individuals present in both datasets :  132 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2709, cols:883, inds:1892 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_SCREENING 
## Before merging: Info of  wVisitIndex_ALZ_SCREENING : 
## #obs:279, cols:35, inds:272 
## 
## Number of individuals that only present in  mergedDF  :  1621 
## Number of individuals that only present in  wVisitIndex_ALZ_SCREENING  :  1 
## Number of individuals present in both datasets :  271 
## 
## Common columns between the two datatsets are:  SYSXM FORM_DATE FILLED_OUT_BY 
## 
## Info for merged dataset:
## #obs:2713, cols:916, inds:1893 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_SCREENING_RC 
## Before merging: Info of  wVisitIndex_ALZ_SCREENING_RC : 
## #obs:556, cols:47, inds:552 
## 
## Number of individuals that only present in  mergedDF  :  1413 
## Number of individuals that only present in  wVisitIndex_ALZ_SCREENING_RC  :  72 
## Number of individuals present in both datasets :  480 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER BRAIN_MRI BRAIN_CT EEG BRAIN_BIO LUMB_NOTES BRNMRI_NOTES BRNCT_NOTES EEG_NOTES PETSP_NOTES BRNBIO_NOTES 
## 
## Info for merged dataset:
## #obs:2818, cols:961, inds:1965 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_ALZ_STICK_D_RC 
## Before merging: Info of  wVisitIndex_ALZ_STICK_D_RC : 
## #obs:430, cols:32, inds:428 
## 
## Number of individuals that only present in  mergedDF  :  1542 
## Number of individuals that only present in  wVisitIndex_ALZ_STICK_D_RC  :  5 
## Number of individuals present in both datasets :  423 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2826, cols:991, inds:1970 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_B4_CDR_RC 
## Before merging: Info of  wVisitIndex_B4_CDR_RC : 
## #obs:599, cols:24, inds:592 
## 
## Number of individuals that only present in  mergedDF  :  1384 
## Number of individuals that only present in  wVisitIndex_B4_CDR_RC  :  6 
## Number of individuals present in both datasets :  586 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2837, cols:1013, inds:1976 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_B5_NPIQ_RC 
## Before merging: Info of  wVisitIndex_B5_NPIQ_RC : 
## #obs:305, cols:24, inds:304 
## 
## Number of individuals that only present in  mergedDF  :  1672 
## Number of individuals that only present in  wVisitIndex_B5_NPIQ_RC  :  0 
## Number of individuals present in both datasets :  304 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER NPIQINF NPIQINF_OTH NPIQTYPE AGITSEV DEPDSEV ANXSEV ELATSEV APASEV DISNSEV IRRSEV MOTSEV NITESEV APPSEV DELSEV HALLSEV 
## 
## Info for merged dataset:
## #obs:2837, cols:1035, inds:1976 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_B6_GDS_RC 
## Before merging: Info of  wVisitIndex_B6_GDS_RC : 
## #obs:543, cols:25, inds:539 
## 
## Number of individuals that only present in  mergedDF  :  1438 
## Number of individuals that only present in  wVisitIndex_B6_GDS_RC  :  1 
## Number of individuals present in both datasets :  538 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM BORED STAY_HOME ALIVE REVIEW_DATE REVIEWER MEMORY 
## 
## Info for merged dataset:
## #obs:2839, cols:1058, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_B7_FAS_RC 
## Before merging: Info of  wVisitIndex_B7_FAS_RC : 
## #obs:435, cols:19, inds:431 
## 
## Number of individuals that only present in  mergedDF  :  1546 
## Number of individuals that only present in  wVisitIndex_B7_FAS_RC  :  0 
## Number of individuals present in both datasets :  431 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2840, cols:1075, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_BCF_RECOG_RC 
## Before merging: Info of  wVisitIndex_BCF_RECOG_RC : 
## #obs:266, cols:10, inds:266 
## 
## Number of individuals that only present in  mergedDF  :  1711 
## Number of individuals that only present in  wVisitIndex_BCF_RECOG_RC  :  0 
## Number of individuals present in both datasets :  266 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2840, cols:1083, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_BCFCD_RC 
## Before merging: Info of  wVisitIndex_BCFCD_RC : 
## #obs:269, cols:24, inds:269 
## 
## Number of individuals that only present in  mergedDF  :  1708 
## Number of individuals that only present in  wVisitIndex_BCFCD_RC  :  0 
## Number of individuals present in both datasets :  269 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2840, cols:1105, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_BCFCI_RC 
## Before merging: Info of  wVisitIndex_BCFCI_RC : 
## #obs:270, cols:24, inds:270 
## 
## Number of individuals that only present in  mergedDF  :  1707 
## Number of individuals that only present in  wVisitIndex_BCFCI_RC  :  0 
## Number of individuals present in both datasets :  270 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER FILE_NAME1 
## 
## Info for merged dataset:
## #obs:2840, cols:1127, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_BILINGUAL_SCALE_RC 
## Before merging: Info of  wVisitIndex_BILINGUAL_SCALE_RC : 
## #obs:240, cols:76, inds:240 
## 
## Number of individuals that only present in  mergedDF  :  1737 
## Number of individuals that only present in  wVisitIndex_BILINGUAL_SCALE_RC  :  0 
## Number of individuals present in both datasets :  240 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2840, cols:1201, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CAT_FLUENCY_RC 
## Before merging: Info of  wVisitIndex_CAT_FLUENCY_RC : 
## #obs:555, cols:15, inds:550 
## 
## Number of individuals that only present in  mergedDF  :  1427 
## Number of individuals that only present in  wVisitIndex_CAT_FLUENCY_RC  :  0 
## Number of individuals present in both datasets :  550 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2841, cols:1214, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CERAD_DEL_RC 
## Before merging: Info of  wVisitIndex_CERAD_DEL_RC : 
## #obs:177, cols:30, inds:177 
## 
## Number of individuals that only present in  mergedDF  :  1800 
## Number of individuals that only present in  wVisitIndex_CERAD_DEL_RC  :  0 
## Number of individuals present in both datasets :  177 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2841, cols:1242, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CERAD_IMM_RC 
## Before merging: Info of  wVisitIndex_CERAD_IMM_RC : 
## #obs:188, cols:74, inds:188 
## 
## Number of individuals that only present in  mergedDF  :  1789 
## Number of individuals that only present in  wVisitIndex_CERAD_IMM_RC  :  0 
## Number of individuals present in both datasets :  188 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2841, cols:1314, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CERAD_RECOG_RC 
## Before merging: Info of  wVisitIndex_CERAD_RECOG_RC : 
## #obs:177, cols:34, inds:177 
## 
## Number of individuals that only present in  mergedDF  :  1800 
## Number of individuals that only present in  wVisitIndex_CERAD_RECOG_RC  :  0 
## Number of individuals present in both datasets :  177 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:2842, cols:1346, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CONSENSUS_DX 
## Before merging: Info of  wVisitIndex_CONSENSUS_DX : 
## #obs:1701, cols:45, inds:1584 
## 
## Number of individuals that only present in  mergedDF  :  393 
## Number of individuals that only present in  wVisitIndex_CONSENSUS_DX  :  0 
## Number of individuals present in both datasets :  1584 
## 
## Common columns between the two datatsets are:  SYSXM 
## 
## Info for merged dataset:
## #obs:3861, cols:1389, inds:1977 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CRAFT_21_DEL_RC 
## Before merging: Info of  wVisitIndex_CRAFT_21_DEL_RC : 
## #obs:523, cols:81, inds:519 
## 
## Number of individuals that only present in  mergedDF  :  1474 
## Number of individuals that only present in  wVisitIndex_CRAFT_21_DEL_RC  :  16 
## Number of individuals present in both datasets :  503 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:3878, cols:1468, inds:1993 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_CRAFT_21_IMM_RC 
## Before merging: Info of  wVisitIndex_CRAFT_21_IMM_RC : 
## #obs:530, cols:84, inds:525 
## 
## Number of individuals that only present in  mergedDF  :  1469 
## Number of individuals that only present in  wVisitIndex_CRAFT_21_IMM_RC  :  1 
## Number of individuals present in both datasets :  524 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:3881, cols:1550, inds:1994 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_MEDCON_RC 
## Before merging: Info of  wVisitIndex_MEDCON_RC : 
## #obs:627, cols:223, inds:618 
## 
## Number of individuals that only present in  mergedDF  :  1376 
## Number of individuals that only present in  wVisitIndex_MEDCON_RC  :  0 
## Number of individuals present in both datasets :  618 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER MEMORY_COMPLAINTS DATE_OF_ONSET DOA_UNK DESCRIBE MEM_COMPLAINTS CURRENT_MED PMH MOOD_CHANGES HYPERTENSION_DX HYPERTENSION_TREATED DIABETES_DX DIABETES_TREATED MYOCARDIAL_DX MYOCARDIAL_TREATED HEART_FAILURE_DX HEART_FAILURE_TREATED HEART_DISEASE_DX HEART_DISEASE_TREATED COPD_DX COPD_TREATED THYROID_DX THYROID_TREATED LIVER_DX LIVER_TREATED RENAL_DX RENAL_TREATED PEPTIC_DX PEPTIC_TREATED PERIPHERAL_DX PERIPHERAL_TREATED STROKE_DX STROKE_TREATED TIA_DX TIA_TREATED HEAD_INJURY_DX HEAD_INJURY_TREATED SEIZURE_DX SEIZURE_TREATED CANCER_DX CANCER_TREATED ARTHRITIS_DX ARTHRITIS_TREATED SYPHILIS_DX SYPHILIS_TREATED ALCOHOL_DX ALCOHOL_TREATED ILLICIT_DRUG_DX ILLICIT_DRUG_TREATED SMOKING_DX SMOKING_TREATED PD_DX PD_TREATED HUNTINGTON_DX HUNTINGTON_TREATED MULTIPLE_SCLEROSIS_DX MULTIPLE_SCLEROSIS_TREATED B12_DX B12_TREATED HYDROCEPHALUS_DX HYDROCEPHALUS_TREATED TREMOR_DX TREMOR_TREATED DOWN_SYNDROME_DX DOWN_SYNDROME_TREATED MED_CONDITIONS_DX MED_CONDITIONS_TREATED OTH_MED_COND_SP STROKE_BRAIN DOCTOR STROKE_PAST STROKE_24HRS SYMPTOMS LOST_SPEECH LOST_UNDERSTAND LOSS_CONSCIOUS WEAKNESS NUMBNESS LOSS_VISION HALF_VISION PERIOD DONT_KNOW SEEK_HELP TREATMENT MEDS PSYCHOTHERAPY OTHER UNKNOWN TAKING_MEDS MEDICATION1 STRENGTH1 SEEN1 MEDICATION2 STRENGTH2 SEEN2 MEDICATION3 STRENGTH3 SEEN3 MEDICATION4 STRENGTH4 SEEN4 MEDICATION5 STRENGTH5 SEEN5 MEDICATION6 STRENGTH6 SEEN6 MEDICATION7 STRENGTH7 SEEN7 MEDICATION8 STRENGTH8 SEEN8 MEDICATION9 STRENGTH9 SEEN9 MEDICATION10 STRENGTH10 SEEN10 MEDICATION11 STRENGTH11 SEEN11 MEDICATION12 STRENGTH12 SEEN12 MEDICATION13 STRENGTH13 SEEN13 MEDICATION14 STRENGTH14 SEEN14 MEDICATION15 STRENGTH15 SEEN15 MEDICATION16 STRENGTH16 SEEN16 MEDICATION17 STRENGTH17 SEEN17 MEDICATION18 STRENGTH18 SEEN18 MEDICATION19 STRENGTH19 SEEN19 MEDICATION20 STRENGTH20 SEEN20 WARFARIN ASPIRIN ANTIPLATELETS DIURETICS ANTICONVULSANTS INSULIN HYPOGLYCEMICS SULFONYLUREA METFORMIN GLITAZONES DIGITALIS NITRATES CALCIUM_CHANNEL BETA_2_AGAONIST BETA_BLOCKERS ACE ANTI_ARRHYTHMICS ANTI_HYPERLIPIDEMICS STATIN_DRUG FIBRATE_DRUG THYROID ANTICHOLINERGICS LEVODOPA ANTIDEPRESSANTS ANTIPSYCHOTICS ANXIOLYTICS CHOLINESTERASE RIVASTIGMINE TACRINE DONEPEZIL GALANTAMINE NMDA MEMANTINE ALPHA_BLOCKERS HYPNOTICS H1_BLOCKERS H2_BLOCKERS NSAID COX2 NARCOTICS HYDERGINE DEPRENYL ESTROGEN_SUPP PRESCRIPTION OTC STEROIDS OTHER_MEDS MULTIVITAMINS VITAMIN_C VITAMIN_E VITAMINE_B12 COENZYME_Q DHA LECITHIN GINKGO FOLIC_ACID VITAMIN_B6 VITAMIN_D OMEGA3 MEDCOND_COMENTS 
## 
## Info for merged dataset:
## #obs:3885, cols:1771, inds:1994 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_MEDICAL_HIST 
## Before merging: Info of  wVisitIndex_MEDICAL_HIST : 
## #obs:889, cols:39, inds:871 
## 
## Number of individuals that only present in  mergedDF  :  1123 
## Number of individuals that only present in  wVisitIndex_MEDICAL_HIST  :  0 
## Number of individuals present in both datasets :  871 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM ANXIETY 
## 
## Info for merged dataset:
## #obs:3906, cols:1808, inds:1994 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_MINT_RC 
## Before merging: Info of  wVisitIndex_MINT_RC : 
## #obs:3, cols:207, inds:3 
## 
## Number of individuals that only present in  mergedDF  :  1991 
## Number of individuals that only present in  wVisitIndex_MINT_RC  :  0 
## Number of individuals present in both datasets :  3 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:3906, cols:2013, inds:1994 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_MINT_SP_RC 
## Before merging: Info of  wVisitIndex_MINT_SP_RC : 
## #obs:303, cols:207, inds:301 
## 
## Number of individuals that only present in  mergedDF  :  1693 
## Number of individuals that only present in  wVisitIndex_MINT_SP_RC  :  0 
## Number of individuals present in both datasets :  301 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:3906, cols:2218, inds:1994 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_MOCA_RC 
## Before merging: Info of  wVisitIndex_MOCA_RC : 
## #obs:585, cols:126, inds:580 
## 
## Number of individuals that only present in  mergedDF  :  1414 
## Number of individuals that only present in  wVisitIndex_MOCA_RC  :  0 
## Number of individuals present in both datasets :  580 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:3906, cols:2342, inds:1994 
## ======================================================================= 
## Currently merging with dataset:  wVisitIndex_NUMBER_SPAN_RC 
## Before merging: Info of  wVisitIndex_NUMBER_SPAN_RC : 
## #obs:527, cols:71, inds:522 
## 
## Number of individuals that only present in  mergedDF  :  1472 
## Number of individuals that only present in  wVisitIndex_NUMBER_SPAN_RC  :  0 
## Number of individuals present in both datasets :  522 
## 
## Common columns between the two datatsets are:  EXAM_DATE SYSXM EXAMINER AGE_AT_EXAM REVIEW_DATE REVIEWER 
## 
## Info for merged dataset:
## #obs:3906, cols:2411, inds:1994</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
